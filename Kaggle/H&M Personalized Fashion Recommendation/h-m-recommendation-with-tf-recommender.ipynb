{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing & Defining Utiliy Funtions","metadata":{}},{"cell_type":"code","source":"!pip install -q --no-deps ../input/tfrs-whl-installation/scann-1.2.3-cp37-cp37m-manylinux2014_x86_64.whl\n!pip install -q --no-deps ../input/tfrs-whl-installation/tensorflow_recommenders-0.6.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:34:12.813605Z","iopub.execute_input":"2022-03-27T06:34:12.814012Z","iopub.status.idle":"2022-03-27T06:34:57.923748Z","shell.execute_reply.started":"2022-03-27T06:34:12.813902Z","shell.execute_reply":"2022-03-27T06:34:57.92273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nos.environ[\"WANDB_API_KEY\"] = \"6f810b088fcc6b9eaaa56c1e52cfd37836606240\"\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport wandb\nfrom wandb.keras import WandbCallback\nimport shutil\nfrom glob import glob\nfrom IPython.display import Image, display\nimport psutil\n\nfrom multiprocessing import cpu_count, Process\nimport copy\nimport warnings\nfrom datetime import datetime, timedelta\nfrom time import time, sleep, mktime\nimport matplotlib.pyplot as plt\nfrom matplotlib import font_manager as fm, rc, rcParams\nfrom tqdm import tqdm\nimport re\nimport random as rnd\nfrom collections import Counter\nimport gc\n\nimport numpy as np\nfrom numpy import array, nan, random as np_rnd, where\nimport pandas as pd\nfrom pandas import DataFrame as dataframe, Series as series, isna, read_csv\nfrom pandas.tseries.offsets import DateOffset\n\nfrom sklearn.model_selection import train_test_split as tts, GridSearchCV as GridTuner, StratifiedKFold, KFold, ShuffleSplit, StratifiedShuffleSplit\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler, KBinsDiscretizer\nfrom sklearn import metrics\n\nfrom optuna import distributions as optuna_dist, visualization as optuna_plt, Trial, create_study, pruners\nfrom optuna.integration import OptunaSearchCV\nfrom optuna.samplers import TPESampler\nfrom optuna.logging import set_verbosity as optuna_set_verbose\nfrom optuna.logging import ERROR as optuna_error_verbose\n\n# ===== tensorflow =====\nimport tensorflow as tf\nfrom tensorflow import random as tf_rnd\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras import metrics as tf_metrics\nfrom tensorflow.keras import callbacks as tf_callbacks\nfrom tqdm.keras import TqdmCallback\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.utils import plot_model\n\nimport tensorflow_recommenders as tfrs\nimport scann\n\n\nwarnings.filterwarnings(action='ignore')\nrcParams['axes.unicode_minus'] = False\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\npd.set_option('display.width', 1000)\npd.set_option('max_colwidth', 200)\n\n# # GPU check\n# device_name = tf.test.gpu_device_name()\n# if device_name != '/device:GPU:0':\n#   print('GPU device not found')\n# print('Found GPU at: {}'.format(device_name))\n\ngpus = tf.config.list_physical_devices('GPU')\n# if gpus:\n#   try:\n#     tf.config.experimental.set_memory_growth(gpus[0], True)\n#   except RuntimeError as e:\n#     print(e)\n\nimport cudf\nimport cupy as cp\nfrom cuml.neighbors import KNeighborsRegressor, KNeighborsClassifier\n\nfrom numba import cuda \ndevice = cuda.get_current_device()\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:34:57.925821Z","iopub.execute_input":"2022-03-27T06:34:57.926113Z","iopub.status.idle":"2022-03-27T06:35:07.505639Z","shell.execute_reply.started":"2022-03-27T06:34:57.926076Z","shell.execute_reply":"2022-03-27T06:35:07.50488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ===== utility functions =====\n# label encoding for categorical column with excepting na value\ndef seed_everything(seed=42):\n    # python-self\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    # python random module\n    rnd.seed(seed)\n    # numpy random\n    np_rnd.seed(seed)\n    # tf random\n    tf_rnd.set_seed(seed)\n    # RAPIDS random\n    cp.random.seed(seed)\ndef which(bool_list):\n    return where(bool_list)[0]\ndef easyIO(x=None, path=None, op=\"r\", keras_inspection=False):\n    tmp = None\n    if op == \"r\":\n        with open(path, \"rb\") as f:\n            tmp = pickle.load(f)\n        return tmp\n    elif op == \"w\":\n        print(x)\n        tmp = x\n        if keras_inspection:\n            tmp = {}\n            if type(x) is dict:\n                for k in x.keys():\n                    if \"MLP\" in k:\n                        tmp[k] = {}\n                        for model_comps in x[k].keys():\n                            if model_comps != \"model\":\n                                tmp[k][model_comps] = copy.deepcopy(x[k][model_comps])\n                        print(F\"INFO : {k} model is removed (keras)\")\n                    else:\n                        tmp[k] = x[k]\n        if input(\"Write [y / n]: \") == \"y\":\n            with open(path, \"wb\") as f:\n                pickle.dump(tmp, f)\n            print(\"operation success\")\n        else:\n            print(\"operation fail\")\n    else:\n        print(\"Unknown operation type\")\ndef diff(first, second):\n    second = set(second)\n    return [item for item in first if item not in second]\ndef findIdx(data_x, col_names):\n    return [int(i) for i, j in enumerate(data_x) if j in col_names]\ndef orderElems(for_order, using_ref):\n    return [i for i in using_ref if i in for_order]\n# concatenate by row\ndef cbr(df1, df2):\n    if type(df1) == series:\n        tmp_concat = series(pd.concat([dataframe(df1), dataframe(df2)], axis=0, ignore_index=True).iloc[:,0])\n        tmp_concat.reset_index(drop=True, inplace=True)\n    elif type(df1) == dataframe:\n        tmp_concat = pd.concat([df1, df2], axis=0, ignore_index=True)\n        tmp_concat.reset_index(drop=True, inplace=True)\n    elif type(df1) == np.ndarray:\n        tmp_concat = np.concatenate([df1, df2], axis=0)\n    else:\n        print(\"Unknown Type: return 1st argument\")\n        tmp_concat = df1\n    return tmp_concat\ndef change_width(ax, new_value):\n    for patch in ax.patches :\n        current_width = patch.get_width()\n        adj_value = current_width - new_value\n        # we change the bar width\n        patch.set_width(new_value)\n        # we recenter the bar\n        patch.set_x(patch.get_x() + adj_value * .5)\ndef week_of_month(date):\n    month = date.month\n    week = 0\n    while date.month == month:\n        week += 1\n        date -= timedelta(days=7)\n    return week\ndef getSeason(date):\n    month = date.month\n    if month in [3, 4, 5]:\n        return \"Spring\"\n    elif month in [6, 7, 8]:\n        return \"Summer\"\n    elif month in [9, 10, 11]:\n        return \"Fall\"\n    else:\n        return \"Winter\"\ndef createFolder(directory):\n    try:\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n    except OSError:\n        print('Error: Creating directory. ' + directory)\ndef softmax(x):\n    max = np.max(x, axis=1, keepdims=True)  # returns max of each row and keeps same dims\n    e_x = np.exp(x - max)  # subtracts each row with its max value\n    sum = np.sum(e_x, axis=1, keepdims=True)  # returns sum of each row and keeps same dims\n    f_x = e_x / sum\n    return f_x\ndef sigmoid(x):\n    return 1/(1 + np.exp(-x))\ndef dispPerformance(result_dic):\n    perf_table = dataframe()\n    index_names = []\n    for k, v in result_dic.items():\n        index_names.append(k)\n        perf_table = pd.concat([perf_table, series(v[\"performance\"]).to_frame().T], ignore_index=True, axis=0)\n    perf_table.index = index_names\n    perf_table.sort_values(perf_table.columns[0], inplace=True)\n    print(perf_table)\n    return perf_table\ndef powspace(start, stop, power, num):\n    start = np.power(start, 1/float(power))\n    stop = np.power(stop, 1/float(power))\n    return np.power(np.linspace(start, stop, num=num), power)\ndef xgb_custom_lossfunction(alpha = 1):\n    def support_under_mse(label, pred):\n        # grad : 1차 미분\n        # hess : 2차 미분\n        residual = (label - pred).astype(\"float\")\n        grad = np.where(residual > 0, -2 * alpha * residual, -2 * residual)\n        hess = np.where(residual > 0, 2 * alpha, 2.0)\n        return grad, hess\n    return support_under_mse\ndef pd_flatten(df):\n    df = df.unstack()\n    df.index = [str(i) + \"_\" + str(j) for i, j in df.index]\n    return df\ndef tf_loss_rmse(y_true, y_pred, sample_weight=False):\n    return tf.sqrt(tf.reduce_mean((y_true - y_pred) ** 2)) if not sample_weight else tf.sqrt(tf.reduce_mean(((y_true - y_pred) ** 2) * sample_weight))\ndef text_extractor(string, lang=\"eng\", spacing=True):\n    # # 괄호를 포함한 괄호 안 문자 제거 정규식\n    # re.sub(r'\\([^)]*\\)', '', remove_text)\n    # # <>를 포함한 <> 안 문자 제거 정규식\n    # re.sub(r'\\<[^)]*\\>', '', remove_text)\n    if lang == \"eng\":\n        text_finder = re.compile('[^ A-Za-z]') if spacing else re.compile('[^A-Za-z]')\n    elif lang == \"kor\":\n        text_finder = re.compile('[^ ㄱ-ㅣ가-힣+]') if spacing else re.compile('[^ㄱ-ㅣ가-힣+]')\n    # default : kor + eng\n    else:\n        text_finder = re.compile('[^ A-Za-zㄱ-ㅣ가-힣+]') if spacing else re.compile('[^A-Za-zㄱ-ㅣ가-힣+]')\n    return text_finder.sub('', string)\ndef memory_usage(message='debug'):\n    # current process RAM usage\n    p = psutil.Process()\n    rss = p.memory_info().rss / 2 ** 20 # Bytes to MB\n    print(f\"[{message}] memory usage: {rss: 10.3f} MB\")\n    return rss\nclass MyLabelEncoder:\n    def __init__(self, preset={}):\n        # dic_cat format -> {\"col_name\": {\"value\": replace}}\n        self.dic_cat = preset\n    def fit_transform(self, data_x, col_names):\n        tmp_x = copy.deepcopy(data_x)\n        for i in col_names:\n            # if key is not in dic, update dic\n            if i not in self.dic_cat.keys():\n                tmp_dic = dict.fromkeys(sorted(set(tmp_x[i]).difference([nan])))\n                label_cnt = 0\n                for j in tmp_dic.keys():\n                    tmp_dic[j] = label_cnt\n                    label_cnt += 1\n                self.dic_cat[i] = tmp_dic\n            # transform value which is not in dic to nan\n            tmp_x[i] = tmp_x[i].astype(\"object\")\n            conv = tmp_x[i].replace(self.dic_cat[i])\n            for conv_idx, j in enumerate(conv):\n                if j not in self.dic_cat[i].values():\n                    conv[conv_idx] = nan\n            # final return\n            tmp_x[i] = conv.astype(\"float\")\n        return tmp_x\n    def transform(self, data_x):\n        tmp_x = copy.deepcopy(data_x)\n        for i in self.dic_cat.keys():\n            # transform value which is not in dic to nan\n            tmp_x[i] = tmp_x[i].astype(\"object\")\n            conv = tmp_x[i].replace(self.dic_cat[i])\n            for conv_idx, j in enumerate(conv):\n                if j not in self.dic_cat[i].values():\n                    conv[conv_idx] = nan\n            # final return\n            tmp_x[i] = conv.astype(\"float\")\n        return tmp_x\n    def clear(self):\n        self.dic_cat = {}\nclass MyOneHotEncoder:\n    def __init__(self, label_preset={}):\n        self.dic_cat = {}\n        self.label_preset = label_preset\n    def fit_transform(self, data_x, col_names):\n        tmp_x = dataframe()\n        for i in data_x:\n            if i not in col_names:\n                tmp_x = pd.concat([tmp_x, dataframe(data_x[i])], axis=1)\n            else:\n                if not ((data_x[i].dtype.name == \"object\") or (data_x[i].dtype.name == \"category\")):\n                    print(F\"WARNING : {i} is not object or category\")\n                self.dic_cat[i] = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n                conv = self.dic_cat[i].fit_transform(dataframe(data_x[i])).astype(\"int\")\n                col_list = []\n                for j in self.dic_cat[i].categories_[0]:\n                    if i in self.label_preset.keys():\n                        for k, v in self.label_preset[i].items():\n                            if v == j:\n                                col_list.append(str(i) + \"_\" + str(k))\n                    else:\n                        col_list.append(str(i) + \"_\" + str(j))\n                conv = dataframe(conv, columns=col_list)\n                tmp_x = pd.concat([tmp_x, conv], axis=1)\n        return tmp_x\n    def transform(self, data_x):\n        tmp_x = dataframe()\n        for i in data_x:\n            if not i in list(self.dic_cat.keys()):\n                tmp_x = pd.concat([tmp_x, dataframe(data_x[i])], axis=1)\n            else:\n                if not ((data_x[i].dtype.name == \"object\") or (data_x[i].dtype.name == \"category\")):\n                    print(F\"WARNING : {i} is not object or category\")\n                conv = self.dic_cat[i].transform(dataframe(data_x[i])).astype(\"int\")\n                col_list = []\n                for j in self.dic_cat[i].categories_[0]:\n                    if i in self.label_preset.keys():\n                        for k, v in self.label_preset[i].items():\n                            if v == j: col_list.append(str(i) + \"_\" + str(k))\n                    else:\n                        col_list.append(str(i) + \"_\" + str(j))\n                conv = dataframe(conv, columns=col_list)\n                tmp_x = pd.concat([tmp_x, conv], axis=1)\n        return tmp_x\n    def clear(self):\n        self.dic_cat = {}\n        self.label_preset = {}\nclass MyKNNImputer:\n    def __init__(self, k=5):\n        self.imputer = KNNImputer(n_neighbors=k)\n        self.dic_cat = {}\n    def fit_transform(self, x, cat_vars=None):\n        if cat_vars is None:\n            x_imp = dataframe(self.imputer.fit_transform(x), columns=x.columns)\n        else:\n            naIdx = dict.fromkeys(cat_vars)\n            for i in cat_vars:\n                self.dic_cat[i] = diff(list(sorted(set(x[i]))), [nan])\n                naIdx[i] = list(which(array(x[i].isna())))\n            x_imp = dataframe(self.imputer.fit_transform(x), columns=x.columns)\n\n            # if imputed categorical value are not in the range, adjust the value\n            for i in cat_vars:\n                x_imp[i] = x_imp[i].apply(lambda x: int(round(x, 0)))\n                for j in naIdx[i]:\n                    if x_imp[i][j] not in self.dic_cat[i]:\n                        if x_imp[i][j] < self.dic_cat[i][0]:\n                            x_imp[i][naIdx[i]] = self.dic_cat[i][0]\n                        elif x_imp[i][j] > self.dic_cat[i][0]:\n                            x_imp[i][naIdx[i]] = self.dic_cat[i][len(self.dic_cat[i]) - 1]\n        return x_imp\n    def transform(self, x):\n        if len(self.dic_cat.keys()) == 0:\n            x_imp = dataframe(self.imputer.transform(x), columns=x.columns)\n        else:\n            naIdx = dict.fromkeys(self.dic_cat.keys())\n            for i in self.dic_cat.keys():\n                naIdx[i] = list(which(array(x[i].isna())))\n            x_imp = dataframe(self.imputer.transform(x), columns=x.columns)\n\n            # if imputed categorical value are not in the range, adjust the value\n            for i in self.dic_cat.keys():\n                x_imp[i] = x_imp[i].apply(lambda x: int(round(x, 0)))\n                for j in naIdx[i]:\n                    if x_imp[i][j] not in self.dic_cat[i]:\n                        if x_imp[i][j] < self.dic_cat[i][0]:\n                            x_imp[i][naIdx[i]] = self.dic_cat[i][0]\n                        elif x_imp[i][j] > self.dic_cat[i][0]:\n                            x_imp[i][naIdx[i]] = self.dic_cat[i][len(self.dic_cat[i]) - 1]\n        return x_imp\n    def clear(self):\n        self.imputer = None\n        self.dic_cat = {}","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:07.507149Z","iopub.execute_input":"2022-03-27T06:35:07.507377Z","iopub.status.idle":"2022-03-27T06:35:07.573503Z","shell.execute_reply.started":"2022-03-27T06:35:07.507345Z","shell.execute_reply":"2022-03-27T06:35:07.572919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RandomCropAndResize(tf.keras.layers.Layer):\n    def __init__(self, crop_ratio=0.8, resize_img_size=128, resize_channels=3, **kwargs):\n        super(RandomCropAndResize, self).__init__(**kwargs)\n        self.img_size = resize_img_size\n        self.channels = resize_channels\n        self.crop_size = int(self.img_size * self.crop_ratio)\n    def call(self, input_image, training=False):\n        if training:\n            input_image = tf.image.random_crop(input_image, [self.crop_size, self.crop_size, self.channels])\n            input_image = tf.image.resize(input_image, [self.resize_img_size, self.resize_img_size])\n            return input_image\n        else:\n            return input_image\ndef RandomAngleDistortion(rotation_factor=0.2, flip=False):\n    if flip:\n        model = Sequential([\n            layers.RandomRotation(factor=(-rotation_factor, rotation_factor)),\n            layers.RandomFlip(\"horizontal\")\n        ])\n        return model\n    else:\n        model = Sequential([\n            layers.RandomRotation(factor=(-rotation_factor, rotation_factor)),\n        ])\n        return model\nclass RandomColorDistortion(tf.keras.layers.Layer):\n    def __init__(self, saturation_factor=(0.8, 1.2), contrast_factor=(0.8, 1.2), brightness_factor=0.2, hue_factor=0.2, hue_flag=True, **kwargs):\n        super(RandomColorDistortion, self).__init__(**kwargs)\n        self.saturation_factor = saturation_factor\n        self.contrast_factor = contrast_factor\n        self.brightness_factor = brightness_factor\n        self.hue_factor = hue_factor\n        self.hue_flag = hue_flag\n    def call(self, input_image, training=False):\n        if training:\n            input_image = tf.image.random_saturation(input_image, self.saturation_factor[0], self.saturation_factor[1])\n            input_image = tf.image.random_contrast(input_image, self.contrast_factor[0], self.contrast_factor[1])\n            input_image = tf.image.random_brightness(input_image, self.brightness_factor)\n            input_image = tf.image.random_hue(input_image, self.hue_factor) if self.hue_flag else input_image\n            return input_image\n        else:\n            return input_image","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:07.576861Z","iopub.execute_input":"2022-03-27T06:35:07.577235Z","iopub.status.idle":"2022-03-27T06:35:07.595857Z","shell.execute_reply.started":"2022-03-27T06:35:07.5772Z","shell.execute_reply":"2022-03-27T06:35:07.595183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing & Feature Engineering","metadata":{}},{"cell_type":"code","source":"seed_everything()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:07.596977Z","iopub.execute_input":"2022-03-27T06:35:07.597654Z","iopub.status.idle":"2022-03-27T06:35:07.667433Z","shell.execute_reply.started":"2022-03-27T06:35:07.597616Z","shell.execute_reply":"2022-03-27T06:35:07.666784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_conv_rf = dict.fromkeys([\"customer_id\"], \"object\")\ncontent_conv_ref = dict.fromkeys([\"article_id\"], \"object\")\nrating_conv_rf = dict.fromkeys([\"customer_id\", \"article_id\", \"sales_channel_id\"], \"object\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:07.668704Z","iopub.execute_input":"2022-03-27T06:35:07.669085Z","iopub.status.idle":"2022-03-27T06:35:07.673377Z","shell.execute_reply.started":"2022-03-27T06:35:07.669051Z","shell.execute_reply":"2022-03-27T06:35:07.67273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user = cudf.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/customers.csv\")\ncontent = cudf.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/articles.csv\", dtype=[\"object\"])\nrating = cudf.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\", dtype=[\"object\"], parse_dates=[\"t_dat\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:07.674604Z","iopub.execute_input":"2022-03-27T06:35:07.675056Z","iopub.status.idle":"2022-03-27T06:35:51.312893Z","shell.execute_reply.started":"2022-03-27T06:35:07.675022Z","shell.execute_reply":"2022-03-27T06:35:51.312097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filtering no image data\ncontent_mask = read_csv(\"../input/h-m-image-exists/content_exists_mask.csv\")\nrating_mask = read_csv(\"../input/h-m-image-exists/rating_exist_mask.csv\")\ncontent = content[content_mask.iloc[:,0]==1]\ncontent.reset_index(drop=True, inplace=True)\nrating = rating[rating_mask.iloc[:,0]==1]\nrating.reset_index(drop=True, inplace=True)\ndel content_mask, rating_mask","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:51.314226Z","iopub.execute_input":"2022-03-27T06:35:51.31448Z","iopub.status.idle":"2022-03-27T06:35:54.375232Z","shell.execute_reply.started":"2022-03-27T06:35:51.314448Z","shell.execute_reply":"2022-03-27T06:35:54.374487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reducing memory**","metadata":{}},{"cell_type":"code","source":"user.drop(\"postal_code\", axis=1, inplace=True)\nuser['customer_id'] = user['customer_id'].str[-16:].str.hex_to_int().astype('int64')\nuser[[\"FN\", \"Active\", \"age\"]] = user[[\"FN\", \"Active\", \"age\"]].astype(\"float32\")\ncontent = content[[\"article_id\", \"product_type_no\", \"graphical_appearance_no\", \"colour_group_code\", \"index_name\"]]\ncontent[[\"product_type_no\", \"graphical_appearance_no\", \"colour_group_code\"]] = \\\n    content[[\"product_type_no\", \"graphical_appearance_no\", \"colour_group_code\"]].astype(\"int32\")\n# rating.drop([\"t_dat\", \"sales_channel_id\", \"price\"], axis=1, inplace=True)\nrating['customer_id'] = rating['customer_id'].str[-16:].str.hex_to_int().astype('int64')","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:54.37636Z","iopub.execute_input":"2022-03-27T06:35:54.376595Z","iopub.status.idle":"2022-03-27T06:35:54.866633Z","shell.execute_reply.started":"2022-03-27T06:35:54.376564Z","shell.execute_reply":"2022-03-27T06:35:54.865898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Users Table**","metadata":{}},{"cell_type":"code","source":"user.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:54.869652Z","iopub.execute_input":"2022-03-27T06:35:54.870312Z","iopub.status.idle":"2022-03-27T06:35:54.922697Z","shell.execute_reply.started":"2022-03-27T06:35:54.870268Z","shell.execute_reply":"2022-03-27T06:35:54.921897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in [\"FN\", \"Active\", \"club_member_status\", \"fashion_news_frequency\", \"postal_code\"]:\n#    print(user[i].value_counts(dropna=False), \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:54.924105Z","iopub.execute_input":"2022-03-27T06:35:54.924363Z","iopub.status.idle":"2022-03-27T06:35:54.928094Z","shell.execute_reply.started":"2022-03-27T06:35:54.924329Z","shell.execute_reply":"2022-03-27T06:35:54.927092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**User Table**\n\n1. FN\n\nnan을 0으로 변환\n\n2. Active\n\nnan을 0으로 변환\n\n3. club_member_status\n\nnan을 \"Prospective\" 로 변환\n\n4. fashion_news_frequency\n\n\"None\" 및 nan 을 \"NONE\" 으로 변환\n\n5. age\n\nnan을 imputation","metadata":{}},{"cell_type":"code","source":"user[\"FN\"].fillna(0.0, inplace=True)\nuser[\"Active\"].fillna(0.0, inplace=True)\nuser[\"club_member_status\"].fillna(\"Prospective\", inplace=True)\nuser[\"fashion_news_frequency\"].replace(\"None\", \"NONE\", inplace=True)\nuser[\"fashion_news_frequency\"].fillna(\"NONE\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:54.929577Z","iopub.execute_input":"2022-03-27T06:35:54.929945Z","iopub.status.idle":"2022-03-27T06:35:54.968895Z","shell.execute_reply.started":"2022-03-27T06:35:54.929911Z","shell.execute_reply":"2022-03-27T06:35:54.968251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:54.970133Z","iopub.execute_input":"2022-03-27T06:35:54.970378Z","iopub.status.idle":"2022-03-27T06:35:54.98083Z","shell.execute_reply.started":"2022-03-27T06:35:54.970346Z","shell.execute_reply":"2022-03-27T06:35:54.980005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:54.982433Z","iopub.execute_input":"2022-03-27T06:35:54.982767Z","iopub.status.idle":"2022-03-27T06:35:55.01479Z","shell.execute_reply.started":"2022-03-27T06:35:54.982725Z","shell.execute_reply":"2022-03-27T06:35:55.01416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Label Encoding for Imputing**","metadata":{}},{"cell_type":"code","source":"user_label_encoder = copy.deepcopy(MyLabelEncoder())\nuser_label_encoder.fit_transform(user.to_pandas(), [\"club_member_status\", \"fashion_news_frequency\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:55.015993Z","iopub.execute_input":"2022-03-27T06:35:55.016244Z","iopub.status.idle":"2022-03-27T06:35:57.944482Z","shell.execute_reply.started":"2022-03-27T06:35:55.016211Z","shell.execute_reply":"2022-03-27T06:35:57.943718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna_set_verbose(optuna_error_verbose)\ndef optuna_objective_function(trial: Trial, train_x, train_y, val_x, val_y):\n    tuning_params = {\n        \"n_neighbors\" : trial.suggest_int(\"n_neighbors\", 3, 99, step=2)\n    }\n    model = KNeighborsRegressor(**tuning_params)\n    model.fit(train_x, train_y) \n    return metrics.mean_absolute_error(val_y.to_array(), model.predict(val_x).to_array())","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:57.945671Z","iopub.execute_input":"2022-03-27T06:35:57.945932Z","iopub.status.idle":"2022-03-27T06:35:57.951777Z","shell.execute_reply.started":"2022-03-27T06:35:57.945897Z","shell.execute_reply":"2022-03-27T06:35:57.951125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything()\ndef imputing_age():\n    _, full_x, _, full_y = tts(user[user[\"age\"].notna()],\n                               user[\"age\"][user[\"age\"].notna()],\n                               test_size=100000, random_state=42,\n                               stratify=pd.cut(user[\"age\"][user[\"age\"].notna()].to_array(), bins=[0,20,30,40,50,60,100], right=False))\n    train_x, val_x, train_y, val_y = tts(full_x, full_y,\n                                         test_size=0.2, random_state=42,\n                                         stratify=pd.cut(full_x[\"age\"].to_array(), bins=[0,20,30,40,50,60,100], right=False))\n    test_x = user[~user[\"age\"].notna()]\n\n    train_x = user_label_encoder.transform(train_x.to_pandas()); train_x.drop([\"customer_id\", \"age\"], axis=1, inplace=True)\n    val_x = user_label_encoder.transform(val_x.to_pandas()); val_x.drop([\"customer_id\", \"age\"], axis=1, inplace=True)\n\n    minmax_scaler = MinMaxScaler()\n    train_x = dataframe(minmax_scaler.fit_transform(train_x))\n    val_x = dataframe(minmax_scaler.transform(val_x))\n\n    optuna_set_verbose(0)\n    optuna_study = create_study(direction='minimize', sampler=TPESampler())\n    optuna_study.optimize(lambda trial: optuna_objective_function(\n        trial, cudf.DataFrame.from_pandas(train_x), cudf.Series.from_pandas(train_y),\n        cudf.DataFrame.from_pandas(val_x), cudf.Series.from_pandas(val_y)), n_trials=100)\n\n    full_x = user_label_encoder.transform(full_x.to_pandas()); full_x.drop([\"customer_id\", \"age\"], axis=1, inplace=True)\n    test_x = user_label_encoder.transform(test_x.to_pandas()); test_x.drop([\"customer_id\", \"age\"], axis=1, inplace=True)\n\n    minmax_scaler = MinMaxScaler()\n    full_x = dataframe(minmax_scaler.fit_transform(full_x))\n    test_x = dataframe(minmax_scaler.transform(test_x))\n\n    print(\"tuned params --->\", optuna_study.best_params)\n    knn = KNeighborsRegressor(**optuna_study.best_params)\n    knn.fit(cudf.DataFrame.from_pandas(full_x), cudf.Series.from_pandas(full_y))\n    user[\"age\"].iloc[which(user[\"age\"].isna().to_array())] = knn.predict(cudf.DataFrame.from_pandas(test_x)).to_array()\n\nimputing_age()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:35:57.953196Z","iopub.execute_input":"2022-03-27T06:35:57.953727Z","iopub.status.idle":"2022-03-27T06:36:49.585821Z","shell.execute_reply.started":"2022-03-27T06:35:57.953689Z","shell.execute_reply":"2022-03-27T06:36:49.585097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**'Age' feature imputing**","metadata":{}},{"cell_type":"code","source":"user.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.586953Z","iopub.execute_input":"2022-03-27T06:36:49.587356Z","iopub.status.idle":"2022-03-27T06:36:49.599473Z","shell.execute_reply.started":"2022-03-27T06:36:49.587318Z","shell.execute_reply":"2022-03-27T06:36:49.598303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user[\"age\"] = user[\"age\"].round().astype(\"float32\")\nif (user[\"age\"] <= 0).sum() > 0:\n    raise ValueError(\"minus value detected\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.600768Z","iopub.execute_input":"2022-03-27T06:36:49.601272Z","iopub.status.idle":"2022-03-27T06:36:49.613588Z","shell.execute_reply.started":"2022-03-27T06:36:49.601222Z","shell.execute_reply":"2022-03-27T06:36:49.612673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user[\"age_cat\"] = pd.cut(user[\"age\"].to_array(), bins=[0,20,30,40,50,60,100], labels=range(6), right=False, ordered=False).astype(\"float32\")\nprint(user[\"age\"].head(5))\nprint(user[\"age_cat\"].head(5))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.614836Z","iopub.execute_input":"2022-03-27T06:36:49.615352Z","iopub.status.idle":"2022-03-27T06:36:49.677261Z","shell.execute_reply.started":"2022-03-27T06:36:49.615306Z","shell.execute_reply":"2022-03-27T06:36:49.676531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.678597Z","iopub.execute_input":"2022-03-27T06:36:49.678871Z","iopub.status.idle":"2022-03-27T06:36:49.692598Z","shell.execute_reply.started":"2022-03-27T06:36:49.678823Z","shell.execute_reply":"2022-03-27T06:36:49.691883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_ref = pd.Index(user[\"customer_id\"].copy().to_array())","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.693957Z","iopub.execute_input":"2022-03-27T06:36:49.694571Z","iopub.status.idle":"2022-03-27T06:36:49.703644Z","shell.execute_reply.started":"2022-03-27T06:36:49.694533Z","shell.execute_reply":"2022-03-27T06:36:49.702893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Contents Table**","metadata":{}},{"cell_type":"code","source":"content.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.704785Z","iopub.execute_input":"2022-03-27T06:36:49.705095Z","iopub.status.idle":"2022-03-27T06:36:49.717509Z","shell.execute_reply.started":"2022-03-27T06:36:49.705059Z","shell.execute_reply":"2022-03-27T06:36:49.716859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.718802Z","iopub.execute_input":"2022-03-27T06:36:49.71908Z","iopub.status.idle":"2022-03-27T06:36:49.730137Z","shell.execute_reply.started":"2022-03-27T06:36:49.719045Z","shell.execute_reply":"2022-03-27T06:36:49.729415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.731413Z","iopub.execute_input":"2022-03-27T06:36:49.731659Z","iopub.status.idle":"2022-03-27T06:36:49.753413Z","shell.execute_reply.started":"2022-03-27T06:36:49.731626Z","shell.execute_reply":"2022-03-27T06:36:49.752754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in content:\n#     print(content[i].value_counts(), \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.754472Z","iopub.execute_input":"2022-03-27T06:36:49.754793Z","iopub.status.idle":"2022-03-27T06:36:49.760738Z","shell.execute_reply.started":"2022-03-27T06:36:49.754758Z","shell.execute_reply":"2022-03-27T06:36:49.759969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # re-organization on categories\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Underwear/nightwear\"] = \"Nightwear\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Cosmetic\"] = \"Unknown\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Bags\"] = \"Accessories\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Items\"] = \"Unknown\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Furniture\"] = \"Unknown\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Garment and Shoe care\"] = \"Shoes\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Stationery\"] = \"Accessories\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Interior textile\"] = \"Unknown\"\n# content[\"product_group_name\"][content[\"product_group_name\"] == \"Fun\"] = \"Unknown\"","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.762277Z","iopub.execute_input":"2022-03-27T06:36:49.762793Z","iopub.status.idle":"2022-03-27T06:36:49.767978Z","shell.execute_reply.started":"2022-03-27T06:36:49.76275Z","shell.execute_reply":"2022-03-27T06:36:49.767201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# content[\"product_group_name\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.773486Z","iopub.execute_input":"2022-03-27T06:36:49.773926Z","iopub.status.idle":"2022-03-27T06:36:49.779468Z","shell.execute_reply.started":"2022-03-27T06:36:49.773883Z","shell.execute_reply":"2022-03-27T06:36:49.778699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_ref = pd.Index(content[\"article_id\"].copy().to_array())\n# # original\n# image_rootPath = \"/kaggle/input/h-and-m-personalized-fashion-recommendations/images/\"\n# resized\nimage_rootPath = \"/kaggle/input/handm-dataset-128x128/images_128_128/\"\ncontent[\"article_id\"] = content[\"article_id\"].to_pandas().apply(lambda x: image_rootPath + x[:3] + \"/\" + x  + \".jpg\").to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.780919Z","iopub.execute_input":"2022-03-27T06:36:49.781568Z","iopub.status.idle":"2022-03-27T06:36:49.923418Z","shell.execute_reply.started":"2022-03-27T06:36:49.781533Z","shell.execute_reply":"2022-03-27T06:36:49.922687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Ratings table**","metadata":{}},{"cell_type":"code","source":"# rating[\"month\"] = rating[\"t_dat\"].dt.month - 1\n# rating[\"weekday\"] = rating[\"t_dat\"].dt.weekday\n# rating[\"holiday\"] = rating[\"weekday\"].apply(lambda x: 1 if x in [5,6] else 0)\n# day_to_sec = 24 * 60 * 60\n# year_to_sec = (365.2425) * day_to_sec\n# rating[\"yts_norm\"] = rating[\"t_dat\"].apply(lambda x: (x - pd.Timestamp(year=x.year, month=1, day=1)).total_seconds() / year_to_sec)\n# rating[\"price_grouped\"] = pd.cut(rating[\"price\"], 7, labels=range(7), ordered=False).astype(\"int\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.92486Z","iopub.execute_input":"2022-03-27T06:36:49.9251Z","iopub.status.idle":"2022-03-27T06:36:49.929381Z","shell.execute_reply.started":"2022-03-27T06:36:49.925066Z","shell.execute_reply":"2022-03-27T06:36:49.928674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.930766Z","iopub.execute_input":"2022-03-27T06:36:49.93122Z","iopub.status.idle":"2022-03-27T06:36:49.943988Z","shell.execute_reply.started":"2022-03-27T06:36:49.931184Z","shell.execute_reply":"2022-03-27T06:36:49.943076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.945336Z","iopub.execute_input":"2022-03-27T06:36:49.946043Z","iopub.status.idle":"2022-03-27T06:36:49.966403Z","shell.execute_reply.started":"2022-03-27T06:36:49.946009Z","shell.execute_reply":"2022-03-27T06:36:49.965759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating[\"t_dat\"] = cudf.to_datetime(rating[\"t_dat\"])\nrating[\"year_month\"] = cudf.to_datetime(rating[\"t_dat\"].dt.strftime('%Y-%m-1'))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:49.967522Z","iopub.execute_input":"2022-03-27T06:36:49.967777Z","iopub.status.idle":"2022-03-27T06:36:50.045663Z","shell.execute_reply.started":"2022-03-27T06:36:49.967741Z","shell.execute_reply":"2022-03-27T06:36:50.045003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rating.drop_duplicates(subset=[\"customer_id\", \"article_id\", \"month\"], inplace=True, ignore_index=True)\nrating.drop_duplicates(subset=[\"customer_id\", \"article_id\", \"year_month\"], inplace=True, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:50.046802Z","iopub.execute_input":"2022-03-27T06:36:50.047127Z","iopub.status.idle":"2022-03-27T06:36:50.691601Z","shell.execute_reply.started":"2022-03-27T06:36:50.047091Z","shell.execute_reply":"2022-03-27T06:36:50.690888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating[\"cnt\"] = 1\ntmp_groupby = rating.groupby(\"year_month\").sum()\ntmp_groupby.sort_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:50.692922Z","iopub.execute_input":"2022-03-27T06:36:50.693159Z","iopub.status.idle":"2022-03-27T06:36:51.629725Z","shell.execute_reply.started":"2022-03-27T06:36:50.693128Z","shell.execute_reply":"2022-03-27T06:36:51.628992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,9))\nax = fig.add_subplot(1, 1, 1)\nplt.xticks(rotation=45)\nplt.title(\"Transaction volume by timeseries\", fontsize=16, fontweight=\"bold\", pad=20)\nplt.plot(tmp_groupby.index.to_array(), tmp_groupby[\"cnt\"].to_array())\nax.set_xticks(tmp_groupby.index.to_array())","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:51.631039Z","iopub.execute_input":"2022-03-27T06:36:51.631288Z","iopub.status.idle":"2022-03-27T06:36:52.006129Z","shell.execute_reply.started":"2022-03-27T06:36:51.631256Z","shell.execute_reply":"2022-03-27T06:36:52.005444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train timeseries : 2018-09 ~ 2019-09**\n\n**Validation timeseries : 2019-10 ~ 2020-09**","metadata":{}},{"cell_type":"code","source":"rating = rating.sample(frac=1, random_state=114).reset_index(drop=True)\nstratVec = []\nfor i in tqdm(rating[\"article_id\"].to_array()):\n    try:\n        stratVec.append(content_ref.get_loc(i))\n    except:\n        stratVec.append(\"Unknown\")\nstratVec = content[\"product_type_no\"].iloc[stratVec].to_array()\n# rating[\"stratVec\"] = stratVec","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:36:52.007197Z","iopub.execute_input":"2022-03-27T06:36:52.007652Z","iopub.status.idle":"2022-03-27T06:38:07.582762Z","shell.execute_reply.started":"2022-03-27T06:36:52.007614Z","shell.execute_reply":"2022-03-27T06:38:07.582002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # for ranking task\n\n# from tqdm.contrib import tzip\n# tmp_groupby = rating.groupby([\"year_month\", \"stratVec\"]).sum()[\"cnt\"]\n# tmp_target = []\n# for i, j in tzip(rating[\"year_month\"].to_array(), rating[\"stratVec\"].to_array()):\n#     try:\n#         tmp_target.append(tmp_groupby.loc[(i, j)])\n#     except:\n#         tmp_target.append(0)\n# rating[\"ranking_target\"] = tmp_target\n\n# tmp_groupby = rating[rating[\"year_month\"] <= datetime(year=2019, month=9, day=1)]\n# tmp_groupby = tmp_groupby.groupby([\"customer_id\", \"stratVec\"]).sum()\n# tmp_groupby = tmp_groupby[\"cnt\"]\n\n# tmp_target = []\n# for i, j in tzip(rating[\"customer_id\"].to_array(), rating[\"stratVec\"].to_array()):\n#     try:\n#         tmp_target.append(tmp_groupby.loc[(i, j)])\n#     except:\n#         tmp_target.append(0)\n# rating[\"ranking_target\"] = tmp_target","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.584035Z","iopub.execute_input":"2022-03-27T06:38:07.584306Z","iopub.status.idle":"2022-03-27T06:38:07.588742Z","shell.execute_reply.started":"2022-03-27T06:38:07.584271Z","shell.execute_reply":"2022-03-27T06:38:07.58791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.589911Z","iopub.execute_input":"2022-03-27T06:38:07.590722Z","iopub.status.idle":"2022-03-27T06:38:07.605773Z","shell.execute_reply.started":"2022-03-27T06:38:07.590684Z","shell.execute_reply":"2022-03-27T06:38:07.604911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.607155Z","iopub.execute_input":"2022-03-27T06:38:07.607439Z","iopub.status.idle":"2022-03-27T06:38:07.6402Z","shell.execute_reply.started":"2022-03-27T06:38:07.607402Z","shell.execute_reply":"2022-03-27T06:38:07.639562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mask = (rating[\"year_month\"] <= datetime(year=2019, month=9, day=1)).to_array()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.641314Z","iopub.execute_input":"2022-03-27T06:38:07.641555Z","iopub.status.idle":"2022-03-27T06:38:07.649724Z","shell.execute_reply.started":"2022-03-27T06:38:07.641521Z","shell.execute_reply":"2022-03-27T06:38:07.648955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating.drop([\"t_dat\", \"sales_channel_id\", \"price\", \"year_month\", \"cnt\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.651936Z","iopub.execute_input":"2022-03-27T06:38:07.652571Z","iopub.status.idle":"2022-03-27T06:38:07.65715Z","shell.execute_reply.started":"2022-03-27T06:38:07.652533Z","shell.execute_reply":"2022-03-27T06:38:07.656339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del tmp_groupby; gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.658626Z","iopub.execute_input":"2022-03-27T06:38:07.659282Z","iopub.status.idle":"2022-03-27T06:38:07.944625Z","shell.execute_reply.started":"2022-03-27T06:38:07.659242Z","shell.execute_reply":"2022-03-27T06:38:07.943754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling - Retrieval\n\n**Retrieval - Users Tower & Contents Tower**","metadata":{}},{"cell_type":"code","source":"dropoutRate = 0.5","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.94702Z","iopub.execute_input":"2022-03-27T06:38:07.947302Z","iopub.status.idle":"2022-03-27T06:38:07.953116Z","shell.execute_reply.started":"2022-03-27T06:38:07.947261Z","shell.execute_reply":"2022-03-27T06:38:07.952442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_user():\n    input_list = []\n    concat_list = []\n    dcn_list = []\n    \n    # categorical feature\n    input_list.append(layers.Input(shape=1, dtype=tf.int64))\n    tmp_unique = user[\"customer_id\"].unique()\n    x = layers.IntegerLookup(vocabulary=tmp_unique[tmp_unique != -1].to_array(), output_mode=\"int\")(input_list[-1])\n    x = layers.Embedding(len(user[\"customer_id\"].unique())+1, 64, embeddings_initializer=\"glorot_normal\")(x)\n    x = layers.Dropout(dropoutRate)(x)\n    x = layers.Dense(16, activation=\"relu\")(x) \n    x = layers.Dropout(dropoutRate)(x)\n    dcn_list.append(layers.Dense(4)(x))\n    \n    input_list.append(layers.Input(shape=1, dtype=tf.string))\n    x = layers.StringLookup(vocabulary=user[\"club_member_status\"].unique().to_array(), output_mode=\"int\")(input_list[-1])\n    dcn_list.append(layers.Embedding(len(user[\"club_member_status\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n\n    input_list.append(layers.Input(shape=1, dtype=tf.string))\n    x = layers.StringLookup(vocabulary=user[\"fashion_news_frequency\"].unique().to_array(), output_mode=\"int\")(input_list[-1])\n    dcn_list.append(layers.Embedding(len(user[\"fashion_news_frequency\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n    \n    input_list.append(layers.Input(shape=1, dtype=tf.int32))\n    x = layers.IntegerLookup(vocabulary=user[\"age_cat\"].unique().to_array(), output_mode=\"int\")(input_list[-1])\n    dcn_list.append(layers.Embedding(len(user[\"age_cat\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n    \n    x = layers.Concatenate(axis=1)(dcn_list)\n    dcn1 = tfrs.layers.dcn.Cross()(x, layers.Dropout(dropoutRate)(x))\n    dcn2 = tfrs.layers.dcn.Cross()(x, layers.Dropout(dropoutRate)(dcn1))\n    \n    # DCN (Deep Cross Network for feature interaction)\n    concat_list.append(layers.Flatten()(x))\n    concat_list.append(layers.Flatten()(dcn1))\n    concat_list.append(layers.Flatten()(dcn2))\n\n    # numeric and binary feature\n    input_list.append(layers.Input(shape=3, dtype=tf.float32))\n    concat_list.append(input_list[-1])\n    \n    x = layers.Concatenate()(concat_list)\n    block1_input = tfa.layers.NoisyDense(128, activity_regularizer=\"l2\")(x)\n    x = tfa.layers.WeightNormalization(\n        layers.Dense(64, activation=\"relu\")\n    )(block1_input)\n    x = layers.Dropout(dropoutRate)(x)\n\n    block2_input = layers.Concatenate()([x, block1_input])\n    x = tfa.layers.WeightNormalization(\n        layers.Dense(64, activation=\"relu\")\n    )(block2_input)\n    x = layers.Dropout(dropoutRate)(x)\n\n    block3_input = layers.Concatenate()([x, block2_input])\n    x = tfa.layers.WeightNormalization(\n        layers.Dense(64, activation=\"relu\")\n    )(block3_input)\n    x = layers.Dropout(dropoutRate)(x)\n    \n    x = tfa.layers.WeightNormalization(\n        layers.Dense(32, activation=\"swish\")\n    )(x)\n\n    final_embeddings = layers.Dense(4)(x)\n    return Model(input_list, final_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.954585Z","iopub.execute_input":"2022-03-27T06:38:07.955147Z","iopub.status.idle":"2022-03-27T06:38:07.976093Z","shell.execute_reply.started":"2022-03-27T06:38:07.955108Z","shell.execute_reply":"2022-03-27T06:38:07.975427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_model(create_model_user(), show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.977483Z","iopub.execute_input":"2022-03-27T06:38:07.977969Z","iopub.status.idle":"2022-03-27T06:38:07.987944Z","shell.execute_reply.started":"2022-03-27T06:38:07.977933Z","shell.execute_reply":"2022-03-27T06:38:07.987137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 128\nchannels = 3\n\ndef create_model_content():\n    input_list = []\n    concat_list = []\n    dcn_list = []\n    \n    # image feature\n    image_cnn_model = Sequential([\n        layers.Conv2D(16, (8, 8), activation=\"relu\", padding=\"same\", input_shape=(img_size, img_size, channels)),\n        layers.Conv2D(16, (8, 8), activation=\"relu\", padding=\"same\"),\n        layers.MaxPooling2D(4, 4),\n        layers.Dropout(dropoutRate),\n        layers.Conv2D(32, (4, 4), activation=\"relu\", padding=\"same\"),\n        layers.Conv2D(32, (4, 4), activation=\"relu\", padding=\"same\"),\n        layers.MaxPooling2D(4, 4),\n        layers.Dropout(dropoutRate),\n        layers.Flatten(),\n        layers.Dense(1024, activation=\"relu\"),\n        layers.Dropout(dropoutRate),\n        layers.Dense(512, activation=\"relu\"),\n        layers.Dropout(dropoutRate),\n        layers.Dense(256, activation=\"relu\"),\n        layers.Dropout(dropoutRate),\n        layers.Dense(128, activation=\"relu\"),\n        layers.Dropout(dropoutRate)\n    ])\n        \n    input_list.append(layers.Input(shape=(img_size, img_size, channels), dtype=tf.float32))\n    x = RandomAngleDistortion(flip=False)(input_list[-1])\n    x = RandomColorDistortion(hue_flag=False)(x)\n    x = layers.Rescaling(1.0/255.0)(x)\n    concat_list.append(image_cnn_model(x))\n    \n    # categorical feature\n    input_list.append(layers.Input(shape=1, dtype=tf.int32))\n    tmp_unique = content[\"product_type_no\"].unique()\n    x = layers.IntegerLookup(vocabulary=tmp_unique[tmp_unique != -1].to_array(), output_mode=\"int\")(input_list[-1])\n    dcn_list.append(layers.Embedding(len(content[\"product_type_no\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n    \n#     input_list.append(layers.Input(shape=1, dtype=tf.string))\n#     tmp_unique = content[\"product_group_name\"].unique()\n#     x = layers.StringLookup(vocabulary=tmp_unique[tmp_unique != \"Unknown\"].to_array(), output_mode=\"int\")(input_list[-1])\n#     dcn_list.append(layers.Embedding(len(content[\"product_group_name\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n\n    input_list.append(layers.Input(shape=1, dtype=tf.int32))\n    tmp_unique = content[\"graphical_appearance_no\"].unique()\n    x = layers.IntegerLookup(vocabulary=tmp_unique[tmp_unique != -1].to_array(), output_mode=\"int\")(input_list[-1])\n    dcn_list.append(layers.Embedding(len(content[\"graphical_appearance_no\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n    \n    input_list.append(layers.Input(shape=1, dtype=tf.int32))\n    tmp_unique = content[\"colour_group_code\"].unique()\n    x = layers.IntegerLookup(vocabulary=tmp_unique[tmp_unique != -1].to_array(), output_mode=\"int\")(input_list[-1])\n    dcn_list.append(layers.Embedding(len(content[\"colour_group_code\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n    \n    input_list.append(layers.Input(shape=1, dtype=tf.string))\n    tmp_unique = content[\"index_name\"].unique()\n    x = layers.StringLookup(vocabulary=tmp_unique[tmp_unique != \"Unknown\"].to_array(), output_mode=\"int\")(input_list[-1])\n    dcn_list.append(layers.Embedding(len(content[\"index_name\"].unique())+1, 4, embeddings_initializer=\"glorot_normal\")(x))\n    \n    # DCN(Deep Cross Network for feature interaction)\n    x = layers.Concatenate(axis=1)(dcn_list)\n    dcn1 = tfrs.layers.dcn.Cross()(x, layers.Dropout(dropoutRate)(x))\n    dcn2 = tfrs.layers.dcn.Cross()(x, layers.Dropout(dropoutRate)(dcn1))\n\n    concat_list.append(layers.Flatten()(x))\n    concat_list.append(layers.Flatten()(dcn1))\n    concat_list.append(layers.Flatten()(dcn2))  \n  \n    x = layers.Concatenate()(concat_list)\n    block1_input = tfa.layers.NoisyDense(256, activity_regularizer=\"l2\")(x)\n    \n    x = tfa.layers.WeightNormalization(\n        layers.Dense(128, activation=\"relu\")\n    )(block1_input)\n    x = layers.Dropout(dropoutRate)(x)\n\n    block2_input = layers.Concatenate()([x, block1_input])\n    x = tfa.layers.WeightNormalization(\n        layers.Dense(128, activation=\"relu\")\n    )(block2_input)\n    x = layers.Dropout(dropoutRate)(x)\n\n    block3_input = layers.Concatenate()([x, block2_input])\n    x = tfa.layers.WeightNormalization(\n        layers.Dense(128, activation=\"relu\")\n    )(block3_input)\n    x = layers.Dropout(dropoutRate)(x)\n    \n    x = tfa.layers.WeightNormalization(\n        layers.Dense(64, activation=\"swish\")\n    )(x)\n    \n    final_embeddings = layers.Dense(4)(x)\n    return Model(input_list, final_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:07.989528Z","iopub.execute_input":"2022-03-27T06:38:07.989824Z","iopub.status.idle":"2022-03-27T06:38:08.016484Z","shell.execute_reply.started":"2022-03-27T06:38:07.989786Z","shell.execute_reply":"2022-03-27T06:38:08.015673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_model_content().summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.017771Z","iopub.execute_input":"2022-03-27T06:38:08.018486Z","iopub.status.idle":"2022-03-27T06:38:08.028167Z","shell.execute_reply.started":"2022-03-27T06:38:08.018448Z","shell.execute_reply":"2022-03-27T06:38:08.027399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_model(create_model_content(), show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.029253Z","iopub.execute_input":"2022-03-27T06:38:08.02968Z","iopub.status.idle":"2022-03-27T06:38:08.037021Z","shell.execute_reply.started":"2022-03-27T06:38:08.029644Z","shell.execute_reply":"2022-03-27T06:38:08.036363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Defining Retrieval Model**","metadata":{}},{"cell_type":"code","source":"def _gather_elements_along_row(data: tf.Tensor,\n                               column_indices: tf.Tensor) -> tf.Tensor:\n  \"\"\"Gathers elements from a 2D tensor given the column indices of each row.\n  A more efficient way of gathering elements from 2D tensor than tf.gather_nd().\n  First, gets the flat 1D indices to gather from. Then flattens the data to 1D\n  and uses tf.gather() to generate 1D output and finnally reshapes the\n  output back to 2D.\n  Args:\n    data: A [N, M] 2D `Tensor`.\n    column_indices: A [N, K] 2D `Tensor` denoting for each row, the K column\n      indices to gather elements from the data `Tensor`.\n  Returns:\n    A [N, K] `Tensor` including output elements gathered from data `Tensor`.\n  Raises:\n    ValueError: if the first dimensions of data and column_indices don't match.\n  \"\"\"\n  with tf.control_dependencies(\n      [tf.assert_equal(tf.shape(data)[0], tf.shape(column_indices)[0])]):\n    num_row = tf.shape(data)[0]\n    num_column = tf.shape(data)[1]\n    num_gathered = tf.shape(column_indices)[1]\n    row_indices = tf.tile(\n        tf.expand_dims(tf.range(num_row), -1),\n        [1, num_gathered])\n    flat_data = tf.reshape(data, [-1])\n    flat_indices = tf.reshape(\n        row_indices * num_column + column_indices, [-1])\n    return tf.reshape(\n        tf.gather(flat_data, flat_indices), [num_row, num_gathered])","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.038612Z","iopub.execute_input":"2022-03-27T06:38:08.038997Z","iopub.status.idle":"2022-03-27T06:38:08.048437Z","shell.execute_reply.started":"2022-03-27T06:38:08.038961Z","shell.execute_reply":"2022-03-27T06:38:08.047496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Modified_Retrieval(tfrs.tasks.Retrieval):\n  def __init__(self,\n               loss=None,\n               sample_weight=None,\n               loss_topk_mean=None,\n               metrics=None,\n               batch_metrics=None,\n               temperature=None,\n               num_hard_negatives=None,\n               name=None):\n    \n    super().__init__(loss=loss, metrics=metrics, batch_metrics=batch_metrics,\n                    temperature=temperature, num_hard_negatives=num_hard_negatives, name=name)\n    self.sample_weight = sample_weight\n    self.loss_topk_mean = loss_topk_mean\n    self.MAX_FLOAT = np.finfo('float32').max\n\n  def call(self,\n           query_embeddings,\n           candidates_embeddings,\n           metric_candidates_embeddings,\n           sample_weight=None,\n           candidate_sampling_probability=None,\n           candidate_ids=None,\n           compute_metrics=True):\n\n    # === Retrieval Model ===\n    # matmul for softmax (in batch sample)\n    scores = tf.linalg.matmul(query_embeddings, candidates_embeddings, transpose_b=True)\n    # using eye function for generating one-hot encoding vector (used on calculating logloss)\n    scores_shape = tf.shape(scores)\n    labels = tf.eye(scores_shape[0], scores_shape[1])\n    \n    metric_update_ops = []\n    if compute_metrics:\n        if self._factorized_metrics:\n            metric_update_ops.append(\n                self._factorized_metrics.update_state(query_embeddings, candidates_embeddings, metric_candidates_embeddings)\n            )\n        if self._batch_metrics:\n            metric_update_ops.extend([\n                batch_metric.update_state(labels, scores)\n                for batch_metric in self._batch_metrics\n            ])\n\n    if self._temperature is not None:\n        scores = scores / self._temperature\n\n    if candidate_sampling_probability is not None:\n        scores = tfrs.layers.loss.SamplingProbablityCorrection()(scores, candidate_sampling_probability)\n\n    if candidate_ids is not None:\n        scores = tfrs.layers.loss.RemoveAccidentalHits()(labels, scores, candidate_ids)\n\n    if self._num_hard_negatives is not None:\n        scores, labels = tfrs.layers.loss.HardNegativeMining(self._num_hard_negatives)(scores, labels)\n    \n    # average the top k logits (excluding my-self value, checking out the +1 operation below codes)\n    if self.loss_topk_mean is not None:\n        # mean top k logits and reshape to [pos, neg, neg ... neg]\n        sorted_scores = _gather_elements_along_row(scores, tf.argsort(scores + labels * self.MAX_FLOAT, direction=\"DESCENDING\"))\n        scores = tf.concat([tf.math.reduce_mean(sorted_scores[:, :(self.loss_topk_mean+1)], axis=-1, keepdims=True), sorted_scores[:, (self.loss_topk_mean+1):]], axis=1)\n\n        labels = tf.concat(\n            [tf.ones((tf.shape(scores)[0], 1)),\n             tf.zeros((tf.shape(scores)[0], tf.shape(scores)[1] - 1))], axis=1\n        )\n\n    # update loss\n    loss = self._loss(y_true=labels, y_pred=scores, sample_weight=sample_weight)\n\n    if not metric_update_ops:\n        return loss\n\n    with tf.control_dependencies(metric_update_ops):\n        return tf.identity(loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.0497Z","iopub.execute_input":"2022-03-27T06:38:08.050031Z","iopub.status.idle":"2022-03-27T06:38:08.067746Z","shell.execute_reply.started":"2022-03-27T06:38:08.049994Z","shell.execute_reply":"2022-03-27T06:38:08.066993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Modified_FactorizedTopK(tfrs.metrics.FactorizedTopK):\n  \"\"\"Computes metrics for across top K candidates surfaced by a retrieval model.\n  The default metric is top K categorical accuracy: how often the true candidate\n   is in the top K candidates for a given query.\n  \"\"\"\n#   def __init__(self, metrics=None, k=100, all_candidates_embeddings=None, scann_leaves=1000, name=\"factorized_top_k\"):\n  def __init__(self, metrics=None, k=100, raw_scann=None, name=\"factorized_top_k\"):\n    super().__init__(candidates=None, metrics=metrics, k=k, name=name)\n#     self._candidates = tfrs.layers.factorized_top_k.Streaming(sorted_order=False)\n#     self.candidates_extractor = tfrs.layers.factorized_top_k.ScaNN(\n#         num_leaves=scann_leaves,\n#         num_leaves_to_search=max(int(scann_leaves*0.2), 10),\n#         num_reordering_candidates=target_top_k*5,\n#         k=target_top_k*3\n#     )\n#     self.candidates_extractor.index_from_dataset(all_candidates_embeddings)\n    self.candidates_extractor = raw_scann\n\n  def update_state(self,\n                   query_embeddings,\n                   candidates_embeddings,\n                   metric_candidates_embeddings):\n\n    positive_scores = tf.reduce_sum(query_embeddings * candidates_embeddings, axis=1, keepdims=True)\n    # When initialization the retrieval model, parameter k is the value about the how many you wanna get dot product valeus on query embedding\n    # When initialization the TopKCategoricalAccuracy(), parameter k is the value you wanna see whether this response on the query are in top k\n#     self._candidates.index_from_dataset(metric_candidates_embeddings)\n    top_k_predictions, _ = self.candidates_extractor(query_embeddings)\n    \n    # the label of scalar value from input query is 1, others are 0\n    # tf.shape(positive_scores) : [batch_size, 1]\n    # tf.shape(top_k_predictions) : [batch_size, K]\n    y_labels = tf.concat(\n        [tf.ones(tf.shape(positive_scores)),\n         tf.zeros(tf.shape(top_k_predictions))],\n        axis=1)\n    y_scores = tf.concat([positive_scores, top_k_predictions], axis=1)\n\n    update_ops = []\n    for metric in self._top_k_metrics:\n      update_ops.append(metric.update_state(y_true=y_labels, y_pred=y_scores))\n\n    return tf.group(update_ops)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.069215Z","iopub.execute_input":"2022-03-27T06:38:08.069749Z","iopub.status.idle":"2022-03-27T06:38:08.080349Z","shell.execute_reply.started":"2022-03-27T06:38:08.069712Z","shell.execute_reply":"2022-03-27T06:38:08.079735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tfrs.Model 클래스를 상속받아 모델 빌드\nclass RetrievalModel(tfrs.Model):\n    def __init__(self, user_model, content_model, task):\n        super().__init__()\n        self.user_model = user_model\n        self.content_model = content_model\n        self.task = task\n#         self.metric_candidates = metric_candidates\n        self.compute_metrics = True\n    def compute_loss(self, features, training=False):\n        user_embeddings = self.user_model(features[0][0])\n        content_embeddings = self.content_model(features[0][1])\n#         metric_candidates_embeddings = self.metric_candidates.map(lambda x1, x2, x3, x4, x5, x6: self.content_model((x1, x2, x3, x4, x5, x6)),\n#                                                                   num_parallel_calls=True)\n        metric_candidates_embeddings = None\n        return self.task(user_embeddings, content_embeddings, metric_candidates_embeddings, compute_metrics=self.compute_metrics)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.081498Z","iopub.execute_input":"2022-03-27T06:38:08.081922Z","iopub.status.idle":"2022-03-27T06:38:08.102249Z","shell.execute_reply.started":"2022-03-27T06:38:08.081892Z","shell.execute_reply":"2022-03-27T06:38:08.101301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the dataset\ndef create_dataset(x, y=None, batch_size=None, shuffle=False):    \n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.map(lambda x, y: ((x[0], (read_image(x[1][0]), x[1][1], x[1][2], x[1][3], x[1][4])), y),\n                         num_parallel_calls=True)\n#     dataset = dataset.cache()\n    dataset = dataset.shuffle(int(batch_size * 2), reshuffle_each_iteration=True) if shuffle else dataset\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(2)\n    return dataset\ndef tfrs_rating_search_index(users_ref, rating_users, contents_ref=None, rating_contents=None):\n    # users_ref : indexes in rating table which are indicating the users feature in users table\n    # contents_ref : indexes in rating table which are indicating the contents feature in contents table\n    if rating_users is None:\n        tmp_user = None\n    else:\n        tmp_user = [] \n        for i in tqdm(rating_users):\n            try:\n                tmp_user.append(users_ref.get_loc(i))\n            except:\n                tmp_user.append(nan)\n                \n    if rating_contents is None:\n        tmp_content = None\n    else:\n        tmp_content = [] \n        for i in tqdm(rating_contents):\n            try:\n                tmp_content.append(contents_ref.get_loc(i))\n            except:\n                tmp_content.append(nan)\n    return tmp_user, tmp_content\ndef read_image(input_image, img_size=128, channels=3, resize=False):\n    image = tf.io.read_file(input_image)\n    image = tf.image.decode_image(image, channels=channels, dtype=tf.float32)\n    image = tf.resize(image, [img_size, img_size]) if resize else tf.ensure_shape(image, [img_size, img_size, channels])\n    return image\ndef get_top_k_accuracy(val_ds, model_retrieval, model_scann, top_k_seq):\n    # get final validation score on entire candidates from established ScaNN model\n    result_score = dict.fromkeys(top_k_seq, 0)\n    \n    query_embeddings = val_ds.map(lambda x, y: model_retrieval.user_model(x[0]))\n    candidates_embeddings = val_ds.map(lambda x, y: model_retrieval.content_model(x[1]))\n\n    positive_scores = tf.data.Dataset.zip((query_embeddings, candidates_embeddings))\n    positive_scores = positive_scores.map(lambda x1, x2: tf.reduce_sum(x1 * x2, axis=1, keepdims=True)).unbatch().as_numpy_iterator()\n    positive_scores = array([i for i in positive_scores])\n    \n    top_k_scores = val_ds.map(lambda x, y: model_scann(x[0], k=np.max(top_k_seq)-1)[0]).unbatch().as_numpy_iterator()\n    top_k_scores = array([i for i in top_k_scores])\n\n    y_labels = tf.concat(\n        [tf.ones(positive_scores.shape),\n         tf.zeros(top_k_scores.shape)],\n        axis=1)\n    y_scores = tf.concat([positive_scores, top_k_scores], axis=1)\n    \n    for i in top_k_seq:\n        tmp_metric = tf.keras.metrics.TopKCategoricalAccuracy(k=i, name=\"top_\" + str(i) + \"_acc\")\n        tmp_metric.update_state(y_true=y_labels, y_pred=y_scores)\n        result_score[i] = tmp_metric.result().numpy()\n    return result_score\nclass EpochsMetricCallback(tf.keras.callbacks.Callback):\n    def __init__(self):\n        super(EpochsMetricCallback, self).__init__()\n    def on_epoch_begin(self, epoch, logs=None):\n        self.model.compute_metrics = False\n    def on_test_begin(self, logs=None):\n        self.model.compute_metrics = True","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.103416Z","iopub.execute_input":"2022-03-27T06:38:08.103883Z","iopub.status.idle":"2022-03-27T06:38:08.124568Z","shell.execute_reply.started":"2022-03-27T06:38:08.103819Z","shell.execute_reply":"2022-03-27T06:38:08.123938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rating = rating.sample(frac=1, random_state=114).reset_index(drop=True)\n# stratVec = []\n# for i in tqdm(rating[\"article_id\"].to_array()):\n#     try:\n#         stratVec.append(content_ref.get_loc(i))\n#     except:\n#         stratVec.append(\"Unknown\")\n# stratVec = content[\"product_type_no\"].iloc[stratVec].to_array()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.127683Z","iopub.execute_input":"2022-03-27T06:38:08.12793Z","iopub.status.idle":"2022-03-27T06:38:08.135072Z","shell.execute_reply.started":"2022-03-27T06:38:08.127898Z","shell.execute_reply":"2022-03-27T06:38:08.134182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rating = rating.sample(frac=1, random_state=114).reset_index(drop=True)\n# stratVec = []\n# for i in tqdm(rating[\"article_id\"].to_array()):\n#     try:\n#         stratVec.append(content_ref.get_loc(i))\n#     except:\n#         stratVec.append(\"Unknown\")\n# stratVec = content[\"index_name\"].iloc[stratVec].to_array()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.136051Z","iopub.execute_input":"2022-03-27T06:38:08.136259Z","iopub.status.idle":"2022-03-27T06:38:08.143825Z","shell.execute_reply.started":"2022-03-27T06:38:08.136223Z","shell.execute_reply":"2022-03-27T06:38:08.142998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**get target column which is used as ranking label**","metadata":{}},{"cell_type":"code","source":"# rating[\"target\"] = rating\n# rating.drop([\"index_name\", \"cnt\"], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.145272Z","iopub.execute_input":"2022-03-27T06:38:08.145802Z","iopub.status.idle":"2022-03-27T06:38:08.152448Z","shell.execute_reply.started":"2022-03-27T06:38:08.145766Z","shell.execute_reply":"2022-03-27T06:38:08.15176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### learning parameter setting\nepochs = 20\npatient_epochs = 10\npatient_lr = 1\neta = 1e-3\nweight_decay = 1e-4\ntarget_top_k = 12\nscann_leaves = 1000\n\nfolder_path = \"./\"\ncheckpoint_filepath = './tmp_checkpoint/fold_checkpoint'\n\nn_folds = 5\nbase_train_size = 1024\ntr_size = base_train_size * 125\nbatch_size = 256\nkfolds_spliter = StratifiedShuffleSplit(n_folds, train_size=tr_size, test_size=int(tr_size * 0.5), random_state=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:33.384282Z","iopub.execute_input":"2022-03-27T06:38:33.384536Z","iopub.status.idle":"2022-03-27T06:38:33.390273Z","shell.execute_reply.started":"2022-03-27T06:38:33.384507Z","shell.execute_reply":"2022-03-27T06:38:33.389288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training - 5 Folds","metadata":{}},{"cell_type":"code","source":"# def create_raw_scann():\n#     raw_content_model = create_model_content()\n    \n#     tmp_ds = content.to_pandas()\n#     tmp_ds = tf.data.Dataset.from_tensor_slices((\n#         tmp_ds[\"article_id\"],\n#         tmp_ds[[\"product_type_no\"]],\n#         tmp_ds[[\"graphical_appearance_no\"]],\n#         tmp_ds[[\"colour_group_code\"]],\n#         tmp_ds[[\"index_name\"]])\n#     ).map(lambda x1, x2, x3, x4, x5: (read_image(x1), x2, x3, x4, x5), num_parallel_calls=True).batch(batch_size).prefetch(2)  \n#     tmp_ds = tmp_ds.map(lambda x1, x2, x3, x4, x5: raw_content_model((x1, x2, x3, x4, x5)), num_parallel_calls=True)\n    \n#     model_scann = tfrs.layers.factorized_top_k.ScaNN(\n#         num_leaves=scann_leaves,\n#         num_leaves_to_search=max(int(scann_leaves*0.2), 10),\n#         num_reordering_candidates=target_top_k*5,\n#         k=target_top_k*3\n#     )\n#     model_scann.index_from_dataset(tmp_ds)\n#     return model_scann\n# raw_scann = create_raw_scann()\nraw_scann = tf.keras.models.load_model(\"../input/h-m-recommendation-raw-scann/models_scann/raw_scann_10240/\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:08.162682Z","iopub.execute_input":"2022-03-27T06:38:08.163293Z","iopub.status.idle":"2022-03-27T06:38:08.388035Z","shell.execute_reply.started":"2022-03-27T06:38:08.16319Z","shell.execute_reply":"2022-03-27T06:38:08.387274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_fold_training(fold, train_idx, val_idx):\n        tmp_time = time()\n\n#         rating_train = rating.iloc[train_idx]\n        rating_train = train_idx\n        rating_train.dropna(inplace=True)\n        rating_train.reset_index(drop=True, inplace=True)\n        rating_train[\"customer_id\"], rating_train[\"article_id\"] = tfrs_rating_search_index(\n            user_ref, rating_train[\"customer_id\"].to_array(), content_ref, rating_train[\"article_id\"].to_array()\n        )    \n\n        print(\"complete searching index on train\")\n\n#         rating_val = rating.iloc[val_idx]\n        rating_val = val_idx\n        rating_val.dropna(inplace=True)\n        rating_val.reset_index(drop=True, inplace=True)\n        rating_val[\"customer_id\"], rating_val[\"article_id\"] = tfrs_rating_search_index(\n            user_ref, rating_val[\"customer_id\"].to_array(), content_ref, rating_val[\"article_id\"].to_array()\n        )\n        print(\"complete searching index on validation\")\n\n        minmax_scaler = MinMaxScaler()\n        user_train_feature = user.iloc[rating_train.iloc[:,0].values].to_pandas()\n        user_train_feature[[\"age\"]] = minmax_scaler.fit_transform(user_train_feature[[\"age\"]])\n        user_train_feature = (\n            user_train_feature[[\"customer_id\"]],\n            user_train_feature[[\"club_member_status\"]],\n            user_train_feature[[\"fashion_news_frequency\"]],\n            user_train_feature[[\"age_cat\"]],\n            user_train_feature[[\"FN\", \"Active\", \"age\"]]\n        )\n        scaler_list.append(minmax_scaler)\n\n        user_val_feature = user.iloc[rating_val.iloc[:,0].values].to_pandas()\n        user_val_feature[[\"age\"]] = minmax_scaler.transform(user_val_feature[[\"age\"]])\n        user_val_feature = (\n            user_val_feature[[\"customer_id\"]],\n            user_val_feature[[\"club_member_status\"]],\n            user_val_feature[[\"fashion_news_frequency\"]],\n            user_val_feature[[\"age_cat\"]],\n            user_val_feature[[\"FN\", \"Active\", \"age\"]]\n        )\n\n        content_train_feature = content.iloc[rating_train.iloc[:,1].values].to_pandas()\n        content_train_feature = (\n            content_train_feature[\"article_id\"],\n            content_train_feature[[\"product_type_no\"]],\n            content_train_feature[[\"graphical_appearance_no\"]],\n            content_train_feature[[\"colour_group_code\"]],\n            content_train_feature[[\"index_name\"]]\n        )\n        content_val_feature = content.iloc[rating_val.iloc[:,1].values].to_pandas()\n        content_val_feature = (\n            content_val_feature[\"article_id\"],\n            content_val_feature[[\"product_type_no\"]],\n            content_val_feature[[\"graphical_appearance_no\"]],\n            content_val_feature[[\"colour_group_code\"]],\n            content_val_feature[[\"index_name\"]]\n        )\n\n        train_ds = create_dataset((user_train_feature, content_train_feature), None, batch_size, True)\n        val_ds = create_dataset((user_val_feature, content_val_feature), None, batch_size, False)\n        del rating_train, rating_val, user_train_feature, user_val_feature, content_train_feature, content_val_feature\n        gc.collect()\n        \n        cb_earlyStopping = tf_callbacks.EarlyStopping(patience=patient_epochs, monitor='val_total_loss', mode='min')\n        cb_reduceLR = tf_callbacks.ReduceLROnPlateau(patience=patient_lr, factor=0.5, min_lr=1e-5)\n        cb_modelsave = tf_callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_total_loss', mode='min', save_weights_only=True, save_best_only=True)\n        cb_epochsmetric = EpochsMetricCallback()\n\n        model_user = create_model_user()\n        model_content = create_model_content()\n                \n        top_k_seq = [target_top_k, 100]\n        top_k_metrics = [tf.keras.metrics.TopKCategoricalAccuracy(k=i, name=\"top_\"+str(i)+\"_acc\") for i in top_k_seq]\n        factorized_topk = Modified_FactorizedTopK(metrics=top_k_metrics, k=max(top_k_seq), raw_scann=raw_scann)\n        \n        task = Modified_Retrieval(\n            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM),\n            metrics=factorized_topk,\n#             operation like softmax temperature\n            temperature=2,\n            loss_topk_mean=4\n        )\n\n        model_retrieval = RetrievalModel(model_user, model_content, task)\n        model_retrieval.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=eta)\n#             optimizer=tfa.optimizers.AdamW(learning_rate=eta, weight_decay=weight_decay)\n        )\n\n        print(\"start training\")\n        model_history = model_retrieval.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=0,\n                    callbacks=[cb_reduceLR, cb_earlyStopping, cb_modelsave, cb_epochsmetric, TqdmCallback(verbose=1)])\n        model_retrieval.load_weights(checkpoint_filepath)\n        print(\"end training\") \n        model_history_list.append(model_history)\n\n        print(\"Fold \" + str(fold) + \" Time (minutes) : \", round((time() - tmp_time) / 60, 3))\n        return model_retrieval","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:19.460411Z","iopub.execute_input":"2022-03-27T06:38:19.461048Z","iopub.status.idle":"2022-03-27T06:38:19.485419Z","shell.execute_reply.started":"2022-03-27T06:38:19.46101Z","shell.execute_reply":"2022-03-27T06:38:19.484454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_scann_model(fold, model_retrieval, candidates_corpus):\n    print(\"start building search model\")\n    model_scann = tfrs.layers.factorized_top_k.ScaNN(\n        model_retrieval.user_model,\n        num_leaves=scann_leaves,\n        num_leaves_to_search=max(int(scann_leaves*0.2), 10),\n        num_reordering_candidates=target_top_k*5,\n        k=scann_output_top_k\n    )\n\n    model_scann.index_from_dataset(\n        candidates_corpus.map(lambda x1, x2, x3, x4, x5: model_retrieval.content_model((x1, x2, x3, x4, x5)), num_parallel_calls=True)\n    )\n    # register the model shape\n    model_scann((array([[0]]), array([[\"0\"]]), array([[\"0\"]]), array([[0.0]]), array([[0.0, 0.0, 0.0]])))\n\n#     fold_top_k_scores.append(get_top_k_accuracy(val_ds, model_retrieval, model_scann, top_k_seq)[target_top_k])\n\n    model_scann_path = \"./models_scann/fold_\" + str(fold) + \"/\"\n    tf.keras.models.save_model(\n        model_scann,\n        model_scann_path,\n        options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n    )\n    print(\"end building search model and save to local\")\n    return model_scann_path","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:38:21.944697Z","iopub.execute_input":"2022-03-27T06:38:21.945371Z","iopub.status.idle":"2022-03-27T06:38:21.953138Z","shell.execute_reply.started":"2022-03-27T06:38:21.945334Z","shell.execute_reply":"2022-03-27T06:38:21.952434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train timeseries : 2018-09 ~ 2019-09**\n\n**Validation timeseries : 2019-10 ~ 2020-09**","metadata":{}},{"cell_type":"code","source":"model_list = []\nmodel_history_list = []\nscaler_list = []\nfold_top_k_scores = []\nmodel_name = \"tfrs\"\nscann_output_top_k = 128\nseed_everything()\n\n# fold training\n# for fold, (train_idx, val_idx) in enumerate(kfolds_spliter.split(range(rating.shape[0]), stratVec)):\nfor fold in range(n_folds):\n# for fold, (train_idx, val_idx) in enumerate(kfolds_spliter.split(range(rating.shape[0]))):\n    print(\"\\n===== Fold \", fold, \"=====\\n\")\n    mem_fold_start = memory_usage()\n    # real data frame\n    _, train_idx = tts(rating[train_mask], test_size=tr_size, stratify=stratVec[train_mask], random_state=fold+100)\n    _, val_idx = tts(rating[~train_mask], test_size=int(tr_size * 0.5), stratify=stratVec[~train_mask], random_state=fold+101)\n\n    model_list.append(do_fold_training(fold, train_idx, val_idx))\n#     model_list.append(do_fold_training(fold, rating.iloc[train_idx], rating.iloc[val_idx]))\n    tf.keras.backend.clear_session()\n    gc.collect()\n    mem_fold_end = memory_usage()\n    print(\"@Memory leaked :\", round(mem_fold_end - mem_fold_start, 3))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T06:48:15.804382Z","iopub.execute_input":"2022-03-27T06:48:15.804648Z","iopub.status.idle":"2022-03-27T06:56:03.26161Z","shell.execute_reply.started":"2022-03-27T06:48:15.804618Z","shell.execute_reply":"2022-03-27T06:56:03.260488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_list = []\n# model_history_list = []\n# scaler_list = []\n# fold_top_k_scores = []\n# model_name = \"tfrs\"\n# scann_output_top_k = 128\n# seed_everything()\n\n# # fold training\n# for fold, (train_idx, val_idx) in enumerate(kfolds_spliter.split(range(rating.shape[0]), stratVec)):\n# # for fold, (train_idx, val_idx) in enumerate(kfolds_spliter.split(range(rating.shape[0]))):\n#     print(\"\\n===== Fold \", fold, \"=====\\n\")\n#     mem_fold_start = memory_usage()\n#     model_list.append(do_fold_training(fold, train_idx, val_idx))\n#     tf.keras.backend.clear_session()\n#     gc.collect()\n#     mem_fold_end = memory_usage()\n#     print(\"@Memory leaked :\", round(mem_fold_end - mem_fold_start, 3))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T02:47:46.168174Z","iopub.execute_input":"2022-03-27T02:47:46.16845Z","iopub.status.idle":"2022-03-27T03:03:41.736279Z","shell.execute_reply.started":"2022-03-27T02:47:46.168415Z","shell.execute_reply":"2022-03-27T03:03:41.735528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del rating; gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:03:41.740251Z","iopub.execute_input":"2022-03-27T03:03:41.740497Z","iopub.status.idle":"2022-03-27T03:03:42.020117Z","shell.execute_reply.started":"2022-03-27T03:03:41.740469Z","shell.execute_reply":"2022-03-27T03:03:42.01938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_scann_path = []\n\ncontent = tf.data.Dataset.from_tensor_slices((\n        content[\"article_id\"].to_pandas(),\n        content[[\"product_type_no\"]].to_pandas(),\n        content[[\"graphical_appearance_no\"]].to_pandas(),\n        content[[\"colour_group_code\"]].to_pandas(),\n        content[[\"index_name\"]].to_pandas())\n).map(lambda x1, x2, x3, x4, x5: (read_image(x1), x2, x3, x4, x5), num_parallel_calls=True).batch(batch_size).prefetch(2)\n\nfor fold in range(n_folds):\n    model_scann_path.append(get_scann_model(fold, model_list[fold], content))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:03:42.021627Z","iopub.execute_input":"2022-03-27T03:03:42.022159Z","iopub.status.idle":"2022-03-27T03:04:28.40665Z","shell.execute_reply.started":"2022-03-27T03:03:42.022115Z","shell.execute_reply":"2022-03-27T03:04:28.405708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in fold_top_k_scores:\n#     print(\"fold top k score :\", i)\n# print(\"fold average score :\", np.mean(fold_top_k_scores))","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:04:28.410524Z","iopub.execute_input":"2022-03-27T03:04:28.410736Z","iopub.status.idle":"2022-03-27T03:04:28.416911Z","shell.execute_reply.started":"2022-03-27T03:04:28.410708Z","shell.execute_reply":"2022-03-27T03:04:28.416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_history(histories, key='binary_crossentropy'):\n  plt.figure(figsize=(16,10))\n\n  for name, history in histories:\n    val = plt.plot(history.epoch, history.history['val_'+key],\n                   '--', label=name.title()+' Val')\n#     plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n#              label=name.title()+' Train')\n\n  plt.xlabel('Epochs')\n  plt.ylabel(key.replace('_',' ').title())\n  plt.legend()\n\n  plt.xlim([0,max(history.epoch)])\n\nplt_input = [(\"fold_\" + str(i), j) for i, j in enumerate(model_history_list)]","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:04:28.418278Z","iopub.execute_input":"2022-03-27T03:04:28.418857Z","iopub.status.idle":"2022-03-27T03:04:28.720952Z","shell.execute_reply.started":"2022-03-27T03:04:28.418816Z","shell.execute_reply":"2022-03-27T03:04:28.720198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(plt_input, key=\"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:08:10.749949Z","iopub.execute_input":"2022-03-27T03:08:10.750163Z","iopub.status.idle":"2022-03-27T03:08:11.121111Z","shell.execute_reply.started":"2022-03-27T03:08:10.750137Z","shell.execute_reply":"2022-03-27T03:08:11.120242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(plt_input, key=\"top_12_acc\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(plt_input, key=\"top_100_acc\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del content; gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:04:28.723471Z","iopub.execute_input":"2022-03-27T03:04:28.723886Z","iopub.status.idle":"2022-03-27T03:04:29.174992Z","shell.execute_reply.started":"2022-03-27T03:04:28.723843Z","shell.execute_reply":"2022-03-27T03:04:29.174263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"rating_test = cudf.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv\", dtype=[\"object\"])\nrating_test_submission = rating_test.copy()\nrating_test[\"customer_id\"] = rating_test[\"customer_id\"].str[-16:].str.hex_to_int().astype('int64')\nrating_test[\"customer_id\"], _ = tfrs_rating_search_index(user_ref, rating_test[\"customer_id\"].to_array())\nscore_counter = [Counter() for _ in range(rating_test.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:04:29.17648Z","iopub.execute_input":"2022-03-27T03:04:29.176955Z","iopub.status.idle":"2022-03-27T03:04:40.108697Z","shell.execute_reply.started":"2022-03-27T03:04:29.176914Z","shell.execute_reply":"2022-03-27T03:04:40.107815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_inference(fold):\n    print(\"=== start fold_\" + str(fold) + \" inference ===\")\n    fold_time = time()\n    model_loaded = tf.keras.models.load_model(model_scann_path[fold])\n    rating_test_scaled = user.iloc[rating_test.iloc[:,0].values].to_pandas()\n    \n    rating_test_scaled[[\"age\"]] = scaler_list[fold].transform(rating_test_scaled[[\"age\"]])\n    scores_table, labels_table = model_loaded((rating_test_scaled[[\"customer_id\"]],\n                                              rating_test_scaled[[\"club_member_status\"]].astype(dtype=\"object\"),\n                                              rating_test_scaled[[\"fashion_news_frequency\"]].astype(dtype=\"object\"),\n                                              rating_test_scaled[[\"age_cat\"]].astype(dtype=\"float32\"),\n                                              rating_test_scaled[[\"FN\", \"Active\", \"age\"]].astype(dtype=\"float32\")))\n    \n    scores_table = scores_table.numpy() / n_folds\n    labels_table = labels_table.numpy()\n    print(\"start update score on samples\")\n    tmp_time = time()\n    get_score_counter(score_counter, scores_table, labels_table, 1024)\n    print(\"end update score on samples :\", round(time() - tmp_time))\n    print(\"=== end fold_\" + str(fold) + \" inference time :\", round(time() - fold_time, 3), \"===\")\ndef get_score_counter(counter_obj, scores_table, labels_table, batch_size=1024):\n    for idx, (scores, labels) in enumerate(tqdm(zip(scores_table, labels_table))):\n        tmp_counter = counter_obj[idx]\n        tmp_update_dic = {}\n        tmp_batch_cnt = 0\n        tmp_batch_size = batch_size\n        for i, j in zip(content_ref[labels], scores):\n            tmp_update_dic[i] = j\n            if tmp_batch_cnt >= tmp_batch_size:\n                tmp_counter.update(tmp_update_dic)\n                tmp_batch_cnt = 0\n                tmp_update_dic = {}\n            else:\n                tmp_batch_cnt += 1\n        tmp_counter.update(tmp_update_dic)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:04:40.109955Z","iopub.execute_input":"2022-03-27T03:04:40.110207Z","iopub.status.idle":"2022-03-27T03:04:40.123719Z","shell.execute_reply.started":"2022-03-27T03:04:40.110174Z","shell.execute_reply":"2022-03-27T03:04:40.122767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(n_folds):\n    memory_usage()\n    do_inference(fold)\n    tf.keras.backend.clear_session()\n    gc.collect()\n    memory_usage()","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:04:40.125257Z","iopub.execute_input":"2022-03-27T03:04:40.125836Z","iopub.status.idle":"2022-03-27T03:07:36.929207Z","shell.execute_reply.started":"2022-03-27T03:04:40.125793Z","shell.execute_reply":"2022-03-27T03:07:36.92839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_labels = []\nfor i in tqdm(range(rating_test_submission.shape[0])):\n    tmp_labels.append(\" \".join([j[0] for j in score_counter[i].most_common(target_top_k)]))\nrating_test_submission.iloc[:,1] = tmp_labels\nrating_test_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-27T03:07:36.934893Z","iopub.execute_input":"2022-03-27T03:07:36.935138Z","iopub.status.idle":"2022-03-27T03:08:10.742351Z","shell.execute_reply.started":"2022-03-27T03:07:36.935111Z","shell.execute_reply":"2022-03-27T03:08:10.741546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}