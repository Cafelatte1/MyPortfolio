{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #필요한 파일 인스톨\n",
    "# !pip install gym pyvirtualdisplay\n",
    "# # • apt-get install -y xvfb python-opengl ffmpeg\n",
    "# # •\n",
    "# # apt-get update\n",
    "# # • apt-get install cmake\n",
    "# !pip install --upgrade setuptools\n",
    "# !pip install ez_setup\n",
    "# !pip install gym[atari]\n",
    "\n",
    "# !pip install box2d-py\n",
    "# !pip install gym[Box_2D]\n",
    "# !pip install pyglet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random as rnd\n",
    "from gym import logger as gym_logger\n",
    "gym_logger.set_level(40)\n",
    "from gym.wrappers.record_video import RecordVideo\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_vedio():\n",
    "    mp4list = glob.glob(\"video/*.mp4\")\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, \"r+w\").read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data=\"''''\".fotmat(encoded.decode(\"ascii\"))))\n",
    "    else:\n",
    "        print(\"error\")\n",
    "    \n",
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, \"./video\", episode_trigger=lambda x: True)\n",
    "    env.reset()\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP with creating video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = wrap_env(gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\"))\n",
    "\n",
    "step = 0\n",
    "score = 0\n",
    "\n",
    "while True:\n",
    "    # random sampling action\n",
    "    action = env.action_space.sample()\n",
    "    # get result from action\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    # terminated : 목표에 도달했는지에 대한 여부 \n",
    "    # truncated : step에 도달했는지에 대한 여부\n",
    "    score += reward\n",
    "    step += 1\n",
    "    if (terminated or truncated) or (step > 200):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDP with DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
    "\n",
    "n_steps = 1000\n",
    "n_scores = []\n",
    "training_data = []\n",
    "accepted_scores = []\n",
    "required_score = -1 * (n_steps * 1) + (n_steps * 1 * 1)\n",
    "required_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\class_reinforcement_learning\\.venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "  0%|          | 23/10000 [01:19<9:32:59,  3.45s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    env.reset()\n",
    "    step = 0\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    previous_obs = None\n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        # save T-1 th position & T th action\n",
    "        if previous_obs is not None:\n",
    "            game_memory.append([previous_obs, action])\n",
    "        previous_obs = obs\n",
    "        # calculating reward from policy\n",
    "        if obs[0] > -0.2:\n",
    "            reward = 1\n",
    "        score += reward\n",
    "        if (terminated or truncated) or (step > n_steps):\n",
    "            break\n",
    "        else:\n",
    "            step += 1\n",
    "    # save raw score value\n",
    "    n_scores.append(score)\n",
    "    if score > required_score:\n",
    "        # save best case score value\n",
    "        accepted_scores.append(score)\n",
    "        # save best case parameter for decision making\n",
    "        for data in game_memory:\n",
    "            training_data.append(data)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scores = np.array(n_scores)\n",
    "# print(n_scores.mean())\n",
    "# print(accepted_scores)\n",
    "\n",
    "train_x = np.array([i[0] for i in training_data]).reshape(-1, 2)\n",
    "train_y = np.array([i[1] for i in training_data]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "40/40 [==============================] - 2s 5ms/step - loss: 1.0944 - accuracy: 0.3522 - val_loss: 1.1183 - val_accuracy: 0.3250\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0939 - accuracy: 0.3774 - val_loss: 1.1185 - val_accuracy: 0.3250\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0939 - accuracy: 0.3774 - val_loss: 1.1178 - val_accuracy: 0.3250\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0936 - accuracy: 0.3774 - val_loss: 1.1173 - val_accuracy: 0.3250\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 1.0934 - accuracy: 0.3774 - val_loss: 1.1168 - val_accuracy: 0.3250\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(4, activation=\"relu\", input_shape=(2,)),\n",
    "    layers.Dense(3, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "filename = \"model_rf.h5\"\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=5, batch_size=4, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
