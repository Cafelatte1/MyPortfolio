{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로우 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중식계 컬럼 정리\n",
    "년 category\n",
    "월 category\n",
    "주 category\n",
    "요일 category\n",
    "공휴일전후 binary\n",
    "frequency_sin_year\tnumeric\t< np.sin((2 * np.pi) * 현재날짜_to초/하루_to초) > \n",
    "frequency_cos_year\tnumeric\t< np.cos((2 * np.pi) * 현재날짜_to초/하루_to초) > \n",
    "\n",
    "# 년월일주, 계절\n",
    "# 1. 일자 관련 컬럼\n",
    "train_x['년'] = train_x['일자'].dt.year\n",
    "train_x['월'] = train_x['일자'].dt.month\n",
    "train_x['일'] = train_x['일자'].dt.day\n",
    "train_x['주'] = train_x['일자'].dt.isocalendar().week\n",
    "train_x['요일'] = train_x['일자'].dt.weekday\n",
    "# 계절\n",
    "season = []\n",
    "for i in train_x['월']:\n",
    "    if i in [3,4,5]:\n",
    "        season.append(0)\n",
    "    elif i in [6,7,8]:\n",
    "        season.append(1)\n",
    "    elif i in [9,10,11]:\n",
    "        season.append(2)\n",
    "    else:\n",
    "        season.append(3)\n",
    "train_x['계절'] = season\n",
    "weekofmonth = []\n",
    "for i in train_x[\"주\"]:\n",
    "    weekofmonth.append((i-1) % 4)\n",
    "\n",
    "train_x[\"before_2020\"] = [1 if i >= 2020 else 0 for i in train_x['년']]\n",
    "\n",
    "# ===== 공휴일전후여부 컬럼추가 (공휴일전후:1 / 공휴일전후아님:0) =====\n",
    "a = []\n",
    "for n in range(len(df_train)):\n",
    "    if n==0:   #첫행은 앞의 행이 없으므로, ‘뒷행-1’값이랑만 일치하면 평일\n",
    "        if (df_train.iloc[n,1]) == (df_train.iloc[n+1,1]-1):\n",
    "            a.append(0)\n",
    "        else:\n",
    "            a.append(1)\n",
    "        \n",
    "    elif n==len(df_train)-1:   #마지막행은 뒷 행 없음, ‘앞행+1’ 값만 일치하면 평일\n",
    "        if (df_train.iloc[n,1] == (df_train.iloc[n-1,1]+1)):\n",
    "            a.append(0)\n",
    "        else:\n",
    "            a.append(1)\n",
    "            \n",
    "    elif df_train.iloc[n,1] == 0:   #월요일(0)의 경우, ‘뒷행-1’값은 0, ‘앞행+1’값은 5여야 평일\n",
    "        if (df_train.iloc[n+1,1]-1 == 0) and (df_train.iloc[n-1,1]+1 == 5):\n",
    "            a.append(0)\n",
    "        else:\n",
    "            a.append(1)\n",
    "            \n",
    "    elif df_train.iloc[n,1] == 4:   #금요일(4)의 경우, ‘앞행+1’값은 4, ‘뒷행-1’ 값은 -1이어야 평일\n",
    "        if (df_train.iloc[n+1,1] -1 == -1) and (df_train.iloc[n-1,1]+1 == 4):\n",
    "            a.append(0)\n",
    "        else:\n",
    "            a.append(1)\n",
    "        \n",
    "    elif ((df_train.iloc[n,1] == (df_train.iloc[n-1,1]+1)) and (df_train.iloc[n,1]) == (df_train.iloc[n+1,1]-1)):    #월,금 아니면(1,2,3) 앞행+1값과 뒷행-1값은 모두 일치해야 평일.\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "df_train[\"공휴일여부\"] = a\n",
    "train_ln = df_train.copy()\n",
    "train_ln.head(10)\n",
    "\n",
    "# 주기성 파생변수 생성\n",
    "time_zero = datetime(1970, 1, 1, 0, 0, 0)\n",
    "day_to_sec = 24*60*60\n",
    "year_to_sec = (365.2425)*day_to_sec\n",
    "frequency_sin_year = []\n",
    "frequency_cos_year = []\n",
    "for i in train_x[\"일자\"]:\n",
    "    time_to_sec = i.to_pydatetime()\n",
    "    time_interval = (time_to_sec - time_zero).total_seconds()\n",
    "    frequency_sin_year.append(np.sin((time_interval / year_to_sec) * 2 * np.pi))\n",
    "    frequency_cos_year.append(np.cos((time_interval / year_to_sec) * 2 * np.pi))\n",
    "\n",
    "train_x[\"frequency_sin_year\"] = frequency_sin_year\n",
    "train_x[\"frequency_cos_year\"] = frequency_cos_year\n",
    "# train_x[\"frequency_sin_year\"].plot()\n",
    "# train_x[\"frequency_cos_year\"].plot()\n",
    "\n",
    "# 본사정원수 numeric\n",
    "# 본사휴가자수 numeric\n",
    "# 본사출장자수 numeric\n",
    "# 본사시간외근무명령서승인건수 numeric\n",
    "# 현본사소속재택근무자수 numeric\n",
    "# 식사가용인원 numeric (본사정원수-(본사휴가자수+본사출장자수+현본사소속재택근무자수)\n",
    "# 야근비율 numeric (본사시간외근무명령서승인건수 / 식사가용인원)\n",
    "# 휴가비율 numeric (본사휴가자수 / 본사정원수)\n",
    "# 출장비율 numeric (본사출장자수 / 본사정원수)\n",
    "# 재택비율 numeric (현본사소속재택근무자수 / 본사정원수)\n",
    "\n",
    "# 식사 가용인원 파생변수 생성 \n",
    "df_train['식사가용인원'] =df_train['본사정원수']-(df_train['본사휴가자수']+df_train['본사출장자수']+df_train['현본사소속재택근무자수']).astype(int)\n",
    "df_train['야근비율'] = round(df_train['본사시간외근무명령서승인건수'] / df_train['식사가용인원'],3).astype(float)\n",
    "df_train['휴가비율'] = round(df_train['본사휴가자수'] / df_train['본사정원수'],3).astype(float)\n",
    "df_train['출장비율'] = round(df_train['본사출장자수'] / df_train['본사정원수'],3).astype(float)\n",
    "df_train['재택비율'] = round(df_train['현본사소속재택근무자수'] / df_train['본사정원수'],3).astype(float)\n",
    "df_train.head()\n",
    "\n",
    "df_train = read_csv(\"./2차프로젝트/original/train.csv\", parse_dates=[\"일자\"])\n",
    "df_train['년'] = df_train['일자'].dt.year\n",
    "df_train['월'] = df_train['일자'].dt.month\n",
    "df_train['일'] = df_train['일자'].dt.day\n",
    "df_train['주'] = df_train['일자'].dt.week\n",
    "df_train['요일'] = df_train['일자'].dt.weekday\n",
    "\n",
    "# ===== 메뉴 embedding =====\n",
    "# 일별 점심메뉴를 작은 리스트로 갖고 있는 2중 리스트 (lunch_train) 만들기\n",
    "lunch_train = []\n",
    "for day in range(len(df_train)):\n",
    "    tmp = df_train.loc[day, \"중식메뉴\"].split(' ')  # 공백으로 문자열 구분\n",
    "    print(tmp)\n",
    "    tmp = ' '.join(tmp).split()  # 빈 원소 삭제\n",
    "    print(tmp)\n",
    "\n",
    "    search = '('  # 원산지 정보는 삭제\n",
    "    for menu in tmp:\n",
    "        if search in menu:\n",
    "            tmp.remove(menu)\n",
    "    lunch_train.append(tmp)\n",
    "lunch_train # 데이터 확인\n",
    "\n",
    "# lunch train data에 메뉴명별 칼럼 만들기 (밥, 국, 반찬1-3)\n",
    "menu_len_list = []\n",
    "bob = []; gook = []; jm = []; side1 = []; side2 = []; kimchi = []; dessert = [];\n",
    "for i, day_menu in enumerate(lunch_train):\n",
    "    bob_tmp = day_menu[0]; bob.append(bob_tmp)\n",
    "    gook_tmp = day_menu[1]; gook.append(gook_tmp)\n",
    "    jm_tmp = day_menu[2]; jm.append(jm_tmp)\n",
    "    side1_tmp = day_menu[3]; side1.append(side1_tmp)\n",
    "    side2_tmp = day_menu[4]; side2.append(side2_tmp)\n",
    "    if i < 1067:\n",
    "        kimchi_tmp = day_menu[-1]; kimchi.append(kimchi_tmp)\n",
    "        dessert_tmp = day_menu[-2]; dessert.append(dessert_tmp)\n",
    "    else:\n",
    "        kimchi_tmp = day_menu[-2]; kimchi.append(kimchi_tmp)\n",
    "        dessert_tmp = day_menu[-1]; dessert.append(dessert_tmp)\n",
    "    menu_len_list.append([len(day_menu),i])\n",
    "menu_len_list # 데이터 확인\n",
    "train_ln = df_train.copy()\n",
    "train_ln['밥'] = bob\n",
    "train_ln['국'] = gook\n",
    "train_ln['메인메뉴'] = jm; train_ln['반찬1'] = side1; train_ln['반찬2'] = side2\n",
    "train_ln['김치'] = kimchi\n",
    "train_ln['사이드'] = dessert\n",
    "train_ln.info()\n",
    "train_ln.head(10)\n",
    "\n",
    "#========특식 컬럼 추가 (쌀밥이 아닌 비빔밥 등의 특식 메뉴 제공)============\n",
    "jmt = []; #특식 컬럼 변수명 지정\n",
    "for i in train_ln['밥']:\n",
    "    if '쌀밥' not in i:\n",
    "        jmt.append(1) #’쌀밥’이라는 단어가 ‘밥’ 컬럼에 있는 경우 1을 반환\n",
    "    else:\n",
    "        jmt.append(0) #있는 경우 0을 반환\n",
    "train_ln['특식'] = jmt #따라서 특식에 쌀밥이 아닌 다른 밥메뉴들이 들어갈 경우 1을 반환\n",
    "\n",
    "#========신메뉴 컬럼 추가 (신메뉴가 수요에 미치는 영향을 파악) (중식)===========\n",
    "new = []\n",
    "for i in range(len(train_ln)): #행 길이 만큼 반복\n",
    "    if 'New' in train_ln.loc[i, '중식메뉴']: #중식메뉴 컬럼에 ‘New’라는 문자열이 있으면\n",
    "            new.append(1) #1을 반환\n",
    "    else:\n",
    "            new.append(0) #아님 0을 반환\n",
    "train_ln['신메뉴'] = new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기상청 외부데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자 -> data_x : iterable, col_names: 찾을 리스트\n",
    "# 리턴 -> 인덱스 위치를 담은 리스트 \n",
    "# col_names 를 인자로 받아서 data_x 에 어디 있는지 인덱스를 찾습니다\n",
    "def findIdx(data_x, col_names):\n",
    "    return [int(i) for i, j in enumerate(data_x) if j in col_names]\n",
    "\n",
    "# 기상청 외부데이터 활용\n",
    "# 점심 11,12,13 저녁 17,18,19\n",
    "forecast = read_csv(\"./2차프로젝트/2016_2021_진주_기온강수.csv\", encoding=\"euc-kr\")\n",
    "forecast[\"강수량\"].fillna(0, inplace=True)\n",
    "forecast.isna().sum()\n",
    "\n",
    "findIdx(forecast[\"기온\"].isna(), [True])\n",
    "forecast[\"기온\"][40765:40768]\n",
    "forecast[\"기온\"][40766] = forecast[\"기온\"][40765:40768].mean()\n",
    "forecast[\"기온\"][40768:40771]\n",
    "forecast[\"기온\"][40769] = forecast[\"기온\"][40768:40771].mean()\n",
    "forecast.isna().sum().sum()\n",
    "train_x.isna().sum().sum()\n",
    "\n",
    "# forecast\n",
    "tmp_list = []\n",
    "for i in forecast[\"일시\"]:\n",
    "    if (\"11:00\" in i) or (\"12:00\" in i) or (\"13:00\" in i):\n",
    "        tmp_list.append(True)\n",
    "    else:\n",
    "        tmp_list.append(False)\n",
    "\n",
    "forecast = forecast[tmp_list]\n",
    "forecast[\"일시\"] = pd.to_datetime(forecast[\"일시\"])\n",
    "forecast.set_index(\"일시\", inplace=True)\n",
    "\n",
    "forecast.isna().sum().sum()\n",
    "\n",
    "forecast.resample(\"1D\").mean().isna().sum()\n",
    "\n",
    "# 10:16 사이에 데이터 없음\n",
    "# 8:15 사이에 데이터 없음\n",
    "# round(forecast.resample(\"1D\").mean()[\"기온\"], 1)\n",
    "# forecast.resample(\"1D\").max()[\"강수량\"]\n",
    "forecast_new = pd.concat([round(forecast.resample(\"1D\").mean()[\"기온\"], 1), forecast.resample(\"1D\").max()[\"강수량\"]], axis=1)\n",
    "forecast_new.isna().sum()\n",
    "\n",
    "forecast_new.reset_index(\"일시\", inplace=True)\n",
    "forecast_new.columns = [\"일자\", \"기온\", \"강수량\"]\n",
    "\n",
    "# train_x = pd.merge(train_x, forecast_new, left_on=\"일자\")\n",
    "train_x = pd.merge(train_x, forecast_new, how=\"left\", on=\"일자\")\n",
    "train_x.isna().sum().sum()\n",
    "# 기온 및 강수량의 11~13 시 결측치는 전날 기온 및 강수량으로 대체하였다\n",
    "train_x[\"기온\"][findIdx(train_x[\"기온\"].isna(), [True])[0]] = train_x[\"기온\"][findIdx(train_x[\"기온\"].isna(), [True])[0]-1]\n",
    "train_x[\"강수량\"][findIdx(train_x[\"강수량\"].isna(), [True])[0]] = 0\n",
    "train_x.isna().sum().sum()\n",
    "\n",
    "train_x[\"강수여부\"] = [1 if i>0 else 0 for i in train_x[\"강수량\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
