{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jobknow_recommendation.ipynb","provenance":[],"collapsed_sections":["R-cueubJN45-","u94f-9W1qWgs"],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyMUfct7HFMOCyZ76uxKNaky"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"266eab0221de4f00b9af6e909fbe27e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ef1123b29c1b4db5a7ddcbef4ddd2450","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f106752c55348a39e7b39b566da9cde","IPY_MODEL_191781a442ca4ccba2ad99bc9330fc75","IPY_MODEL_18eb0a20b2c3431f8a93a6b72bea408d"]}},"ef1123b29c1b4db5a7ddcbef4ddd2450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f106752c55348a39e7b39b566da9cde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab8d217706ef4cca847e3a0b2e98f5de","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 38%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7e3bf85e7b0408b804edd71791fbd67"}},"191781a442ca4ccba2ad99bc9330fc75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4642344519be42cab06d22579424c8d4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":38,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04d820ef6aad4665aee0dba52bb62398"}},"18eb0a20b2c3431f8a93a6b72bea408d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5d44299c12d44f7fb667f625a41159d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 38/100 [02:12&lt;03:28,  3.36s/epoch, loss=5.68, f1=0.738, val_loss=5.84, val_f1=0.405, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0dc257e8d854ebd9998b4c7cbb1f2f2"}},"ab8d217706ef4cca847e3a0b2e98f5de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e7e3bf85e7b0408b804edd71791fbd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4642344519be42cab06d22579424c8d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"04d820ef6aad4665aee0dba52bb62398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d44299c12d44f7fb667f625a41159d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b0dc257e8d854ebd9998b4c7cbb1f2f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6dd9acae06154778a37fce5f7cf90846":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_243b8426e7924e8b822617944cf15d63","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fa906a4652a7432b802f087c6e875edd","IPY_MODEL_14e14e2473774b0bbdd590e7f2b2b3a7"]}},"243b8426e7924e8b822617944cf15d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fa906a4652a7432b802f087c6e875edd":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_c60f8dc7fed94bbda9100ec58dcefe62","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.68MB of 0.68MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_817b7e2c23a94d0ab7388ce0d80b716e"}},"14e14e2473774b0bbdd590e7f2b2b3a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1ef8954fcde94d2a86d5466009bf7d43","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14f55666656f4a659a759b53d3950af0"}},"c60f8dc7fed94bbda9100ec58dcefe62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"817b7e2c23a94d0ab7388ce0d80b716e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ef8954fcde94d2a86d5466009bf7d43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"14f55666656f4a659a759b53d3950af0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10cd30555e5c4862bf11fcada4652779":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c25c382b90744c0ca3282a7670bfe12f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2698bf3995cc40dcb3a4da97e40629f0","IPY_MODEL_91deb63e220b435ba11c333ffd43bcb7","IPY_MODEL_05d827240a554434b67a7bf4124c7528"]}},"c25c382b90744c0ca3282a7670bfe12f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2698bf3995cc40dcb3a4da97e40629f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_89f6381fa5ca4507b1799ccb448b16f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 42%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a4ca70c862446cd8d5f41764000bd57"}},"91deb63e220b435ba11c333ffd43bcb7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9425d0d96ae24b318f21138fc5672843","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":42,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7284ca83cd04f4d9a30f244399a5921"}},"05d827240a554434b67a7bf4124c7528":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_de1bef17884440fa963ca3bc0a1ec1b4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 42/100 [02:31&lt;03:21,  3.47s/epoch, loss=5.84, f1=0.763, val_loss=5.96, val_f1=0.414, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6eac27c2bb44bcc89db5a6b2389e15c"}},"89f6381fa5ca4507b1799ccb448b16f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6a4ca70c862446cd8d5f41764000bd57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9425d0d96ae24b318f21138fc5672843":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f7284ca83cd04f4d9a30f244399a5921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de1bef17884440fa963ca3bc0a1ec1b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e6eac27c2bb44bcc89db5a6b2389e15c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01d128a0bad7479591fc552f04b37bff":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d780bdf7ea0c4255b2168b378a3b092c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_567b39286a9b4181848f390888a9588e","IPY_MODEL_fd0795eab1484476ad85e4351c44173c"]}},"d780bdf7ea0c4255b2168b378a3b092c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"567b39286a9b4181848f390888a9588e":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_b32c4490e4554a16838d6f67ede6c573","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.73MB of 0.73MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1129f8f45f243af9fe580983e929922"}},"fd0795eab1484476ad85e4351c44173c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8e7f060e61744e0cad2a83f11c5d078c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ae46dc727114ee2bbb259f52a57e5c4"}},"b32c4490e4554a16838d6f67ede6c573":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a1129f8f45f243af9fe580983e929922":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e7f060e61744e0cad2a83f11c5d078c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6ae46dc727114ee2bbb259f52a57e5c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a9eabe130f14d0194df5cfb266616fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97d0d69e7dd24638a852b703cf193525","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_46e7be95151f4ad6afe15ee8032e03ad","IPY_MODEL_b04434deff784eb38c03ebecdb462722","IPY_MODEL_5d02ac9e7ab54ebe818ee82d8fdb1d56"]}},"97d0d69e7dd24638a852b703cf193525":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46e7be95151f4ad6afe15ee8032e03ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_593c8d83bcba4dc8af38aaf6d95a8667","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 43%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0adacc0aa1d4b6f935745178dfe46e5"}},"b04434deff784eb38c03ebecdb462722":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9321fa7955d04a2d82d32ad479cc225b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":43,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4778eee479542d3b7d93c0878a5d43f"}},"5d02ac9e7ab54ebe818ee82d8fdb1d56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_113e6a33a57e45f9975c459a55b59641","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 43/100 [02:34&lt;03:15,  3.43s/epoch, loss=5.98, f1=0.738, val_loss=6.06, val_f1=0.385, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5645584eab4a47b4b9afa90113320921"}},"593c8d83bcba4dc8af38aaf6d95a8667":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0adacc0aa1d4b6f935745178dfe46e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9321fa7955d04a2d82d32ad479cc225b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d4778eee479542d3b7d93c0878a5d43f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"113e6a33a57e45f9975c459a55b59641":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5645584eab4a47b4b9afa90113320921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97eedb95cfd8471dbd0afb82d003a6c4":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f7ede8b0f425449c8e94f31a67f98c3c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6034584e940e4470add0a48703f24982","IPY_MODEL_b940ccc1448049358437a1c4d25200b3"]}},"f7ede8b0f425449c8e94f31a67f98c3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6034584e940e4470add0a48703f24982":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_d42584c3fd884bc1b0edcbe262872cb9","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.74MB of 0.74MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_efed9f858b32446e99c54706861c7009"}},"b940ccc1448049358437a1c4d25200b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a7533f94baca476cb404575dcb0f6a3e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_15120b138a7346be82aeac21a6eeaec6"}},"d42584c3fd884bc1b0edcbe262872cb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"efed9f858b32446e99c54706861c7009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7533f94baca476cb404575dcb0f6a3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"15120b138a7346be82aeac21a6eeaec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d4de893122542f7963e763ce1b75c26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e9bf1adbf6a2484188a692417327ad32","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_baefe5abfd7543489a4f926873957dca","IPY_MODEL_9e5c916b3cd04e47843cf78fae13416d","IPY_MODEL_c148b6fad3d44b33a0946974f3a463d2"]}},"e9bf1adbf6a2484188a692417327ad32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"baefe5abfd7543489a4f926873957dca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f7f96c4b8ce04bafb5fe3c15aef74bc0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 41%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86685a2778994ac9bf7003721b6eee86"}},"9e5c916b3cd04e47843cf78fae13416d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c087c15355e34fd1aed1d997e6e483df","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":41,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2b70217a0cb4b72a1e819a0f7de245d"}},"c148b6fad3d44b33a0946974f3a463d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9afe933928914e3aac53772615b8e6f8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 41/100 [02:26&lt;03:20,  3.40s/epoch, loss=5.65, f1=0.777, val_loss=5.82, val_f1=0.424, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9842cb3aac24c10bbd45ecc43419c57"}},"f7f96c4b8ce04bafb5fe3c15aef74bc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86685a2778994ac9bf7003721b6eee86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c087c15355e34fd1aed1d997e6e483df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b2b70217a0cb4b72a1e819a0f7de245d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9afe933928914e3aac53772615b8e6f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d9842cb3aac24c10bbd45ecc43419c57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b75cbafed6a4749b1df30d2c7dd8d26":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e33cae76dd94258a9c291d552ad6747","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_80d039e86e0a43ffaf500d1055674a02","IPY_MODEL_cfc895a52ec84735a36122efd67f4af6"]}},"4e33cae76dd94258a9c291d552ad6747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"80d039e86e0a43ffaf500d1055674a02":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_e96d9dbefc3046b28eb9508f37a62c86","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.71MB of 0.71MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e2179c5f2f454f3a8e740c5bb5d84419"}},"cfc895a52ec84735a36122efd67f4af6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d8e3579bd91140299432595393749afe","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4dad28fe22bd4e9badc466f8423e0d24"}},"e96d9dbefc3046b28eb9508f37a62c86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e2179c5f2f454f3a8e740c5bb5d84419":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8e3579bd91140299432595393749afe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4dad28fe22bd4e9badc466f8423e0d24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1d9dca933644a2283f51df860bda6ba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_78a33037bc2648e29c36a8297a8643e0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_20b46448e91d4ec4b729fdd39b66fbc3","IPY_MODEL_b1ce4e4d1aa34aa985c43efddfeddc12","IPY_MODEL_92bca27680a248c8a04e613b28495bd4"]}},"78a33037bc2648e29c36a8297a8643e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"20b46448e91d4ec4b729fdd39b66fbc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d250ef1325f4bd99108992c35a94d4b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 42%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c24c210563d44b69f33f057d25a366d"}},"b1ce4e4d1aa34aa985c43efddfeddc12":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8fe793515bb842a78ac45fb8e5cef7d3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":42,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04339ab6d7e14a74b78674ca779d6aeb"}},"92bca27680a248c8a04e613b28495bd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_12a12b15fadc47338aa3afbeeeb7b5f6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 42/100 [02:29&lt;03:19,  3.44s/epoch, loss=5.78, f1=0.761, val_loss=5.91, val_f1=0.403, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f24855224b64dae85287bd1ae170baa"}},"3d250ef1325f4bd99108992c35a94d4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1c24c210563d44b69f33f057d25a366d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8fe793515bb842a78ac45fb8e5cef7d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"04339ab6d7e14a74b78674ca779d6aeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"12a12b15fadc47338aa3afbeeeb7b5f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2f24855224b64dae85287bd1ae170baa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"756bd9584e08431b8a389bfeba2b23ba":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_befef100f6174de098198822c87797f5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3dc118186094480aad113ab6790e2c6d","IPY_MODEL_fec3eddaf34741779a879783c1595952"]}},"befef100f6174de098198822c87797f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dc118186094480aad113ab6790e2c6d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_8ff99bfe7fa547a0bb24693271750f21","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.73MB of 0.73MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf2ccbae97f84af984418d5e40baf366"}},"fec3eddaf34741779a879783c1595952":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_01a3b340ea6a4e9fb40d5d0abeedd7f0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_07e5fa8e684a468796a69734f040415b"}},"8ff99bfe7fa547a0bb24693271750f21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bf2ccbae97f84af984418d5e40baf366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01a3b340ea6a4e9fb40d5d0abeedd7f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"07e5fa8e684a468796a69734f040415b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77986159db104a3b888323e0696bd8ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e04a16382c7439881e538a06623dcca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f0cc9d2c6fd241c0b15eb949deadfe11","IPY_MODEL_40d6ab41bfe148cf8ef560c9fe82edac","IPY_MODEL_2a684a7dc38944da930823431295f770"]}},"4e04a16382c7439881e538a06623dcca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0cc9d2c6fd241c0b15eb949deadfe11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1801fedb41c6401e9ab2240efdd860a7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 37%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_683e50242af9454b8759db0c5e74480e"}},"40d6ab41bfe148cf8ef560c9fe82edac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da2bb6830c574ec2a953b971cea5ebca","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":37,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d0ad118543e2493680e9a46a3ecddcbd"}},"2a684a7dc38944da930823431295f770":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71b6ea34cbe341d88ad3cf5841d8ec7e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 37/100 [02:10&lt;03:35,  3.43s/epoch, loss=5.63, f1=0.763, val_loss=5.8, val_f1=0.409, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a71421c678944ecb973b3f25d202da2f"}},"1801fedb41c6401e9ab2240efdd860a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"683e50242af9454b8759db0c5e74480e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da2bb6830c574ec2a953b971cea5ebca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d0ad118543e2493680e9a46a3ecddcbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71b6ea34cbe341d88ad3cf5841d8ec7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a71421c678944ecb973b3f25d202da2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be0ed6d342b241fbb2fc3a86cef99d1c":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ddf07745a7844ca79a689a664afd7c2d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_19fabfd6d24a425391693012391008ea","IPY_MODEL_3a0b601de642411fb57ee9c27261675c"]}},"ddf07745a7844ca79a689a664afd7c2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19fabfd6d24a425391693012391008ea":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_00182dcc1f5944ca9bdf7ebeb75448be","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.66MB of 0.66MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e82fe30d2564834827f51dcbac898dd"}},"3a0b601de642411fb57ee9c27261675c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b14f2039d0ab4708be2f5132b0a5db92","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7d9166bdfa3403fa51d58aafc57bad4"}},"00182dcc1f5944ca9bdf7ebeb75448be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e82fe30d2564834827f51dcbac898dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b14f2039d0ab4708be2f5132b0a5db92":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f7d9166bdfa3403fa51d58aafc57bad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"645667eed2ec4f61a7948c21a9426ecf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1507257fa194969a3f05a1aa19c10db","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1e22b66a74f44913977d77a816108bcd","IPY_MODEL_22850fe2524444b5aa5b4825971a1a56","IPY_MODEL_0f09fffb70a24dff8a5e1ba1bb7adc32"]}},"e1507257fa194969a3f05a1aa19c10db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e22b66a74f44913977d77a816108bcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a84d6f6a2c234cf08140faab9e23b076","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 37%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4137009bf83342ef8eba32e95b6bd1ad"}},"22850fe2524444b5aa5b4825971a1a56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a2d28bd8d7dc4335800d36edd13a4b15","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":37,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2165031c30b84cb3bb49cb72e04c7683"}},"0f09fffb70a24dff8a5e1ba1bb7adc32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71ef43d581454a7d8745eb2cec80eae8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 37/100 [02:09&lt;03:33,  3.39s/epoch, loss=5.22, f1=0.773, val_loss=5.49, val_f1=0.412, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38766e1ff1da44bab73fa0522ea55027"}},"a84d6f6a2c234cf08140faab9e23b076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4137009bf83342ef8eba32e95b6bd1ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2d28bd8d7dc4335800d36edd13a4b15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2165031c30b84cb3bb49cb72e04c7683":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71ef43d581454a7d8745eb2cec80eae8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38766e1ff1da44bab73fa0522ea55027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b316f22a56244e2390d45cdd9650b4f0":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb5d1e366a934fc09e6ae10a9eed5e2e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a9650d67a5541ca9a4876c41623f098","IPY_MODEL_423204a1a60a4a5889d50f3d726cfa33"]}},"bb5d1e366a934fc09e6ae10a9eed5e2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a9650d67a5541ca9a4876c41623f098":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_633f41b1bc674f18be6af8c958dfa27d","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.66MB of 0.66MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_059a6b8a1a4b4075849afae2ce44906a"}},"423204a1a60a4a5889d50f3d726cfa33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b831c7327d674c25a7050e8a4c7eb82f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6dbd6b3c4cfb48149cac39b9bec3f3ce"}},"633f41b1bc674f18be6af8c958dfa27d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"059a6b8a1a4b4075849afae2ce44906a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b831c7327d674c25a7050e8a4c7eb82f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6dbd6b3c4cfb48149cac39b9bec3f3ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26d9537cf8294a15837b3e8222875209":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d98307dd2df241f4bf9d208353a07357","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74e31d8a9e524275a75ad2c7dcd76f4f","IPY_MODEL_80b7ad96d4a848c389fcabb530324469","IPY_MODEL_9c101cd520694f988bb39fae04c3d72f"]}},"d98307dd2df241f4bf9d208353a07357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74e31d8a9e524275a75ad2c7dcd76f4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d62fe8705fe843f8a071f7131c10b875","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 40%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b52d3d9667d497492bfed3067380f8e"}},"80b7ad96d4a848c389fcabb530324469":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_46f6148b64104a028dfbf537163efd01","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":40,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e58f8816f0447b1a4fd3cc1d0d122ee"}},"9c101cd520694f988bb39fae04c3d72f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef4d1d359ab14ebba6566da072e6f978","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 40/100 [02:25&lt;03:24,  3.42s/epoch, loss=5.4, f1=0.786, val_loss=5.62, val_f1=0.435, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_944c6459f7d74a29b0ddd51f0eee3420"}},"d62fe8705fe843f8a071f7131c10b875":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3b52d3d9667d497492bfed3067380f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46f6148b64104a028dfbf537163efd01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2e58f8816f0447b1a4fd3cc1d0d122ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef4d1d359ab14ebba6566da072e6f978":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"944c6459f7d74a29b0ddd51f0eee3420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1970d70befc343589cbd3d38d984ec66":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97c77d526afe4313a7f924b08a12da61","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_030cb10a780e4bf495647ffabe427876","IPY_MODEL_6f8c4f46412442e886ad40b56f7dd2de"]}},"97c77d526afe4313a7f924b08a12da61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"030cb10a780e4bf495647ffabe427876":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_2f8389a9c4d34861a6ce8f2ff1a21fbc","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.70MB of 0.70MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bac6c46dea8942bd8cdf909d845134d0"}},"6f8c4f46412442e886ad40b56f7dd2de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4fbaf01e84564addb61cb0c83e7a0aa5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0e2d8f3a48ed4cb79bc5c47c584e3919"}},"2f8389a9c4d34861a6ce8f2ff1a21fbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bac6c46dea8942bd8cdf909d845134d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fbaf01e84564addb61cb0c83e7a0aa5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0e2d8f3a48ed4cb79bc5c47c584e3919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8400cd0d50414cfbb1328225c40650c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6b8c5e9737945b4a3680baa1789a6b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9e8afbd9845c462ebb8730d520bfd5d3","IPY_MODEL_a0f6b01ed4244986a454221c47d14764","IPY_MODEL_9d4f4e3b0c4944d8b03b61275b617633"]}},"b6b8c5e9737945b4a3680baa1789a6b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e8afbd9845c462ebb8730d520bfd5d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2583f97592fc47bd91747a4fc5f1d148","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 38%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e5da099438b4b7f8bbb0731fe753a69"}},"a0f6b01ed4244986a454221c47d14764":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8da9e10e479042fe87f5447d558fe3ba","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":38,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_40da3d70cbce490abd4e56d6278f1713"}},"9d4f4e3b0c4944d8b03b61275b617633":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d60309655e84b118f6a303b09215cc9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 38/100 [02:13&lt;03:25,  3.32s/epoch, loss=5.55, f1=0.763, val_loss=5.74, val_f1=0.4, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8c0744901604fe99bfc2832d1ea8fe7"}},"2583f97592fc47bd91747a4fc5f1d148":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e5da099438b4b7f8bbb0731fe753a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8da9e10e479042fe87f5447d558fe3ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"40da3d70cbce490abd4e56d6278f1713":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d60309655e84b118f6a303b09215cc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e8c0744901604fe99bfc2832d1ea8fe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72d8829538fb417ca56ed4f0faa4b35a":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e75b53e232048e9b0df32311bee5530","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_48542afafa7f4aa7abe8ab6321b3bf42","IPY_MODEL_d82e27900b1a4a2aa2c47dde4d5e39fc"]}},"4e75b53e232048e9b0df32311bee5530":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"48542afafa7f4aa7abe8ab6321b3bf42":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_9598817c316c46c88d97d9876906e61f","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.68MB of 0.68MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3532d926e8cb486ea7e85f9e371a227c"}},"d82e27900b1a4a2aa2c47dde4d5e39fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c34c087230564c5fbc7cfaaac89819ed","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb186a98d0dc463aa5dc40623be2cac8"}},"9598817c316c46c88d97d9876906e61f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3532d926e8cb486ea7e85f9e371a227c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c34c087230564c5fbc7cfaaac89819ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bb186a98d0dc463aa5dc40623be2cac8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64138e7a003c40b3b0df3194573acd45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_45897eb7caf24bd9984f97c486a6b1a3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3e73078150ce4faca525601d2e4eeda8","IPY_MODEL_abe99ce4afcd4862944ddae8489ba71a","IPY_MODEL_e095847cdac14aada4d90ba0358f1314"]}},"45897eb7caf24bd9984f97c486a6b1a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e73078150ce4faca525601d2e4eeda8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b354155120ae4e579f15fa382816324c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 41%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0588d17aba03486a85a4434eb4f530b5"}},"abe99ce4afcd4862944ddae8489ba71a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1f68d422ac1f421586d3bbcf00816e19","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":41,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d4ec30bb53940e3afb527221a3fb92f"}},"e095847cdac14aada4d90ba0358f1314":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1bdadc262955456aa87b9fa207597207","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 41/100 [02:27&lt;03:20,  3.40s/epoch, loss=5.94, f1=0.737, val_loss=6.03, val_f1=0.388, lr=1e-7]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_673562dc5cf544e4a5a9dd39331afc14"}},"b354155120ae4e579f15fa382816324c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0588d17aba03486a85a4434eb4f530b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f68d422ac1f421586d3bbcf00816e19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3d4ec30bb53940e3afb527221a3fb92f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1bdadc262955456aa87b9fa207597207":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"673562dc5cf544e4a5a9dd39331afc14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b9fb8c28e414d438cbf2f32ddbb281b":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0df3ef10239e465ab542f0e2def443c9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e9327d8a17ef4043b432fcb7cafa470d","IPY_MODEL_1180f92faabb4087aa8dbd4c6c689d1a"]}},"0df3ef10239e465ab542f0e2def443c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9327d8a17ef4043b432fcb7cafa470d":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_view_name":"LabelView","style":"IPY_MODEL_39a7e534a2d945c0b06441e05bea08bc","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.71MB of 0.71MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5dbd1a4554964bf1a704c7ea9c963d5c"}},"1180f92faabb4087aa8dbd4c6c689d1a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4905303ff97e42e390a4edd18abd00f0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8782ca14e4b44a1ca9ff78717875f201"}},"39a7e534a2d945c0b06441e05bea08bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5dbd1a4554964bf1a704c7ea9c963d5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4905303ff97e42e390a4edd18abd00f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8782ca14e4b44a1ca9ff78717875f201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["# Importing"],"metadata":{"id":"2jJuBxwbs5wf"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X9nCBwgCeV3c","executionInfo":{"status":"ok","timestamp":1642217848336,"user_tz":-540,"elapsed":84275,"user":{"displayName":"김영준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpTdFUUaMn51B-vREgj8EQWx2hKK-I4nl4g_I8lA=s64","userId":"06606532799291918175"}},"outputId":"42142090-8cd7-4a3e-96f5-6433d6d7a7a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (0.10.2)\n","Collecting statsmodels\n","  Downloading statsmodels-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.4.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.19.5)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.1.5)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (0.5.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->statsmodels) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->statsmodels) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.2->statsmodels) (1.15.0)\n","Installing collected packages: statsmodels\n","  Attempting uninstall: statsmodels\n","    Found existing installation: statsmodels 0.10.2\n","    Uninstalling statsmodels-0.10.2:\n","      Successfully uninstalled statsmodels-0.10.2\n","Successfully installed statsmodels-0.13.1\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n","Collecting xgboost\n","  Downloading xgboost-1.5.1-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n","\u001b[K     |████████████████████████████████| 173.5 MB 10 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n","Installing collected packages: xgboost\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 0.90\n","    Uninstalling xgboost-0.90:\n","      Successfully uninstalled xgboost-0.90\n","Successfully installed xgboost-1.5.1\n","Collecting catboost\n","  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n","\u001b[K     |████████████████████████████████| 76.1 MB 107 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n","Installing collected packages: catboost\n","Successfully installed catboost-1.0.4\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.23.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n","\u001b[K     |████████████████████████████████| 98 kB 5.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n","Collecting kt-legacy\n","  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.6)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.43.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.10.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n","Installing collected packages: kt-legacy, keras-tuner\n","Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n","Collecting optuna\n","  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n","\u001b[K     |████████████████████████████████| 308 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n","Collecting colorlog\n","  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.29)\n","Collecting alembic\n","  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 72.4 MB/s \n","\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n","Collecting cmaes>=0.8.2\n","  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n","Collecting cliff\n","  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 11.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.10.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n","Collecting Mako\n","  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n","\u001b[K     |████████████████████████████████| 75 kB 6.2 MB/s \n","\u001b[?25hCollecting cmd2>=1.0.0\n","  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n","\u001b[K     |████████████████████████████████| 149 kB 97.0 MB/s \n","\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n","  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 85.2 MB/s \n","\u001b[?25hCollecting autopage>=0.4.0\n","  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n","Collecting stevedore>=2.0.1\n","  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Collecting pyperclip>=1.6\n","  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n","Building wheels for collected packages: pyperclip\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=45b112d7cfd56344b5b72adad27e4a83a65816c653f4d6a72d5ff21245dc1aba\n","  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n","Successfully built pyperclip\n","Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n","Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n","Collecting wandb\n","  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 72.8 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.2-py2.py3-none-any.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 74.1 MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=80b6a287a2c0d406689e0e18fa476d06876ddb4ba8df9cd42598fd2484d8e93c\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=511041cf2613b531fa1b4fdbc979165e8fce15db11f06267c123dc877d8bdcdd\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.26 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.2 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.9 yaspin-2.1.0\n","Found GPU at: /device:GPU:0\n"]}],"source":["# # keep runtime\n","# function ClickConnect(){\n","# console.log(\"Working\"); \n","# document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n","# }\n","# var clicker = setInterval(ClickConnect,60000);\n","# # stop keeping runtime \n","# clearInterval(clicker);\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install --upgrade scikit-learn\n","!pip install --upgrade statsmodels\n","!pip install --upgrade xgboost\n","\n","# # lightgbm gpu version\n","# !pip uninstall lightgbmt --yes\n","# !pip install --upgrade cmake\n","# !git clone --recursive https://github.com/Microsoft/LightGBM\n","# %cd LightGBM\n","# !mkdir build\n","# %cd build\n","# !cmake -DUSE_GPU=1 ..\n","# !make -j$(nproc)\n","# %cd ../python-package\n","# !python3 setup.py install --gpu\n","\n","!pip install --upgrade catboost\n","!pip install --upgrade tensorflow\n","!pip install --upgrade keras\n","!pip install --upgrade keras-tuner\n","!pip install --upgrade tensorflow-addons\n","!pip install --upgrade optuna\n","!pip install --upgrade wandb\n","\n","import os\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/projects/DA_Platform\")\n","from DA_v5 import *\n","import wandb\n","from wandb.keras import WandbCallback\n","from optuna.integration.wandb import WeightsAndBiasesCallback as optuna_wnbcallback\n","from optuna import pruners\n","import shutil\n","from glob import glob\n","from IPython.display import Image, display\n","\n","import sys\n","from multiprocessing import cpu_count\n","import copy\n","import pickle\n","import warnings\n","from datetime import datetime, timedelta\n","from time import time, sleep, mktime\n","from matplotlib import font_manager as fm, rc, rcParams\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import re\n","import random\n","import wandb\n","from wandb.keras import WandbCallback\n","import shutil\n","\n","import numpy as np\n","from numpy import array, nan, random as rnd, where\n","import pandas as pd\n","from pandas import DataFrame as dataframe, Series as series, isna, read_csv\n","from pandas.tseries.offsets import DateOffset\n","import statsmodels.api as sm\n","from scipy.stats import f_oneway\n","\n","from sklearn import preprocessing as prep\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.impute import KNNImputer\n","from sklearn.model_selection import train_test_split as tts, GridSearchCV as GridTuner, StratifiedKFold, KFold\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n","from sklearn import metrics\n","from sklearn.pipeline import make_pipeline\n","\n","from sklearn import linear_model as lm\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as qda\n","from sklearn import svm\n","import lightgbm as lgb\n","import xgboost as xgb\n","import catboost as cat\n","from sklearn import neighbors as knn\n","from sklearn import ensemble\n","from optuna import distributions as optuna_dist, visualization as optuna_plt, Trial, create_study\n","from optuna.integration import OptunaSearchCV\n","from optuna.samplers import TPESampler\n","from optuna.logging import set_verbosity as optuna_set_verbose\n","\n","# ===== tensorflow =====\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import metrics as tf_metrics\n","from tensorflow.keras import callbacks as tf_callbacks\n","from tqdm.keras import TqdmCallback\n","import tensorflow_addons as tfa\n","import keras_tuner as kt\n","from keras_tuner import HyperModel\n","from tensorflow.keras.utils import plot_model\n","\n","# ===== timeseries =====\n","from statsmodels.tsa.arima.model import ARIMA\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from sklearn.model_selection import TimeSeriesSplit\n","from tensorflow.keras.preprocessing import timeseries_dataset_from_array as make_ts_tensor\n","\n","# global setting\n","warnings.filterwarnings(action='ignore')\n","rcParams['axes.unicode_minus'] = False\n","pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 100)\n","pd.set_option('display.width', 1000)\n","pd.set_option('max_colwidth', 200)\n","\n","rcParams['axes.unicode_minus'] = False\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","os.environ[\"WANDB_API_KEY\"] = \"6f810b088fcc6b9eaaa56c1e52cfd37836606240\"\n","folder_path = \"/content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/\"\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    tf.config.experimental.set_memory_growth(gpus[0], True)\n","  except RuntimeError as e:\n","    print(e)"]},{"cell_type":"markdown","source":["# Preprocessing - 2017"],"metadata":{"id":"dQ2KlMoHs63g"}},{"cell_type":"code","source":["# # ===== Preprocessing =====\n","# target_year = \"2017\"\n","# target_var = \"knowcode\"\n","# full_x = read_csv(folder_path + \"train/KNOW_\" + target_year + \".csv\", dtype={target_var: str}, na_values=[\"\", \" \"], encoding=\"utf-8\")\n","# full_x.drop([\"idx\"], axis=1, inplace=True)\n","# print(\"before removing dups\", full_x.shape[0])\n","# full_x.drop_duplicates(inplace=True)\n","# print(\"after removing dups\", full_x.shape[0])\n","\n","# print(\"before removing invalid values on target\", full_x.shape[0])\n","# full_x[target_var].replace(\" \", \"\", inplace=True)\n","# full_x = full_x[(full_x[target_var] != \"9999999\") & (full_x[target_var] != nan)]\n","# print(\"after removing invalid values on target\", full_x.shape[0])\n","# full_x.reset_index(drop=True, inplace=True)\n","\n","# full_y = full_x[target_var].to_frame()\n","# target_encoder = copy.deepcopy(MyLabelEncoder())\n","# full_y = target_encoder.fit_transform(full_y, [target_var])\n","# print(target_encoder.dic_cat)\n","# full_y.isna().sum()\n","# full_y[target_var] = full_y[target_var].astype(\"int\")\n","# print(full_y[target_var].value_counts())\n","# full_x.drop([target_var], axis=1, inplace=True)\n","\n","# test_x = read_csv(folder_path + \"test/KNOW_\" + target_year + \"_test.csv\", dtype={target_var: str}, na_values=[\"\", \" \"], encoding=\"utf-8\")\n","# submission_idx_start = test_x[\"idx\"].iloc[0]\n","# submission_idx_end = test_x[\"idx\"][-1:].iloc[0]\n","# test_x.drop([\"idx\"], axis=1, inplace=True)\n","\n","\n","\n","# # # text feature 정리\n","# # \"bq4_1a\" 필요자격증1\n","# # \"bq4_1b\" 필요자격증2\n","# # \"bq4_1c\" 필요자격증3\n","# # \"bq5_2\" 요구훈련종류\n","# # \"bq19_1\" : 향후 일자리 변화 이유\n","# # \"bq30\" : 유사직업명\n","# # \"bq31\" : 사용도구 및 프로그램\n","# # \"bq32\" : 이전직업\n","# # \"bq33\" : 전직 가능 직업\n","# # \"bq34\" : 신직업 발굴\n","# # \"bq38_1\" : 전공\n","\n","# # \"bq31\" 사용도구 및 프로그램은 콤마로 구분되는 멀티레이블 컬럼으로 볃도로 처리\n","# text_vars = [\"bq4_1a\", \"bq4_1b\", \"bq4_1c\", \"bq5_2\", \"bq19_1\",\n","#              \"bq30\", \"bq31_0\", \"bq31_1\", \"bq31_2\", \"bq32\", \"bq33\", \"bq34\", \"bq38_1\"]\n","\n","# # \"bq31\" 사용도구 및 프로그램 -> 세 컬럼 분리\n","# max_size_tool = 3\n","# bq31_split_vector = full_x[\"bq31\"].str.split(\",\")\n","# for i in range(max_size_tool):\n","#     full_x[\"bq31_\" + str(i)] = bq31_split_vector.str[i]\n","\n","# bq31_split_vector = test_x[\"bq31\"].str.split(\",\")\n","# for i in range(max_size_tool):\n","#     test_x[\"bq31_\" + str(i)] = bq31_split_vector.str[i]\n","\n","# # text 컬럼 전역 전처리\n","# for i in text_vars:\n","#     for idx, value in enumerate(full_x[i]):\n","#         if isna(value):\n","#             full_x[i][idx] = \"none\"\n","#         else:\n","#             value = text_extractor(value, \"both\", False).lower()\n","#             full_x[i][idx] = value\n","\n","# for i in text_vars:\n","#     for idx, value in enumerate(test_x[i]):\n","#         if isna(value):\n","#             test_x[i][idx] = \"none\"\n","#         else:\n","#             value = text_extractor(value, \"both\", False).lower()\n","#             test_x[i][idx] = value\n","\n","\n","# # \"bq4_1a\" 필요자격증\n","# # 기술사 - 기능장 - 기사 - 산업기사 - 기능사\n","# remove_text = [\"기술사\", \"기능장\", \"기사\", \"산업기사\", \"기능사\",\n","#                \"자격증\", \"자격\", \"면허증\", \"면허\", \"전문가\"]\n","# for idx, value in enumerate(full_x[\"bq4_1a\"]):\n","#     for i in remove_text:\n","#         value = value.replace(i, \"\")\n","#     full_x[\"bq4_1a\"][idx] = value\n","\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq4_1a\"].value_counts().index[full_x[\"bq4_1a\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq4_1a\"].value_counts().index[full_x[\"bq4_1a\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq4_1a\"].value_counts().index[full_x[\"bq4_1a\"].value_counts() > 9]\n","# print(len(high_freq))\n","\n","# for idx, value in enumerate(test_x[\"bq4_1a\"]):\n","#     for i in remove_text:\n","#         value = value.replace(i, \"\")\n","#     test_x[\"bq4_1a\"][idx] = value\n","\n","# # remove low frequency\n","# full_x[\"bq4_1a\"] = full_x[\"bq4_1a\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq4_1a\"] = test_x[\"bq4_1a\"].apply(lambda x: x if x in high_freq else \"none\")\n","# # print(full_x[\"bq4_1a\"].value_counts())\n","\n","# # \"bq5_2\" 요구훈련 종류\n","# # print(full_x[\"bq5_2\"].value_counts())\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq5_2\"].value_counts().index[full_x[\"bq5_2\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq5_2\"].value_counts().index[full_x[\"bq5_2\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq5_2\"].value_counts().index[full_x[\"bq5_2\"].value_counts() > 9]\n","# print(len(high_freq))\n","\n","# # remove low frequency\n","# full_x[\"bq5_2\"] = full_x[\"bq5_2\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq5_2\"] = test_x[\"bq5_2\"].apply(lambda x: x if x in high_freq else \"none\")\n","# # print(full_x[\"bq5_2\"].value_counts())\n","\n","\n","# # \"bq30\" 유사직업명\n","# print(full_x[\"bq30\"].value_counts())\n","# full_x[\"bq30\"] = full_x[\"bq30\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq30\"].value_counts().index[full_x[\"bq30\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq30\"].value_counts().index[full_x[\"bq30\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq30\"].value_counts().index[full_x[\"bq30\"].value_counts() > 9]\n","# print(len(high_freq))\n","# test_x[\"bq30\"] = test_x[\"bq30\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq30\"] = full_x[\"bq30\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq30\"] = test_x[\"bq30\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq30\"].value_counts())\n","\n","\n","\n","# # \"bq31\" 사용도구 및 프로그램 -> \"bq31_0\", \"bq31_1\", \"bq31_2\"\n","# bq31_vars = [\"bq31_0\", \"bq31_1\", \"bq31_2\"]\n","# max_size_tool = 3\n","# tmp = series()\n","# for i in range(max_size_tool):\n","#     full_x[\"bq31_\" + str(i)] = full_x[\"bq31_\" + str(i)].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","#     tmp = tmp.append(full_x[\"bq31_\" + str(i)])\n","# tmp.reset_index(drop=True, inplace=True)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(tmp.value_counts().index[tmp.value_counts() > i]) < 100:\n","#         high_freq = tmp.value_counts().index[tmp.value_counts() > i]\n","#         break\n","# # high_freq = tmp.value_counts().index[tmp.value_counts() > 2]\n","# print(len(high_freq))\n","# for i in range(max_size_tool):\n","#     test_x[\"bq31_\" + str(i)] = test_x[\"bq31_\" + str(i)].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# for i in range(max_size_tool):\n","#     full_x[\"bq31_\" + str(i)] = full_x[\"bq31_\" + str(i)].apply(lambda x: x if x in high_freq else \"none\")\n","#     test_x[\"bq31_\" + str(i)] = test_x[\"bq31_\" + str(i)].apply(lambda x: x if x in high_freq else \"none\")\n","\n","# # transform to BOW\n","# from sklearn.feature_extraction.text import CountVectorizer\n","# bq31_bow_encoder = CountVectorizer()\n","\n","# tmp = []\n","# for i in zip(full_x[bq31_vars[0]], full_x[bq31_vars[1]], full_x[bq31_vars[2]]):\n","#     tmp.append(\" \".join(i))\n","# bow = bq31_bow_encoder.fit_transform(tmp)\n","# full_x = pd.concat([full_x, dataframe(bow.toarray(), columns=[\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))])], axis=1)\n","\n","# tmp = []\n","# for i in zip(test_x[bq31_vars[0]], test_x[bq31_vars[1]], test_x[bq31_vars[2]]):\n","#     tmp.append(\" \".join(i))\n","# bow = bq31_bow_encoder.transform(tmp)\n","# test_x = pd.concat([test_x, dataframe(bow.toarray(), columns=[\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))])], axis=1)\n","\n","\n","# # \"bq32\" 이전 직업\n","# print(full_x[\"bq32\"].value_counts())\n","# full_x[\"bq32\"] = full_x[\"bq32\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq32\"].value_counts().index[full_x[\"bq32\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq32\"].value_counts().index[full_x[\"bq32\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq32\"].value_counts().index[full_x[\"bq32\"].value_counts() > 2]\n","# print(len(high_freq))\n","# test_x[\"bq32\"] = test_x[\"bq32\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq32\"] = full_x[\"bq32\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq32\"] = test_x[\"bq32\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq32\"].value_counts())\n","\n","\n","# # \"bq33\" 전직가능직업\n","# print(full_x[\"bq33\"].value_counts())\n","# full_x[\"bq33\"] = full_x[\"bq33\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq33\"].value_counts().index[full_x[\"bq33\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq33\"].value_counts().index[full_x[\"bq33\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq33\"].value_counts().index[full_x[\"bq33\"].value_counts() > 2]\n","# print(len(high_freq))\n","# test_x[\"bq33\"] = test_x[\"bq33\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq33\"] = full_x[\"bq33\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq33\"] = test_x[\"bq33\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq33\"].value_counts())\n","\n","\n","# # \"bq34\" 신직업 발굴\n","# full_x[\"bq34\"] = full_x[\"bq34\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq34\"].value_counts().index[full_x[\"bq34\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq34\"].value_counts().index[full_x[\"bq34\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq34\"].value_counts().index[full_x[\"bq34\"].value_counts() > 2]\n","# len(high_freq)\n","# test_x[\"bq34\"] = test_x[\"bq34\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq34\"] = full_x[\"bq34\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq34\"] = test_x[\"bq34\"].apply(lambda x: x if x in high_freq else \"none\")\n","\n","# # \"bq38_1\" 전공\n","# print(full_x[\"bq38_1\"].value_counts())\n","# full_x[\"bq38_1\"] = full_x[\"bq38_1\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq38_1\"].value_counts().index[full_x[\"bq38_1\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq38_1\"].value_counts().index[full_x[\"bq38_1\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq38_1\"].value_counts().index[full_x[\"bq38_1\"].value_counts() > 2]\n","# print(len(high_freq))\n","# test_x[\"bq38_1\"] = test_x[\"bq38_1\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq38_1\"] = full_x[\"bq38_1\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq38_1\"] = test_x[\"bq38_1\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq38_1\"].value_counts())\n","\n","# full_x.isna().sum()\n","# print(full_x.isna().sum().index[full_x.isna().sum() != 0])\n","# test_x.isna().sum()\n","# print(test_x.isna().sum().index[full_x.isna().sum() != 0])\n","\n","\n","\n","\n","# # age transformation\n","# full_x[\"bq37_age_cat\"] = pd.cut(full_x[\"bq37\"], [i * 10 for i in range(1, 10)], right=False).astype(\"object\")\n","# test_x[\"bq37_age_cat\"] = pd.cut(test_x[\"bq37\"], [i * 10 for i in range(1, 10)], right=False).astype(\"object\")\n","\n","# # === 불필요 컬럼 drop 및 이상치 제거 ===\n","# # 해당 업계 초봉 drop\n","# full_x.drop([\"bq41_2\"], axis=1, inplace=True)\n","# test_x.drop([\"bq41_2\"], axis=1, inplace=True)\n","\n","# # 불필요 텍스트 컬럼 drop\n","# full_x.drop([\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\", \"bq31_0\", \"bq31_1\", \"bq31_2\"], axis=1, inplace=True)\n","# test_x.drop([\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\", \"bq31_0\", \"bq31_1\", \"bq31_2\"], axis=1, inplace=True)\n","# text_vars = diff(text_vars, [\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\", \"bq31_0\", \"bq31_1\", \"bq31_2\"])\n","\n","# # 이상치 aq41_1 == 33\n","# full_y = full_y[~(full_x[\"aq41_1\"] == 33)]\n","# full_x = full_x[~(full_x[\"aq41_1\"] == 33)]\n","# full_x.reset_index(drop=True, inplace=True)\n","# full_y.reset_index(drop=True, inplace=True)\n","\n","# full_x[\"bq41_1\"].fillna(0.0, inplace=True)\n","# full_x[\"bq41_3\"].fillna(0.0, inplace=True)\n","# full_x[\"bq41_1_unemp\"] = [1 if i == 0 else 0 for i in full_x[\"bq41_1\"]]\n","# full_x[\"bq41_3_unemp\"] = [1 if i == 0 else 0 for i in full_x[\"bq41_3\"]]\n","\n","# test_x[\"bq41_1\"].fillna(0.0, inplace=True)\n","# test_x[\"bq41_3\"].fillna(0.0, inplace=True)\n","# test_x[\"bq41_1_unemp\"] = [1 if i == 0 else 0 for i in test_x[\"bq41_1\"]]\n","# test_x[\"bq41_3_unemp\"] = [1 if i == 0 else 0 for i in test_x[\"bq41_3\"]]\n","\n","# bin_vars = []\n","# ord_vars = list(full_x.columns[:82])\n","# # ord_vars = []\n","# text_vars += [\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))]\n","# num_vars = [\"bq23\", \"bq37\", \"bq41_1\", \"bq41_3\"]\n","\n","\n","# full_x.isna().sum()\n","# print(full_x.isna().sum().index[full_x.isna().sum() != 0])\n","# test_x.isna().sum()\n","# print(test_x.isna().sum().index[full_x.isna().sum() != 0])\n","\n","\n","# full_x[diff(full_x.columns, text_vars)] = full_x[diff(full_x.columns, text_vars)].fillna(0.0)\n","# test_x[diff(full_x.columns, text_vars)] = test_x[diff(full_x.columns, text_vars)].fillna(0.0)\n","\n","# text_vars = [\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))]\n","# cat_vars = diff(full_x.columns, num_vars + ord_vars + bin_vars + text_vars)\n","\n","# # columns length check\n","# print(\"columns lenght check\")\n","# print(len(full_x.columns) == len(num_vars) + len(ord_vars) + len(bin_vars) + len(cat_vars) + len(text_vars))\n","\n","\n","\n","# # full_x.isna().sum()\n","# # print(full_x.isna().sum().index[full_x.isna().sum() != 0])\n","# # test_x.isna().sum()\n","# # print(test_x.isna().sum().index[full_x.isna().sum() != 0])\n","\n","\n","# label_encoder = copy.deepcopy(MyLabelEncoder())\n","# full_x = label_encoder.fit_transform(full_x, cat_vars + bin_vars + ord_vars)\n","# for i in cat_vars:\n","#     print(full_x[i].value_counts().sort_index(), \"\\n\")\n","# test_x = label_encoder.transform(test_x)\n","# for i in cat_vars:\n","#     print(test_x[i].value_counts().sort_index(), \"\\n\")\n","\n","\n","# # string var check\n","# for i in full_x:\n","#     if full_x[i].dtype == \"object\":\n","#         print(i)\n","\n","# # print(full_x.isna().sum())\n","# # print(full_x.isna().sum().sum())\n","# # print(test_x.isna().sum())\n","# # print(test_x.isna().sum().sum())\n","\n","# knn_imputer = copy.deepcopy(MyKNNImputer())\n","# full_x = knn_imputer.fit_transform(full_x, full_y, cat_vars + bin_vars + ord_vars + text_vars)\n","# test_x = knn_imputer.transform(test_x)\n","\n","# print(full_x.isna().sum().sum())\n","# print(test_x.isna().sum().sum())\n","\n","# # string var check\n","# for i in full_x:\n","#     if full_x[i].dtype == \"object\":\n","#         print(i)\n","\n","# # === one hot encoding ===\n","# # print(full_x.isna().sum().sum())\n","# # print(test_x.isna().sum().sum())\n","\n","# # print(full_x.shape[1] == len(cat_vars) + len(bin_vars) + len(ord_vars) + len(num_vars))\n","\n","# # print(full_x.head(20))\n","# # print(test_x.head(20))\n","\n","# oh_encoder = copy.deepcopy(MyOneHotEncoder())\n","# full_x_oh = oh_encoder.fit_transform(full_x, cat_vars)\n","# test_x_oh = oh_encoder.transform(test_x)\n","# categoIdx = findIdx(full_x.columns, cat_vars)\n","\n","# # print(full_x_oh.isna().sum().sum())\n","# # print(test_x_oh.isna().sum().sum())\n","\n","# print(full_x.shape)\n","# print(test_x.shape)\n","# print(full_x_oh.shape)\n","# print(test_x_oh.shape)"],"metadata":{"id":"L5EW9QN1ejT3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642077014301,"user_tz":-540,"elapsed":72460,"user":{"displayName":"김영준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpTdFUUaMn51B-vREgj8EQWx2hKK-I4nl4g_I8lA=s64","userId":"06606532799291918175"}},"outputId":"7b861bb1-21bd-4332-c189-2f77734546da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["before removing dups 9486\n","after removing dups 9486\n","before removing invalid values on target 9486\n","after removing invalid values on target 9104\n","{'knowcode': {'110101': 0, '110102': 1, '110103': 2, '110104': 3, '110105': 4, '110201': 5, '110202': 6, '110203': 7, '11101': 8, '11102': 9, '11201': 10, '12101': 11, '12102': 12, '121101': 13, '121102': 14, '121103': 15, '121104': 16, '121105': 17, '121201': 18, '12201': 19, '122101': 20, '122102': 21, '122103': 22, '122104': 23, '122105': 24, '122201': 25, '122301': 26, '12301': 27, '12401': 28, '12402': 29, '13101': 30, '131101': 31, '131201': 32, '131202': 33, '131203': 34, '132002': 35, '132004': 36, '13201': 37, '13202': 38, '13203': 39, '13204': 40, '13305': 41, '133101': 42, '133201': 43, '133202': 44, '133203': 45, '133204': 46, '133205': 47, '133301': 48, '133302': 49, '13401': 50, '134101': 51, '134102': 52, '134201': 53, '134301': 54, '134302': 55, '134303': 56, '134401': 57, '135001': 58, '13501': 59, '136001': 60, '136002': 61, '13701': 62, '13902': 63, '140201': 64, '140204': 65, '140205': 66, '140206': 67, '140207': 68, '140301': 69, '140304': 70, '140305': 71, '140306': 72, '140401': 73, '140501': 74, '140502': 75, '140601': 76, '140701': 77, '14103': 78, '14201': 79, '14301': 80, '15101': 81, '151101': 82, '151105': 83, '151107': 84, '151108': 85, '151201': 86, '151301': 87, '15201': 88, '152101': 89, '152201': 90, '153101': 91, '153102': 92, '153103': 93, '153104': 94, '153105': 95, '153106': 96, '153201': 97, '153202': 98, '153203': 99, '153301': 100, '154101': 101, '154102': 102, '154103': 103, '154104': 104, '154201': 105, '155101': 106, '155102': 107, '155103': 108, '155104': 109, '155105': 110, '155106': 111, '155203': 112, '155301': 113, '155302': 114, '155303': 115, '155305': 116, '155401': 117, '155501': 118, '156101': 119, '156201': 120, '157101': 121, '157201': 122, '158201': 123, '158401': 124, '158402': 125, '158501': 126, '159104': 127, '16101': 128, '16201': 129, '16301': 130, '21001': 131, '211101': 132, '211201': 133, '212101': 134, '212102': 135, '212201': 136, '212301': 137, '212901': 138, '213001': 139, '214101': 140, '214102': 141, '214201': 142, '214301': 143, '214401': 144, '214501': 145, '215101': 146, '215105': 147, '22103': 148, '221101': 149, '221102': 150, '221201': 151, '221301': 152, '221401': 153, '222001': 154, '22201': 155, '22202': 156, '23101': 157, '231101': 158, '231102': 159, '231201': 160, '231301': 161, '231401': 162, '231501': 163, '23201': 164, '232101': 165, '232901': 166, '23301': 167, '23401': 168, '23402': 169, '23403': 170, '240101': 171, '240201': 172, '240301': 173, '24101': 174, '24203': 175, '24301': 176, '24402': 177, '24404': 178, '250201': 179, '250301': 180, '25101': 181, '25201': 182, '25301': 183, '25401': 184, '25402': 185, '26101': 186, '26102': 187, '26201': 188, '26301': 189, '26401': 190, '27101': 191, '27201': 192, '28101': 193, '28201': 194, '28202': 195, '28203': 196, '28204': 197, '28301': 198, '28401': 199, '28402': 200, '29101': 201, '29201': 202, '29202': 203, '29203': 204, '29303': 205, '29401': 206, '29501': 207, '29901': 208, '29902': 209, '29904': 210, '301004': 211, '301101': 212, '301102': 213, '301103': 214, '301104': 215, '301105': 216, '301106': 217, '301107': 218, '301108': 219, '301109': 220, '301110': 221, '301111': 222, '301112': 223, '301113': 224, '301201': 225, '301301': 226, '301401': 227, '302001': 228, '303001': 229, '305001': 230, '306101': 231, '306201': 232, '306301': 233, '306401': 234, '306501': 235, '306502': 236, '306601': 237, '306701': 238, '306901': 239, '306902': 240, '306903': 241, '306904': 242, '307101': 243, '307301': 244, '307401': 245, '307501': 246, '307601': 247, '31101': 248, '31201': 249, '31301': 250, '31302': 251, '31401': 252, '31403': 253, '31501': 254, '32101': 255, '32201': 256, '32301': 257, '32302': 258, '32401': 259, '32501': 260, '33201': 261, '33202': 262, '411101': 263, '411102': 264, '411103': 265, '411104': 266, '411105': 267, '411106': 268, '411201': 269, '411202': 270, '411301': 271, '412001': 272, '412002': 273, '412003': 274, '413101': 275, '413201': 276, '413202': 277, '414101': 278, '414102': 279, '414201': 280, '414301': 281, '414302': 282, '414303': 283, '414401': 284, '414501': 285, '414502': 286, '414503': 287, '414601': 288, '414602': 289, '414701': 290, '414702': 291, '414703': 292, '414901': 293, '414902': 294, '415101': 295, '415201': 296, '415202': 297, '415301': 298, '415404': 299, '415501': 300, '415502': 301, '415503': 302, '416101': 303, '416102': 304, '416103': 305, '416104': 306, '416105': 307, '416201': 308, '416202': 309, '416203': 310, '416204': 311, '416205': 312, '416301': 313, '416302': 314, '416303': 315, '416304': 316, '416401': 317, '416501': 318, '416601': 319, '416701': 320, '417102': 321, '417201': 322, '420101': 323, '420201': 324, '420202': 325, '420301': 326, '420401': 327, '420402': 328, '420403': 329, '420901': 330, '511101': 331, '511201': 332, '511301': 333, '511401': 334, '511402': 335, '511501': 336, '512101': 337, '512102': 338, '512201': 339, '512301': 340, '512401': 341, '521201': 342, '521303': 343, '521304': 344, '522101': 345, '522201': 346, '522202': 347, '523001': 348, '524001': 349, '531201': 350, '531301': 351, '531401': 352, '531501': 353, '531601': 354, '531701': 355, '532101': 356, '532201': 357, '532301': 358, '532401': 359, '541101': 360, '541201': 361, '541301': 362, '542001': 363, '550101': 364, '550201': 365, '561101': 366, '561301': 367, '561401': 368, '561501': 369, '561601': 370, '562301': 371, '562401': 372, '611001': 373, '612101': 374, '612201': 375, '612301': 376, '612501': 377, '613001': 378, '615101': 379, '615203': 380, '615301': 381, '615401': 382, '615501': 383, '615601': 384, '615701': 385, '616101': 386, '616201': 387, '617101': 388, '617901': 389, '621101': 390, '621102': 391, '621201': 392, '621202': 393, '621203': 394, '621301': 395, '621401': 396, '621402': 397, '621403': 398, '621901': 399, '622101': 400, '622201': 401, '622304': 402, '622901': 403, '623001': 404, '623002': 405, '624101': 406, '624201': 407, '624301': 408, '624401': 409, '701101': 410, '701201': 411, '701301': 412, '701401': 413, '701501': 414, '701601': 415, '701701': 416, '702101': 417, '702201': 418, '702301': 419, '702401': 420, '702501': 421, '702502': 422, '702601': 423, '702701': 424, '703101': 425, '703201': 426, '704001': 427, '705101': 428, '705201': 429, '705901': 430, '705902': 431, '706001': 432, '811101': 433, '811201': 434, '811301': 435, '811401': 436, '811501': 437, '811601': 438, '811901': 439, '812101': 440, '812102': 441, '812201': 442, '812301': 443, '812401': 444, '812901': 445, '813101': 446, '813201': 447, '814001': 448, '815001': 449, '816103': 450, '817101': 451, '817201': 452, '817301': 453, '821101': 454, '821201': 455, '822101': 456, '822301': 457, '823101': 458, '823301': 459, '824101': 460, '825101': 461, '825201': 462, '826101': 463, '826201': 464, '826301': 465, '826401': 466, '826901': 467, '826902': 468, '831101': 469, '831201': 470, '831301': 471, '832101': 472, '832201': 473, '833001': 474, '834001': 475, '835101': 476, '835201': 477, '836001': 478, '841101': 479, '842101': 480, '842201': 481, '842301': 482, '851101': 483, '851201': 484, '852101': 485, '852201': 486, '852301': 487, '852401': 488, '853101': 489, '853201': 490, '861101': 491, '861201': 492, '861301': 493, '862101': 494, '862201': 495, '862301': 496, '863101': 497, '863201': 498, '863301': 499, '863401': 500, '864101': 501, '864201': 502, '864301': 503, '871101': 504, '871201': 505, '872101': 506, '872201': 507, '872301': 508, '873101': 509, '873201': 510, '873301': 511, '873401': 512, '873501': 513, '881101': 514, '881201': 515, '882101': 516, '882201': 517, '882301': 518, '883101': 519, '883201': 520, '884101': 521, '884102': 522, '884201': 523, '885101': 524, '885201': 525, '885902': 526, '901101': 527, '901201': 528, '901301': 529, '901401': 530, '901501': 531, '902101': 532, '902201': 533, '903101': 534, '904101': 535, '904201': 536}}\n","134    137\n","132    106\n","211     78\n","143     62\n","374     60\n","      ... \n","61      15\n","69      15\n","77      15\n","93      15\n","0       15\n","Name: knowcode, Length: 537, dtype: int64\n","96\n","95\n","없다        6351\n","선생님        269\n","없음         244\n","기사          95\n","연구원         51\n","          ... \n","소방감          1\n","홍보실장         1\n","탁구강사         1\n","냉난방기술자       1\n","cpa          1\n","Name: bq30, Length: 1120, dtype: int64\n","76\n","none     8013\n","선생님       269\n","기사         95\n","연구원        51\n","기사님        50\n","교수님        29\n","교수         27\n","농부         26\n","의사선생님      25\n","원장님        24\n","엔지니어       23\n","간호사        23\n","강사         15\n","작가         15\n","가이드        14\n","전문의        13\n","주방장        12\n","개발자        11\n","수리기사       10\n","상담원         9\n","교도관         9\n","아줌마         9\n","pd          9\n","감독님         9\n","정비기사        8\n","원장          8\n","도우미         8\n","관제사         8\n","전기기사        8\n","목수          8\n","교감선생님       8\n","택배기사        8\n","설계사         7\n","이발사         7\n","지휘자         7\n","통관사         7\n","선생          7\n","청소부         7\n","검사원         7\n","디자이너        7\n","버스기사        7\n","미용사         6\n","은행원         6\n","상담사         6\n","감독          6\n","쌤           6\n","여사님         6\n","사장님         6\n","판매원         6\n","교장선생님       6\n","미싱사         6\n","감정사         6\n","공무원         6\n","노가다         5\n","이모님         5\n","펀드매니저       5\n","기장          5\n","작업치료사       5\n","의사          5\n","점원          5\n","기관사         5\n","장례사         5\n","조리사         5\n","아저씨         5\n","실장님         5\n","트럭기사        5\n","택시기사        5\n","잠수사         5\n","기공사         5\n","요리사         5\n","언더라이터       5\n","간호원         5\n","복덕방         5\n","소방관         5\n","주유원         5\n","수퍼바이저       5\n","Name: bq30, dtype: int64\n","95\n","없다            5496\n","none           248\n","없음             203\n","주부             140\n","회사원            115\n","              ... \n","사진관알바            1\n","에널리스트            1\n","에너지진단관련연구원       1\n","가구업체직원           1\n","고기집식당운영          1\n","Name: bq32, Length: 1452, dtype: int64\n","80\n","none      7609\n","주부         140\n","회사원        115\n","학생          96\n","자영업         83\n","사무직         75\n","거절          67\n","판매직         51\n","사무원         51\n","교사          48\n","학생없다        36\n","생산직         33\n","학원강사        30\n","연구원         28\n","무직          26\n","전임강사        23\n","농업          22\n","공무원         22\n","간호사         21\n","은행원         21\n","시간강사        17\n","서비스업        15\n","전업주부        15\n","영업직         15\n","용접공         15\n","사회복지사       14\n","대학생         14\n","유치원교사       14\n","선장          13\n","일반사무직       12\n","강사          12\n","판매원         12\n","동일          12\n","보험설계사       11\n","서비스직        11\n","교수          11\n","배관공         10\n","택시기사        10\n","의사          10\n","항해사          9\n","농사           9\n","의류판매원        9\n","단순노무직        9\n","직업군인         8\n","디자이너         8\n","일반간호사        8\n","수의사          8\n","가정주부         8\n","미용사          8\n","영업           8\n","개인사업         8\n","건설업          7\n","판매업          7\n","총무사무원        7\n","기관사          7\n","행정사무원        7\n","군인           7\n","일용직          6\n","미장공          6\n","금융사무원        6\n","경리사무원        6\n","식당운영         6\n","회계사무원        6\n","영업사원         6\n","초등교사         5\n","미싱사          5\n","음식점자영업       5\n","운동선수         5\n","택시운전         5\n","건설노동자        5\n","건축기사         5\n","유통업          5\n","알바           5\n","군인장교         5\n","교도관          5\n","대학강사         5\n","간호조무사        5\n","피부관리사        5\n","주방보조         5\n","회사원사무직       5\n","Name: bq32, dtype: int64\n","없다               6390\n","모름                415\n","none              353\n","없음                212\n","교수                 38\n","                 ... \n","행정서사                1\n","백호우                 1\n","잡지사에디터등앵커아나운서       1\n","화학시험연구원             1\n","의학계열교수연구원           1\n","Name: bq33, Length: 1347, dtype: int64\n","69\n","none       8748\n","교수           38\n","대학교수         21\n","학원강사         18\n","변호사          15\n","강사           14\n","세무사           9\n","연구원           9\n","장학사           9\n","의대교수          8\n","자영업           7\n","창업            7\n","대학강사          6\n","댄스강사          6\n","학원교사          6\n","택시기사          5\n","웹디자이너         5\n","사회복지사         5\n","컨설턴트          4\n","아나운서          4\n","인테리어          4\n","호텔관리사         4\n","물리치료사         4\n","관세사보세사        4\n","건축설계사         4\n","부품회사취직        4\n","공인중개사         4\n","요양보호사         4\n","공무원           4\n","출판사           4\n","상담사           4\n","컨설팅           4\n","미용사           4\n","항해사           3\n","웨딩플래너         3\n","지도자           3\n","정비기사          3\n","체육교사          3\n","법무사           3\n","작가            3\n","프로그램개발자       3\n","경비지도사         3\n","전기기술자         3\n","개인병원원장        3\n","심리상담가         3\n","래프팅지도자        3\n","보건교사          3\n","군무원           3\n","수선집           3\n","음식점운영         3\n","디자이너          3\n","호텔지배인         3\n","잘모름           3\n","보석감정사         3\n","교감교장          3\n","안전기사          3\n","웹툰작가          3\n","청소년지도사        3\n","식당운영          3\n","대리점           3\n","기계수리업         3\n","사진사           3\n","웹디자인          3\n","치위생사          3\n","보험설계사         3\n","행정사           3\n","유치원교사         3\n","방송기자          3\n","웹프로그래머        3\n","Name: bq33, dtype: int64\n","인문계       386\n","기계        381\n","경영학       334\n","none      263\n","기계공학      179\n","         ... \n","공간정보공학      1\n","미술치료전공      1\n","아동심리학       1\n","산업스포츠학      1\n","영상의학        1\n","Name: bq38_1, Length: 1396, dtype: int64\n","98\n","none      3556\n","인문계        386\n","기계         381\n","경영학        334\n","기계공학       179\n","전기         156\n","컴퓨터공학      154\n","의학         146\n","실업계        145\n","전자공학       140\n","경제학        129\n","행정학        114\n","인문         110\n","법학         108\n","토목공학        93\n","간호학         85\n","전기공학        84\n","상업          76\n","화학공학        72\n","전자          71\n","문           70\n","건축공학        67\n","화학          67\n","산업디자인       63\n","공고          63\n","국어국문학       63\n","문과          62\n","건축학         60\n","사회복지학       58\n","시각디자인       56\n","심리학         54\n","교육학         54\n","환경공학        51\n","체육학         49\n","토목          49\n","이           49\n","식품영양학       48\n","건축          47\n","신문방송학       47\n","회계학         46\n","경영          44\n","사회학         42\n","수학          40\n","통계학         39\n","이과          38\n","국문학         37\n","유아교육        35\n","인문고         33\n","공업          32\n","화공          32\n","물리학         31\n","재료공학        31\n","컴퓨터         30\n","생물학         30\n","영어영문학       29\n","디자인         29\n","실업          29\n","유아교육학       27\n","정보통신        27\n","실용음악        27\n","무역학         26\n","항해학         26\n","회계          26\n","물리치료학       26\n","기계과         26\n","약학          26\n","사회복지        25\n","금속공학        24\n","국문          24\n","여상          24\n","철학          24\n","신소재공학       23\n","연극영화        23\n","상업고         22\n","산업공학        22\n","컴퓨터학        22\n","상           22\n","문예창작        21\n","관광학         21\n","상고          21\n","무용학         21\n","정보통신공학      20\n","전산학         19\n","생명공학        19\n","전산          18\n","전기과         18\n","디자인학        18\n","도시공학        18\n","의예          18\n","사학          18\n","경호학         18\n","섬유공학        18\n","영문학         18\n","성악          17\n","식품공학        17\n","수의학         17\n","정보통신학       17\n","자동차공학       17\n","Name: bq38_1, dtype: int64\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq31', 'bq40', 'bq41_1', 'bq41_2', 'bq41_3'], dtype='object')\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq31', 'bq40', 'bq41_1', 'bq41_2', 'bq41_3'], dtype='object')\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq40'], dtype='object')\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq40'], dtype='object')\n","columns lenght check\n","True\n","WARNING : bq1 is not object or category\n","WARNING : bq2 is not object or category\n","WARNING : bq3 is not object or category\n","WARNING : bq4 is not object or category\n","WARNING : bq5 is not object or category\n","WARNING : bq5_1 is not object or category\n","WARNING : bq6 is not object or category\n","WARNING : bq7 is not object or category\n","WARNING : bq8_1 is not object or category\n","WARNING : bq8_2 is not object or category\n","WARNING : bq8_3 is not object or category\n","WARNING : bq9 is not object or category\n","WARNING : bq10 is not object or category\n","WARNING : bq11 is not object or category\n","WARNING : bq12_1 is not object or category\n","WARNING : bq12_2 is not object or category\n","WARNING : bq12_3 is not object or category\n","WARNING : bq12_4 is not object or category\n","WARNING : bq12_5 is not object or category\n","WARNING : bq13 is not object or category\n","WARNING : bq14 is not object or category\n","WARNING : bq15_1 is not object or category\n","WARNING : bq15_2 is not object or category\n","WARNING : bq15_3 is not object or category\n","WARNING : bq16 is not object or category\n","WARNING : bq17 is not object or category\n","WARNING : bq18_1 is not object or category\n","WARNING : bq18_2 is not object or category\n","WARNING : bq18_3 is not object or category\n","WARNING : bq18_4 is not object or category\n","WARNING : bq18_5 is not object or category\n","WARNING : bq18_6 is not object or category\n","WARNING : bq18_7 is not object or category\n","WARNING : bq19 is not object or category\n","WARNING : bq20 is not object or category\n","WARNING : bq21 is not object or category\n","WARNING : bq22 is not object or category\n","WARNING : bq24_1 is not object or category\n","WARNING : bq24_2 is not object or category\n","WARNING : bq24_3 is not object or category\n","WARNING : bq24_4 is not object or category\n","WARNING : bq24_5 is not object or category\n","WARNING : bq24_6 is not object or category\n","WARNING : bq24_7 is not object or category\n","WARNING : bq24_8 is not object or category\n","WARNING : bq25 is not object or category\n","WARNING : bq26 is not object or category\n","WARNING : bq27 is not object or category\n","WARNING : bq28 is not object or category\n","WARNING : bq29 is not object or category\n","WARNING : bq35 is not object or category\n","WARNING : bq36 is not object or category\n","WARNING : bq38 is not object or category\n","WARNING : bq39_1 is not object or category\n","WARNING : bq39_2 is not object or category\n","WARNING : bq40 is not object or category\n","WARNING : bq41_1_unemp is not object or category\n","WARNING : bq41_3_unemp is not object or category\n","WARNING : aq1_1 is not object or category\n","WARNING : aq1_2 is not object or category\n","WARNING : aq2_1 is not object or category\n","WARNING : aq2_2 is not object or category\n","WARNING : aq3_1 is not object or category\n","WARNING : aq3_2 is not object or category\n","WARNING : aq4_1 is not object or category\n","WARNING : aq4_2 is not object or category\n","WARNING : aq5_1 is not object or category\n","WARNING : aq5_2 is not object or category\n","WARNING : aq6_1 is not object or category\n","WARNING : aq6_2 is not object or category\n","WARNING : aq7_1 is not object or category\n","WARNING : aq7_2 is not object or category\n","WARNING : aq8_1 is not object or category\n","WARNING : aq8_2 is not object or category\n","WARNING : aq9_1 is not object or category\n","WARNING : aq9_2 is not object or category\n","WARNING : aq10_1 is not object or category\n","WARNING : aq10_2 is not object or category\n","WARNING : aq11_1 is not object or category\n","WARNING : aq11_2 is not object or category\n","WARNING : aq12_1 is not object or category\n","WARNING : aq12_2 is not object or category\n","WARNING : aq13_1 is not object or category\n","WARNING : aq13_2 is not object or category\n","WARNING : aq14_1 is not object or category\n","WARNING : aq14_2 is not object or category\n","WARNING : aq15_1 is not object or category\n","WARNING : aq15_2 is not object or category\n","WARNING : aq16_1 is not object or category\n","WARNING : aq16_2 is not object or category\n","WARNING : aq17_1 is not object or category\n","WARNING : aq17_2 is not object or category\n","WARNING : aq18_1 is not object or category\n","WARNING : aq18_2 is not object or category\n","WARNING : aq19_1 is not object or category\n","WARNING : aq19_2 is not object or category\n","WARNING : aq20_1 is not object or category\n","WARNING : aq20_2 is not object or category\n","WARNING : aq21_1 is not object or category\n","WARNING : aq21_2 is not object or category\n","WARNING : aq22_1 is not object or category\n","WARNING : aq22_2 is not object or category\n","WARNING : aq23_1 is not object or category\n","WARNING : aq23_2 is not object or category\n","WARNING : aq24_1 is not object or category\n","WARNING : aq24_2 is not object or category\n","WARNING : aq25_1 is not object or category\n","WARNING : aq25_2 is not object or category\n","WARNING : aq26_1 is not object or category\n","WARNING : aq26_2 is not object or category\n","WARNING : aq27_1 is not object or category\n","WARNING : aq27_2 is not object or category\n","WARNING : aq28_1 is not object or category\n","WARNING : aq28_2 is not object or category\n","WARNING : aq29_1 is not object or category\n","WARNING : aq29_2 is not object or category\n","WARNING : aq30_1 is not object or category\n","WARNING : aq30_2 is not object or category\n","WARNING : aq31_1 is not object or category\n","WARNING : aq31_2 is not object or category\n","WARNING : aq32_1 is not object or category\n","WARNING : aq32_2 is not object or category\n","WARNING : aq33_1 is not object or category\n","WARNING : aq33_2 is not object or category\n","WARNING : aq34_1 is not object or category\n","WARNING : aq34_2 is not object or category\n","WARNING : aq35_1 is not object or category\n","WARNING : aq35_2 is not object or category\n","WARNING : aq36_1 is not object or category\n","WARNING : aq36_2 is not object or category\n","WARNING : aq37_1 is not object or category\n","WARNING : aq37_2 is not object or category\n","WARNING : aq38_1 is not object or category\n","WARNING : aq38_2 is not object or category\n","WARNING : aq39_1 is not object or category\n","WARNING : aq39_2 is not object or category\n","WARNING : aq40_1 is not object or category\n","WARNING : aq40_2 is not object or category\n","WARNING : aq41_1 is not object or category\n","WARNING : aq41_2 is not object or category\n","0.0      142\n","1.0       22\n","2.0     1705\n","3.0      105\n","4.0       47\n","5.0      555\n","6.0      416\n","7.0      417\n","8.0      212\n","9.0      361\n","10.0     288\n","11.0      28\n","12.0     936\n","13.0     210\n","14.0     793\n","15.0     712\n","16.0     612\n","17.0     892\n","18.0     632\n","19.0      14\n","20.0       4\n","Name: bq1, dtype: int64 \n","\n","0.0    5921\n","1.0    1255\n","2.0     465\n","3.0     819\n","4.0     576\n","5.0      67\n","Name: bq2, dtype: int64 \n","\n","0.0    1648\n","1.0    3655\n","2.0    1188\n","3.0    1024\n","4.0     857\n","5.0     731\n","Name: bq3, dtype: int64 \n","\n","0.0    3992\n","1.0    5111\n","Name: bq4, dtype: int64 \n","\n","0.0     7216\n","1.0       61\n","2.0       18\n","3.0       16\n","4.0       12\n","5.0       39\n","6.0       14\n","7.0       15\n","8.0       16\n","9.0       14\n","10.0      16\n","11.0      16\n","12.0      23\n","13.0      58\n","14.0      10\n","15.0      20\n","16.0      10\n","17.0      10\n","18.0      16\n","19.0      11\n","20.0      15\n","21.0      11\n","22.0      16\n","23.0      26\n","24.0      23\n","25.0      14\n","26.0      11\n","27.0      17\n","28.0      17\n","29.0      17\n","30.0      14\n","31.0      13\n","32.0      20\n","33.0      22\n","34.0      10\n","35.0      34\n","36.0      18\n","37.0      15\n","38.0      17\n","39.0      10\n","40.0      12\n","41.0      14\n","42.0      15\n","43.0      16\n","44.0      10\n","45.0      11\n","46.0      14\n","47.0      15\n","48.0      17\n","49.0      11\n","50.0      16\n","51.0      10\n","52.0      52\n","53.0      10\n","54.0      10\n","55.0      17\n","56.0      14\n","57.0     149\n","58.0      13\n","59.0      15\n","60.0      13\n","61.0      12\n","62.0      14\n","63.0     106\n","64.0      18\n","65.0      49\n","66.0      13\n","67.0      22\n","68.0      15\n","69.0      12\n","70.0      83\n","71.0      13\n","72.0      10\n","73.0      14\n","74.0      14\n","75.0      11\n","76.0      15\n","77.0      12\n","78.0      13\n","79.0      21\n","80.0      12\n","81.0      10\n","82.0      10\n","83.0      39\n","84.0      11\n","85.0      14\n","86.0      13\n","87.0      11\n","88.0      12\n","89.0      16\n","90.0      11\n","91.0      10\n","92.0      22\n","93.0      14\n","94.0      15\n","95.0      11\n","Name: bq4_1a, dtype: int64 \n","\n","0.0    4347\n","1.0    4756\n","Name: bq5, dtype: int64 \n","\n","0.0    4756\n","1.0     566\n","2.0     972\n","3.0     975\n","4.0     733\n","5.0     536\n","6.0     565\n","Name: bq5_1, dtype: int64 \n","\n","0.0        3\n","1.0     8458\n","2.0        4\n","3.0        3\n","4.0        3\n","5.0        5\n","6.0        4\n","7.0        3\n","8.0        4\n","9.0        5\n","10.0       3\n","11.0       3\n","12.0       4\n","13.0       8\n","14.0       5\n","15.0       3\n","16.0       4\n","17.0       4\n","18.0       3\n","19.0       3\n","20.0      10\n","21.0       4\n","22.0       3\n","23.0       3\n","24.0       5\n","25.0      12\n","26.0       3\n","27.0       7\n","28.0       3\n","29.0       4\n","30.0       3\n","31.0       7\n","32.0       3\n","33.0       4\n","34.0       3\n","35.0       3\n","36.0       3\n","37.0       3\n","38.0       7\n","39.0      18\n","40.0       3\n","41.0       4\n","42.0       4\n","43.0       5\n","44.0       4\n","45.0      91\n","46.0       3\n","47.0       3\n","48.0       3\n","49.0       3\n","50.0       3\n","51.0      17\n","52.0      11\n","53.0       3\n","54.0       4\n","55.0       3\n","56.0       4\n","57.0       3\n","58.0       3\n","59.0       3\n","60.0       3\n","61.0       6\n","62.0       7\n","63.0       3\n","64.0       3\n","65.0       5\n","66.0       4\n","67.0       3\n","68.0      11\n","69.0      15\n","70.0      90\n","71.0      17\n","72.0       5\n","73.0       3\n","74.0       5\n","75.0       5\n","76.0       7\n","77.0       3\n","78.0       3\n","79.0       3\n","80.0       4\n","81.0       3\n","82.0       3\n","83.0       3\n","84.0       6\n","85.0       8\n","86.0      12\n","87.0      18\n","88.0       8\n","89.0       3\n","90.0       5\n","91.0       3\n","92.0       3\n","93.0       3\n","94.0       3\n","Name: bq5_2, dtype: int64 \n","\n","0.0     509\n","1.0    1022\n","2.0    1324\n","3.0    1055\n","4.0    1393\n","5.0    1836\n","6.0    1964\n","Name: bq6, dtype: int64 \n","\n","0.0     737\n","1.0    2344\n","2.0     468\n","3.0    1743\n","4.0    3107\n","5.0     517\n","6.0     187\n","Name: bq7, dtype: int64 \n","\n","0.0     167\n","1.0     986\n","2.0    2918\n","3.0    4199\n","4.0     833\n","Name: bq8_1, dtype: int64 \n","\n","0.0     618\n","1.0    1818\n","2.0    3292\n","3.0    2798\n","4.0     577\n","Name: bq8_2, dtype: int64 \n","\n","0.0     792\n","1.0    2113\n","2.0    3469\n","3.0    2345\n","4.0     384\n","Name: bq8_3, dtype: int64 \n","\n","0.0     110\n","1.0     875\n","2.0    2197\n","3.0    5039\n","4.0     882\n","Name: bq9, dtype: int64 \n","\n","0.0      75\n","1.0     688\n","2.0    2645\n","3.0    4810\n","4.0     885\n","Name: bq10, dtype: int64 \n","\n","0.0     353\n","1.0    2154\n","2.0    3640\n","3.0    2728\n","4.0     228\n","Name: bq11, dtype: int64 \n","\n","0.0     197\n","1.0    1843\n","2.0    4082\n","3.0    2600\n","4.0     381\n","Name: bq12_1, dtype: int64 \n","\n","0.0    1554\n","1.0     166\n","2.0    1068\n","3.0    4029\n","4.0    2007\n","5.0     279\n","Name: bq12_2, dtype: int64 \n","\n","0.0    1279\n","1.0      59\n","2.0     499\n","3.0    3500\n","4.0    3227\n","5.0     539\n","Name: bq12_3, dtype: int64 \n","\n","0.0     834\n","1.0      14\n","2.0     166\n","3.0    2865\n","4.0    4423\n","5.0     801\n","Name: bq12_4, dtype: int64 \n","\n","0.0      26\n","1.0     476\n","2.0    4370\n","3.0    3806\n","4.0     425\n","Name: bq12_5, dtype: int64 \n","\n","0.0     246\n","1.0    2042\n","2.0    3461\n","3.0    3178\n","4.0     176\n","Name: bq13, dtype: int64 \n","\n","0.0     292\n","1.0    2072\n","2.0    4043\n","3.0    2520\n","4.0     176\n","Name: bq14, dtype: int64 \n","\n","0.0     677\n","1.0    3787\n","2.0    2987\n","3.0    1552\n","4.0     100\n","Name: bq15_1, dtype: int64 \n","\n","0.0     182\n","1.0    1442\n","2.0    3473\n","3.0    3455\n","4.0     551\n","Name: bq15_2, dtype: int64 \n","\n","0.0     217\n","1.0    1550\n","2.0    4153\n","3.0    2770\n","4.0     413\n","Name: bq15_3, dtype: int64 \n","\n","0.0     194\n","1.0    1737\n","2.0    3320\n","3.0    3609\n","4.0     243\n","Name: bq16, dtype: int64 \n","\n","0.0     180\n","1.0    2395\n","2.0    4901\n","3.0    1551\n","4.0      76\n","Name: bq17, dtype: int64 \n","\n","0.0     140\n","1.0    1764\n","2.0    3987\n","3.0    2973\n","4.0     239\n","Name: bq18_1, dtype: int64 \n","\n","0.0     219\n","1.0    1990\n","2.0    3751\n","3.0    2772\n","4.0     371\n","Name: bq18_2, dtype: int64 \n","\n","0.0     909\n","1.0    2695\n","2.0    2931\n","3.0    2070\n","4.0     498\n","Name: bq18_3, dtype: int64 \n","\n","0.0     361\n","1.0    2198\n","2.0    3595\n","3.0    2532\n","4.0     417\n","Name: bq18_4, dtype: int64 \n","\n","0.0     533\n","1.0    2682\n","2.0    3694\n","3.0    2008\n","4.0     186\n","Name: bq18_5, dtype: int64 \n","\n","0.0     466\n","1.0    3340\n","2.0    3837\n","3.0    1321\n","4.0     139\n","Name: bq18_6, dtype: int64 \n","\n","0.0     181\n","1.0    1688\n","2.0    4550\n","3.0    2452\n","4.0     232\n","Name: bq18_7, dtype: int64 \n","\n","0.0     474\n","1.0    3056\n","2.0    3100\n","3.0    2257\n","4.0     216\n","Name: bq19, dtype: int64 \n","\n","0.0     518\n","1.0    3490\n","2.0    4288\n","3.0     807\n","Name: bq20, dtype: int64 \n","\n","0.0     466\n","1.0    3265\n","2.0    4131\n","3.0    1094\n","4.0     147\n","Name: bq21, dtype: int64 \n","\n","0.0    2004\n","1.0    1936\n","2.0    1289\n","3.0    1721\n","4.0     731\n","5.0    1422\n","Name: bq22, dtype: int64 \n","\n","0.0    2429\n","1.0    6674\n","Name: bq24_1, dtype: int64 \n","\n","0.0    3541\n","1.0    5562\n","Name: bq24_2, dtype: int64 \n","\n","0.0    3831\n","1.0    5272\n","Name: bq24_3, dtype: int64 \n","\n","0.0    2321\n","1.0    6782\n","Name: bq24_4, dtype: int64 \n","\n","0.0    1811\n","1.0    7292\n","Name: bq24_5, dtype: int64 \n","\n","0.0    1467\n","1.0    7636\n","Name: bq24_6, dtype: int64 \n","\n","0.0    1530\n","1.0    7573\n","Name: bq24_7, dtype: int64 \n","\n","0.0    1413\n","1.0    7690\n","Name: bq24_8, dtype: int64 \n","\n","0.0      23\n","1.0     618\n","2.0    3261\n","3.0    4842\n","4.0     359\n","Name: bq25, dtype: int64 \n","\n","0.0      17\n","1.0     308\n","2.0    3305\n","3.0    4626\n","4.0     847\n","Name: bq26, dtype: int64 \n","\n","0.0      50\n","1.0     842\n","2.0    3590\n","3.0    4288\n","4.0     333\n","Name: bq27, dtype: int64 \n","\n","0.0     108\n","1.0    1111\n","2.0    3818\n","3.0    3807\n","4.0     259\n","Name: bq28, dtype: int64 \n","\n","0.0     814\n","1.0    3553\n","2.0    3925\n","3.0     774\n","4.0      37\n","Name: bq29, dtype: int64 \n","\n","0.0     8012\n","1.0        9\n","2.0       14\n","3.0       23\n","4.0        5\n","5.0        6\n","6.0        9\n","7.0        6\n","8.0       15\n","9.0       11\n","10.0       7\n","11.0       6\n","12.0       8\n","13.0       8\n","14.0       9\n","15.0      27\n","16.0      29\n","17.0       6\n","18.0       5\n","19.0       5\n","20.0      95\n","21.0      50\n","22.0       5\n","23.0       5\n","24.0      26\n","25.0       8\n","26.0       7\n","27.0       8\n","28.0       6\n","29.0       6\n","30.0       7\n","31.0       5\n","32.0       6\n","33.0       6\n","34.0       9\n","35.0       7\n","36.0     269\n","37.0       7\n","38.0       5\n","39.0      10\n","40.0       5\n","41.0       5\n","42.0       6\n","43.0       5\n","44.0       9\n","45.0       5\n","46.0      23\n","47.0       6\n","48.0      51\n","49.0       5\n","50.0       8\n","51.0      24\n","52.0       6\n","53.0       5\n","54.0      25\n","55.0       5\n","56.0       7\n","57.0      15\n","58.0       5\n","59.0       5\n","60.0       5\n","61.0       8\n","62.0      13\n","63.0       5\n","64.0       8\n","65.0       5\n","66.0      12\n","67.0       5\n","68.0       7\n","69.0       7\n","70.0       8\n","71.0       5\n","72.0       7\n","73.0       5\n","74.0       6\n","75.0       5\n","Name: bq30, dtype: int64 \n","\n","0.0     7609\n","1.0        8\n","2.0       21\n","3.0        5\n","4.0       12\n","5.0        8\n","6.0       67\n","7.0        5\n","8.0        7\n","9.0        5\n","10.0       6\n","11.0      22\n","12.0       5\n","13.0      48\n","14.0      11\n","15.0       7\n","16.0       5\n","17.0       6\n","18.0       7\n","19.0       9\n","20.0      22\n","21.0       9\n","22.0       5\n","23.0      14\n","24.0      12\n","25.0       8\n","26.0      26\n","27.0       5\n","28.0       8\n","29.0       6\n","30.0      10\n","31.0      11\n","32.0      51\n","33.0      74\n","34.0      14\n","35.0      33\n","36.0      15\n","37.0      11\n","38.0      13\n","39.0       8\n","40.0      17\n","41.0       6\n","42.0       5\n","43.0      28\n","44.0       8\n","45.0       6\n","46.0      15\n","47.0      15\n","48.0       5\n","49.0      14\n","50.0       5\n","51.0      21\n","52.0       5\n","53.0       9\n","54.0      10\n","55.0       8\n","56.0      12\n","57.0       6\n","58.0      83\n","59.0      15\n","60.0      23\n","61.0       5\n","62.0     140\n","63.0       8\n","64.0       5\n","65.0       7\n","66.0      10\n","67.0       5\n","68.0       7\n","69.0      12\n","70.0      51\n","71.0       5\n","72.0      96\n","73.0      36\n","74.0      30\n","75.0       9\n","76.0       7\n","77.0       6\n","78.0     115\n","79.0       5\n","Name: bq32, dtype: int64 \n","\n","0.0     8747\n","1.0       14\n","2.0        3\n","3.0        4\n","4.0        3\n","5.0        4\n","6.0        4\n","7.0        4\n","8.0        3\n","9.0       38\n","10.0       3\n","11.0       3\n","12.0       3\n","13.0       6\n","14.0      21\n","15.0       6\n","16.0       3\n","17.0       3\n","18.0       4\n","19.0       4\n","20.0       3\n","21.0       3\n","22.0      15\n","23.0       3\n","24.0       3\n","25.0       3\n","26.0       4\n","27.0       3\n","28.0       5\n","29.0       4\n","30.0       9\n","31.0       3\n","32.0       3\n","33.0       3\n","34.0       4\n","35.0       3\n","36.0       9\n","37.0       4\n","38.0       3\n","39.0       5\n","40.0       3\n","41.0       3\n","42.0       3\n","43.0       3\n","44.0       3\n","45.0       8\n","46.0       4\n","47.0       7\n","48.0       3\n","49.0       3\n","50.0       9\n","51.0       3\n","52.0       3\n","53.0       3\n","54.0       7\n","55.0       3\n","56.0       3\n","57.0       4\n","58.0       3\n","59.0       4\n","60.0       4\n","61.0       5\n","62.0       3\n","63.0      18\n","64.0       6\n","65.0       3\n","66.0       3\n","67.0       4\n","68.0       3\n","Name: bq33, dtype: int64 \n","\n","0.0        2\n","1.0     9067\n","2.0        3\n","3.0        3\n","4.0        2\n","5.0        2\n","6.0        3\n","7.0        2\n","8.0        2\n","9.0        2\n","10.0       4\n","11.0       2\n","12.0       4\n","13.0       3\n","14.0       2\n","Name: bq34, dtype: int64 \n","\n","0.0     404\n","1.0    2647\n","2.0    3862\n","3.0    2092\n","4.0      98\n","Name: bq35, dtype: int64 \n","\n","0.0    6218\n","1.0    2885\n","Name: bq36, dtype: int64 \n","\n","0.0     263\n","1.0    1985\n","2.0    1261\n","3.0    4291\n","4.0     945\n","5.0     358\n","Name: bq38, dtype: int64 \n","\n","0.0     3555\n","1.0       85\n","2.0       47\n","3.0       67\n","4.0       60\n","5.0       44\n","6.0      334\n","7.0      129\n","8.0       18\n","9.0       63\n","10.0      32\n","11.0      21\n","12.0      54\n","13.0      24\n","14.0      37\n","15.0      63\n","16.0      24\n","17.0     381\n","18.0     179\n","19.0      26\n","20.0      18\n","21.0      29\n","22.0      18\n","23.0      26\n","24.0      21\n","25.0      70\n","26.0      62\n","27.0      21\n","28.0      26\n","29.0      31\n","30.0     108\n","31.0      18\n","32.0      25\n","33.0      58\n","34.0      42\n","35.0      22\n","36.0      63\n","37.0      22\n","38.0      21\n","39.0      76\n","40.0      22\n","41.0      19\n","42.0      30\n","43.0      18\n","44.0      17\n","45.0      17\n","46.0      40\n","47.0      56\n","48.0      17\n","49.0      48\n","50.0      47\n","51.0      23\n","52.0      29\n","53.0     145\n","54.0      27\n","55.0      54\n","56.0      26\n","57.0      24\n","58.0      23\n","59.0      18\n","60.0      29\n","61.0      35\n","62.0      27\n","63.0      18\n","64.0     146\n","65.0      49\n","66.0      38\n","67.0     110\n","68.0     386\n","69.0      33\n","70.0      17\n","71.0      31\n","72.0     156\n","73.0      84\n","74.0      18\n","75.0      18\n","76.0      19\n","77.0      71\n","78.0     140\n","79.0      27\n","80.0      20\n","81.0      17\n","82.0      24\n","83.0      49\n","84.0      30\n","85.0     154\n","86.0      22\n","87.0      49\n","88.0      93\n","89.0      39\n","90.0      26\n","91.0     114\n","92.0      32\n","93.0      67\n","94.0      72\n","95.0      51\n","96.0      26\n","97.0      46\n","Name: bq38_1, dtype: int64 \n","\n","0.0    7832\n","1.0    1271\n","Name: bq39_1, dtype: int64 \n","\n","0.0    6622\n","1.0     217\n","2.0     806\n","3.0     187\n","4.0     594\n","5.0     648\n","6.0      29\n","Name: bq39_2, dtype: int64 \n","\n","0.0    1271\n","1.0    6806\n","2.0    1026\n","Name: bq40, dtype: int64 \n","\n","0.0       2\n","1.0    1013\n","2.0    3407\n","3.0    2524\n","4.0    1697\n","5.0     391\n","6.0      67\n","7.0       2\n","Name: bq37_age_cat, dtype: int64 \n","\n","0.0    7804\n","1.0    1299\n","Name: bq41_1_unemp, dtype: int64 \n","\n","0.0    7817\n","1.0    1286\n","Name: bq41_3_unemp, dtype: int64 \n","\n","0.0      161\n","1.0       20\n","2.0     1750\n","3.0      129\n","4.0       50\n","5.0      557\n","6.0      439\n","7.0      433\n","8.0      207\n","9.0      397\n","10.0     290\n","11.0      29\n","12.0     998\n","13.0     203\n","14.0     819\n","15.0     749\n","16.0     642\n","17.0     949\n","18.0     652\n","19.0       8\n","20.0       4\n","Name: bq1, dtype: int64 \n","\n","0.0    6121\n","1.0    1314\n","2.0     494\n","3.0     890\n","4.0     582\n","5.0      85\n","Name: bq2, dtype: int64 \n","\n","0.0    1716\n","1.0    3738\n","2.0    1250\n","3.0    1135\n","4.0     900\n","5.0     747\n","Name: bq3, dtype: int64 \n","\n","0.0    4053\n","1.0    5433\n","Name: bq4, dtype: int64 \n","\n","0.0     7668\n","1.0       64\n","2.0       17\n","3.0       17\n","4.0        9\n","5.0       34\n","6.0       11\n","7.0       14\n","8.0       19\n","9.0       13\n","10.0      19\n","11.0      17\n","12.0      24\n","13.0      65\n","14.0       7\n","15.0      13\n","16.0       9\n","17.0      12\n","18.0      12\n","19.0      11\n","20.0      15\n","21.0      11\n","22.0      21\n","23.0      21\n","24.0      26\n","25.0      15\n","26.0       7\n","27.0      16\n","28.0      16\n","29.0      18\n","30.0      12\n","31.0      12\n","32.0      20\n","33.0      21\n","34.0       6\n","35.0      40\n","36.0      27\n","37.0      10\n","38.0      16\n","39.0       8\n","40.0      12\n","41.0      13\n","42.0      16\n","43.0      22\n","44.0      10\n","45.0       7\n","46.0      17\n","47.0      15\n","48.0      16\n","49.0       8\n","50.0      14\n","51.0       6\n","52.0      43\n","53.0       9\n","54.0      11\n","55.0      14\n","56.0      14\n","57.0     143\n","58.0      10\n","59.0      16\n","60.0      11\n","61.0      13\n","62.0      13\n","63.0     117\n","64.0      13\n","65.0      43\n","66.0      18\n","67.0      16\n","68.0      18\n","69.0      15\n","70.0      72\n","71.0       5\n","72.0       7\n","73.0      15\n","74.0      12\n","75.0      12\n","76.0      16\n","77.0       4\n","78.0       7\n","79.0      23\n","80.0      15\n","81.0       6\n","82.0       8\n","83.0      51\n","84.0       7\n","85.0      11\n","86.0      12\n","87.0      10\n","88.0       5\n","89.0      17\n","90.0      12\n","91.0       6\n","92.0      27\n","93.0      13\n","94.0      23\n","95.0       4\n","Name: bq4_1a, dtype: int64 \n","\n","0.0    4712\n","1.0    4774\n","Name: bq5, dtype: int64 \n","\n","0.0    4774\n","1.0     650\n","2.0    1071\n","3.0    1047\n","4.0     790\n","5.0     585\n","6.0     569\n","Name: bq5_1, dtype: int64 \n","\n","1.0     8963\n","5.0        6\n","6.0        1\n","7.0        1\n","8.0        3\n","9.0        1\n","11.0       1\n","12.0       3\n","13.0       1\n","14.0       4\n","15.0       1\n","17.0      11\n","19.0       1\n","20.0       8\n","23.0       1\n","25.0       6\n","26.0       3\n","27.0       9\n","28.0       2\n","30.0       1\n","31.0       5\n","32.0       3\n","33.0       2\n","35.0       3\n","38.0       4\n","39.0      34\n","40.0       2\n","41.0       5\n","43.0       1\n","44.0       5\n","45.0      71\n","46.0       3\n","47.0       5\n","48.0       3\n","49.0       2\n","50.0       1\n","51.0      16\n","52.0      14\n","54.0       3\n","56.0      10\n","58.0       2\n","59.0       3\n","60.0       7\n","61.0      12\n","62.0      10\n","63.0       2\n","65.0       3\n","66.0       4\n","67.0       5\n","68.0      13\n","69.0       9\n","70.0      89\n","71.0      12\n","72.0       3\n","73.0       9\n","74.0       1\n","75.0       4\n","76.0       7\n","78.0       3\n","80.0       6\n","81.0       2\n","82.0       2\n","83.0       5\n","84.0       1\n","85.0      13\n","86.0      14\n","87.0      21\n","88.0       2\n","91.0       2\n","94.0       1\n","Name: bq5_2, dtype: int64 \n","\n","0.0     480\n","1.0    1148\n","2.0    1357\n","3.0    1075\n","4.0    1466\n","5.0    1902\n","6.0    2058\n","Name: bq6, dtype: int64 \n","\n","0.0     810\n","1.0    2416\n","2.0     507\n","3.0    1753\n","4.0    3266\n","5.0     542\n","6.0     192\n","Name: bq7, dtype: int64 \n","\n","0.0     153\n","1.0     994\n","2.0    3021\n","3.0    4380\n","4.0     938\n","Name: bq8_1, dtype: int64 \n","\n","0.0     659\n","1.0    1930\n","2.0    3345\n","3.0    2895\n","4.0     657\n","Name: bq8_2, dtype: int64 \n","\n","0.0     837\n","1.0    2224\n","2.0    3541\n","3.0    2433\n","4.0     451\n","Name: bq8_3, dtype: int64 \n","\n","0.0     116\n","1.0     931\n","2.0    2242\n","3.0    5256\n","4.0     941\n","Name: bq9, dtype: int64 \n","\n","0.0      67\n","1.0     768\n","2.0    2751\n","3.0    4943\n","4.0     957\n","Name: bq10, dtype: int64 \n","\n","0.0     379\n","1.0    2214\n","2.0    3865\n","3.0    2811\n","4.0     217\n","Name: bq11, dtype: int64 \n","\n","0.0     232\n","1.0    1963\n","2.0    4269\n","3.0    2604\n","4.0     418\n","Name: bq12_1, dtype: int64 \n","\n","0.0    1609\n","1.0     160\n","2.0    1130\n","3.0    4179\n","4.0    2108\n","5.0     300\n","Name: bq12_2, dtype: int64 \n","\n","0.0    1332\n","1.0      54\n","2.0     521\n","3.0    3611\n","4.0    3454\n","5.0     514\n","Name: bq12_3, dtype: int64 \n","\n","0.0     884\n","1.0      12\n","2.0     183\n","3.0    2930\n","4.0    4657\n","5.0     820\n","Name: bq12_4, dtype: int64 \n","\n","0.0      25\n","1.0     498\n","2.0    4613\n","3.0    3938\n","4.0     412\n","Name: bq12_5, dtype: int64 \n","\n","0.0     253\n","1.0    2146\n","2.0    3691\n","3.0    3186\n","4.0     210\n","Name: bq13, dtype: int64 \n","\n","0.0     317\n","1.0    2194\n","2.0    4204\n","3.0    2569\n","4.0     202\n","Name: bq14, dtype: int64 \n","\n","0.0     805\n","1.0    3883\n","2.0    3015\n","3.0    1669\n","4.0     114\n","Name: bq15_1, dtype: int64 \n","\n","0.0     201\n","1.0    1532\n","2.0    3528\n","3.0    3623\n","4.0     602\n","Name: bq15_2, dtype: int64 \n","\n","0.0     229\n","1.0    1627\n","2.0    4304\n","3.0    2835\n","4.0     491\n","Name: bq15_3, dtype: int64 \n","\n","0.0     207\n","1.0    1890\n","2.0    3377\n","3.0    3741\n","4.0     271\n","Name: bq16, dtype: int64 \n","\n","0.0     205\n","1.0    2472\n","2.0    5188\n","3.0    1567\n","4.0      54\n","Name: bq17, dtype: int64 \n","\n","0.0     143\n","1.0    1852\n","2.0    4046\n","3.0    3156\n","4.0     289\n","Name: bq18_1, dtype: int64 \n","\n","0.0     225\n","1.0    2069\n","2.0    3738\n","3.0    3010\n","4.0     444\n","Name: bq18_2, dtype: int64 \n","\n","0.0    1000\n","1.0    2765\n","2.0    3024\n","3.0    2168\n","4.0     529\n","Name: bq18_3, dtype: int64 \n","\n","0.0     347\n","1.0    2202\n","2.0    3787\n","3.0    2723\n","4.0     427\n","Name: bq18_4, dtype: int64 \n","\n","0.0     567\n","1.0    2737\n","2.0    3877\n","3.0    2090\n","4.0     215\n","Name: bq18_5, dtype: int64 \n","\n","0.0     515\n","1.0    3390\n","2.0    4006\n","3.0    1448\n","4.0     127\n","Name: bq18_6, dtype: int64 \n","\n","0.0     182\n","1.0    1702\n","2.0    4690\n","3.0    2642\n","4.0     270\n","Name: bq18_7, dtype: int64 \n","\n","0.0     511\n","1.0    3159\n","2.0    3196\n","3.0    2389\n","4.0     231\n","Name: bq19, dtype: int64 \n","\n","0.0     564\n","1.0    3594\n","2.0    4535\n","3.0     793\n","Name: bq20, dtype: int64 \n","\n","0.0     550\n","1.0    3348\n","2.0    4317\n","3.0    1123\n","4.0     148\n","Name: bq21, dtype: int64 \n","\n","0.0    2070\n","1.0    1947\n","2.0    1286\n","3.0    1842\n","4.0     840\n","5.0    1501\n","Name: bq22, dtype: int64 \n","\n","0.0    2520\n","1.0    6966\n","Name: bq24_1, dtype: int64 \n","\n","0.0    3642\n","1.0    5844\n","Name: bq24_2, dtype: int64 \n","\n","0.0    3938\n","1.0    5548\n","Name: bq24_3, dtype: int64 \n","\n","0.0    2345\n","1.0    7141\n","Name: bq24_4, dtype: int64 \n","\n","0.0    1847\n","1.0    7639\n","Name: bq24_5, dtype: int64 \n","\n","0.0    1546\n","1.0    7940\n","Name: bq24_6, dtype: int64 \n","\n","0.0    1605\n","1.0    7881\n","Name: bq24_7, dtype: int64 \n","\n","0.0    1450\n","1.0    8036\n","Name: bq24_8, dtype: int64 \n","\n","0.0      26\n","1.0     707\n","2.0    3314\n","3.0    5096\n","4.0     343\n","Name: bq25, dtype: int64 \n","\n","0.0      14\n","1.0     317\n","2.0    3465\n","3.0    4773\n","4.0     917\n","Name: bq26, dtype: int64 \n","\n","0.0      54\n","1.0     950\n","2.0    3648\n","3.0    4486\n","4.0     348\n","Name: bq27, dtype: int64 \n","\n","0.0      97\n","1.0    1148\n","2.0    3952\n","3.0    4010\n","4.0     279\n","Name: bq28, dtype: int64 \n","\n","0.0     821\n","1.0    3611\n","2.0    4217\n","3.0     801\n","4.0      36\n","Name: bq29, dtype: int64 \n","\n","0.0     8464\n","1.0        5\n","2.0       18\n","3.0       20\n","5.0       11\n","6.0       15\n","7.0        2\n","8.0       13\n","9.0       11\n","10.0       7\n","11.0       5\n","12.0       6\n","13.0       7\n","14.0       5\n","15.0      16\n","16.0      25\n","17.0       4\n","19.0       2\n","20.0      81\n","21.0      44\n","22.0       6\n","23.0       5\n","24.0      32\n","25.0       8\n","26.0       6\n","27.0      12\n","28.0       2\n","29.0       1\n","30.0       4\n","31.0       4\n","32.0      19\n","33.0       9\n","34.0       4\n","35.0       7\n","36.0     277\n","37.0       9\n","38.0       3\n","39.0      10\n","40.0       2\n","41.0       4\n","42.0       2\n","43.0      10\n","44.0       7\n","45.0       3\n","46.0      17\n","47.0       7\n","48.0      71\n","49.0       6\n","50.0       5\n","51.0      12\n","52.0       1\n","53.0      13\n","54.0      14\n","55.0       4\n","56.0       6\n","57.0      13\n","58.0       7\n","59.0       3\n","60.0       2\n","61.0      13\n","62.0       8\n","63.0       1\n","64.0       4\n","65.0       5\n","66.0      14\n","67.0       1\n","68.0      10\n","69.0       4\n","70.0       9\n","71.0       9\n","72.0       3\n","73.0       6\n","74.0       7\n","75.0       4\n","Name: bq30, dtype: int64 \n","\n","0.0     7963\n","1.0        2\n","2.0       23\n","3.0        4\n","4.0       12\n","5.0        7\n","6.0       68\n","7.0        4\n","8.0       10\n","9.0        6\n","10.0      10\n","11.0      18\n","12.0       3\n","13.0      40\n","14.0      18\n","15.0       7\n","16.0       5\n","17.0       2\n","18.0       3\n","19.0      16\n","20.0      17\n","21.0       9\n","22.0       6\n","23.0       4\n","24.0      13\n","25.0       7\n","26.0      12\n","27.0       2\n","28.0       9\n","29.0      10\n","30.0       4\n","31.0      11\n","32.0      46\n","33.0      99\n","34.0      13\n","35.0      24\n","36.0      15\n","37.0      12\n","38.0      15\n","39.0       5\n","40.0       8\n","41.0       3\n","42.0       2\n","43.0      27\n","44.0       8\n","45.0       5\n","46.0      16\n","47.0      14\n","48.0       8\n","49.0      16\n","50.0       4\n","51.0      22\n","52.0       6\n","53.0       7\n","54.0       5\n","55.0      11\n","56.0       4\n","57.0       4\n","58.0      89\n","59.0      20\n","60.0      19\n","61.0       6\n","62.0     155\n","63.0      13\n","64.0       3\n","65.0      12\n","66.0       6\n","67.0       4\n","68.0      17\n","69.0      23\n","70.0      58\n","71.0       5\n","72.0     120\n","73.0      30\n","74.0      26\n","75.0      12\n","76.0       2\n","77.0       8\n","78.0     128\n","79.0       6\n","Name: bq32, dtype: int64 \n","\n","0.0     9166\n","1.0       19\n","2.0        2\n","3.0        3\n","4.0        3\n","5.0        6\n","6.0        3\n","7.0        1\n","9.0       57\n","10.0       1\n","11.0       1\n","12.0       3\n","13.0       9\n","14.0      36\n","15.0       4\n","16.0       1\n","17.0       1\n","18.0       3\n","19.0       3\n","20.0       1\n","21.0       8\n","22.0      17\n","23.0       3\n","28.0       8\n","29.0      12\n","30.0      10\n","31.0       3\n","32.0       3\n","34.0       7\n","35.0       1\n","36.0      13\n","37.0       3\n","38.0       3\n","39.0       4\n","40.0       3\n","41.0       1\n","42.0       1\n","43.0       3\n","44.0       2\n","45.0       7\n","46.0       2\n","47.0       5\n","50.0       4\n","53.0       2\n","54.0       3\n","55.0       3\n","56.0       2\n","58.0       2\n","59.0       3\n","60.0       2\n","61.0       1\n","62.0       1\n","63.0      17\n","64.0       1\n","65.0       2\n","68.0       1\n","Name: bq33, dtype: int64 \n","\n","1.0     9474\n","2.0        2\n","3.0        1\n","4.0        2\n","5.0        1\n","6.0        2\n","7.0        1\n","8.0        1\n","13.0       1\n","14.0       1\n","Name: bq34, dtype: int64 \n","\n","0.0     375\n","1.0    2789\n","2.0    3967\n","3.0    2255\n","4.0     100\n","Name: bq35, dtype: int64 \n","\n","0.0    6551\n","1.0    2935\n","Name: bq36, dtype: int64 \n","\n","0.0     278\n","1.0    2116\n","2.0    1279\n","3.0    4405\n","4.0     994\n","5.0     414\n","Name: bq38, dtype: int64 \n","\n","0.0     3725\n","1.0       80\n","2.0       57\n","3.0       57\n","4.0       69\n","5.0       53\n","6.0      314\n","7.0      115\n","8.0       17\n","9.0       76\n","10.0      36\n","11.0      25\n","12.0      56\n","13.0      22\n","14.0      42\n","15.0      64\n","16.0      16\n","17.0     384\n","18.0     177\n","19.0      33\n","20.0      12\n","21.0      36\n","22.0      12\n","23.0      42\n","24.0      26\n","25.0      73\n","26.0      85\n","27.0      13\n","28.0      25\n","29.0      33\n","30.0     126\n","31.0      18\n","32.0      19\n","33.0      75\n","34.0      64\n","35.0      34\n","36.0      59\n","37.0      25\n","38.0      35\n","39.0      64\n","40.0      24\n","41.0      16\n","42.0      29\n","43.0      20\n","44.0      12\n","45.0      16\n","46.0      36\n","47.0      52\n","48.0      19\n","49.0      44\n","50.0      48\n","51.0      18\n","52.0      26\n","53.0     131\n","54.0      17\n","55.0      49\n","56.0      26\n","57.0      28\n","58.0      27\n","59.0      25\n","60.0      31\n","61.0      34\n","62.0      22\n","63.0      18\n","64.0     153\n","65.0      47\n","66.0      39\n","67.0     131\n","68.0     435\n","69.0      22\n","70.0      13\n","71.0      27\n","72.0     148\n","73.0     112\n","74.0      25\n","75.0      25\n","76.0      29\n","77.0      65\n","78.0     126\n","79.0      40\n","80.0      27\n","81.0      15\n","82.0      24\n","83.0      67\n","84.0      20\n","85.0     166\n","86.0      23\n","87.0      49\n","88.0      85\n","89.0      47\n","90.0      26\n","91.0     100\n","92.0      35\n","93.0      68\n","94.0      83\n","95.0      61\n","96.0      25\n","97.0      66\n","Name: bq38_1, dtype: int64 \n","\n","0.0    8153\n","1.0    1333\n","Name: bq39_1, dtype: int64 \n","\n","0.0    6827\n","1.0     229\n","2.0     886\n","3.0     211\n","4.0     609\n","5.0     683\n","6.0      41\n","Name: bq39_2, dtype: int64 \n","\n","0.0    1333\n","1.0    7046\n","2.0    1107\n","Name: bq40, dtype: int64 \n","\n","0.0       8\n","1.0    1147\n","2.0    3456\n","3.0    2657\n","4.0    1745\n","5.0     415\n","6.0      55\n","7.0       3\n","Name: bq37_age_cat, dtype: int64 \n","\n","0.0    8115\n","1.0    1371\n","Name: bq41_1_unemp, dtype: int64 \n","\n","0.0    8144\n","1.0    1342\n","Name: bq41_3_unemp, dtype: int64 \n","\n","0\n","0\n","WARNING : bq1 is not object or category\n","WARNING : bq2 is not object or category\n","WARNING : bq3 is not object or category\n","WARNING : bq4 is not object or category\n","WARNING : bq4_1a is not object or category\n","WARNING : bq5 is not object or category\n","WARNING : bq5_1 is not object or category\n","WARNING : bq5_2 is not object or category\n","WARNING : bq6 is not object or category\n","WARNING : bq7 is not object or category\n","WARNING : bq8_1 is not object or category\n","WARNING : bq8_2 is not object or category\n","WARNING : bq8_3 is not object or category\n","WARNING : bq9 is not object or category\n","WARNING : bq10 is not object or category\n","WARNING : bq11 is not object or category\n","WARNING : bq12_1 is not object or category\n","WARNING : bq12_2 is not object or category\n","WARNING : bq12_3 is not object or category\n","WARNING : bq12_4 is not object or category\n","WARNING : bq12_5 is not object or category\n","WARNING : bq13 is not object or category\n","WARNING : bq14 is not object or category\n","WARNING : bq15_1 is not object or category\n","WARNING : bq15_2 is not object or category\n","WARNING : bq15_3 is not object or category\n","WARNING : bq16 is not object or category\n","WARNING : bq17 is not object or category\n","WARNING : bq18_1 is not object or category\n","WARNING : bq18_2 is not object or category\n","WARNING : bq18_3 is not object or category\n","WARNING : bq18_4 is not object or category\n","WARNING : bq18_5 is not object or category\n","WARNING : bq18_6 is not object or category\n","WARNING : bq18_7 is not object or category\n","WARNING : bq19 is not object or category\n","WARNING : bq20 is not object or category\n","WARNING : bq21 is not object or category\n","WARNING : bq22 is not object or category\n","WARNING : bq24_1 is not object or category\n","WARNING : bq24_2 is not object or category\n","WARNING : bq24_3 is not object or category\n","WARNING : bq24_4 is not object or category\n","WARNING : bq24_5 is not object or category\n","WARNING : bq24_6 is not object or category\n","WARNING : bq24_7 is not object or category\n","WARNING : bq24_8 is not object or category\n","WARNING : bq25 is not object or category\n","WARNING : bq26 is not object or category\n","WARNING : bq27 is not object or category\n","WARNING : bq28 is not object or category\n","WARNING : bq29 is not object or category\n","WARNING : bq30 is not object or category\n","WARNING : bq32 is not object or category\n","WARNING : bq33 is not object or category\n","WARNING : bq34 is not object or category\n","WARNING : bq35 is not object or category\n","WARNING : bq36 is not object or category\n","WARNING : bq38 is not object or category\n","WARNING : bq38_1 is not object or category\n","WARNING : bq39_1 is not object or category\n","WARNING : bq39_2 is not object or category\n","WARNING : bq40 is not object or category\n","WARNING : bq37_age_cat is not object or category\n","WARNING : bq41_1_unemp is not object or category\n","WARNING : bq41_3_unemp is not object or category\n","WARNING : bq1 is not object or category\n","WARNING : bq2 is not object or category\n","WARNING : bq3 is not object or category\n","WARNING : bq4 is not object or category\n","WARNING : bq4_1a is not object or category\n","WARNING : bq5 is not object or category\n","WARNING : bq5_1 is not object or category\n","WARNING : bq5_2 is not object or category\n","WARNING : bq6 is not object or category\n","WARNING : bq7 is not object or category\n","WARNING : bq8_1 is not object or category\n","WARNING : bq8_2 is not object or category\n","WARNING : bq8_3 is not object or category\n","WARNING : bq9 is not object or category\n","WARNING : bq10 is not object or category\n","WARNING : bq11 is not object or category\n","WARNING : bq12_1 is not object or category\n","WARNING : bq12_2 is not object or category\n","WARNING : bq12_3 is not object or category\n","WARNING : bq12_4 is not object or category\n","WARNING : bq12_5 is not object or category\n","WARNING : bq13 is not object or category\n","WARNING : bq14 is not object or category\n","WARNING : bq15_1 is not object or category\n","WARNING : bq15_2 is not object or category\n","WARNING : bq15_3 is not object or category\n","WARNING : bq16 is not object or category\n","WARNING : bq17 is not object or category\n","WARNING : bq18_1 is not object or category\n","WARNING : bq18_2 is not object or category\n","WARNING : bq18_3 is not object or category\n","WARNING : bq18_4 is not object or category\n","WARNING : bq18_5 is not object or category\n","WARNING : bq18_6 is not object or category\n","WARNING : bq18_7 is not object or category\n","WARNING : bq19 is not object or category\n","WARNING : bq20 is not object or category\n","WARNING : bq21 is not object or category\n","WARNING : bq22 is not object or category\n","WARNING : bq24_1 is not object or category\n","WARNING : bq24_2 is not object or category\n","WARNING : bq24_3 is not object or category\n","WARNING : bq24_4 is not object or category\n","WARNING : bq24_5 is not object or category\n","WARNING : bq24_6 is not object or category\n","WARNING : bq24_7 is not object or category\n","WARNING : bq24_8 is not object or category\n","WARNING : bq25 is not object or category\n","WARNING : bq26 is not object or category\n","WARNING : bq27 is not object or category\n","WARNING : bq28 is not object or category\n","WARNING : bq29 is not object or category\n","WARNING : bq30 is not object or category\n","WARNING : bq32 is not object or category\n","WARNING : bq33 is not object or category\n","WARNING : bq34 is not object or category\n","WARNING : bq35 is not object or category\n","WARNING : bq36 is not object or category\n","WARNING : bq38 is not object or category\n","WARNING : bq38_1 is not object or category\n","WARNING : bq39_1 is not object or category\n","WARNING : bq39_2 is not object or category\n","WARNING : bq40 is not object or category\n","WARNING : bq37_age_cat is not object or category\n","WARNING : bq41_1_unemp is not object or category\n","WARNING : bq41_3_unemp is not object or category\n","(9103, 239)\n","(9486, 239)\n","(9103, 986)\n","(9486, 986)\n"]}]},{"cell_type":"markdown","source":["# Preprocessing - 2017 (embedding layer)"],"metadata":{"id":"3EOpL3ZKHYwy"}},{"cell_type":"code","source":["# # ===== Preprocessing =====\n","# target_year = \"2017\"\n","# target_var = \"knowcode\"\n","# full_x = read_csv(folder_path + \"train/KNOW_\" + target_year + \".csv\", dtype={target_var: str}, na_values=[\"\", \" \"], encoding=\"utf-8\")\n","# full_x.drop([\"idx\"], axis=1, inplace=True)\n","# print(\"before removing dups\", full_x.shape[0])\n","# full_x.drop_duplicates(inplace=True)\n","# print(\"after removing dups\", full_x.shape[0])\n","\n","# print(\"before removing invalid values on target\", full_x.shape[0])\n","# full_x[target_var].replace(\" \", \"\", inplace=True)\n","# full_x = full_x[(full_x[target_var] != \"9999999\") & (full_x[target_var] != nan)]\n","# print(\"after removing invalid values on target\", full_x.shape[0])\n","# full_x.reset_index(drop=True, inplace=True)\n","\n","# full_y = full_x[target_var].to_frame()\n","# target_encoder = copy.deepcopy(MyLabelEncoder())\n","# full_y = target_encoder.fit_transform(full_y, [target_var])\n","# print(target_encoder.dic_cat)\n","# full_y.isna().sum()\n","# full_y[target_var] = full_y[target_var].astype(\"int\")\n","# print(full_y[target_var].value_counts())\n","# full_x.drop([target_var], axis=1, inplace=True)\n","\n","# test_x = read_csv(folder_path + \"test/KNOW_\" + target_year + \"_test.csv\", dtype={target_var: str}, na_values=[\"\", \" \"], encoding=\"utf-8\")\n","# submission_idx_start = test_x[\"idx\"].iloc[0]\n","# submission_idx_end = test_x[\"idx\"][-1:].iloc[0]\n","# test_x.drop([\"idx\"], axis=1, inplace=True)\n","\n","\n","\n","# # # text feature 정리\n","# # \"bq4_1a\" 필요자격증1\n","# # \"bq4_1b\" 필요자격증2\n","# # \"bq4_1c\" 필요자격증3\n","# # \"bq5_2\" 요구훈련종류\n","# # \"bq19_1\" : 향후 일자리 변화 이유\n","# # \"bq30\" : 유사직업명\n","# # \"bq31\" : 사용도구 및 프로그램\n","# # \"bq32\" : 이전직업\n","# # \"bq33\" : 전직 가능 직업\n","# # \"bq34\" : 신직업 발굴\n","# # \"bq38_1\" : 전공\n","\n","# # \"bq31\" 사용도구 및 프로그램은 콤마로 구분되는 멀티레이블 컬럼으로 볃도로 처리\n","# text_vars = [\"bq4_1a\", \"bq4_1b\", \"bq4_1c\", \"bq5_2\", \"bq19_1\",\n","#              \"bq30\", \"bq31_0\", \"bq31_1\", \"bq31_2\", \"bq32\", \"bq33\", \"bq34\", \"bq38_1\"]\n","\n","# # \"bq31\" 사용도구 및 프로그램 -> 세 컬럼 분리\n","# max_size_tool = 3\n","# bq31_split_vector = full_x[\"bq31\"].str.split(\",\")\n","# for i in range(max_size_tool):\n","#     full_x[\"bq31_\" + str(i)] = bq31_split_vector.str[i]\n","\n","# bq31_split_vector = test_x[\"bq31\"].str.split(\",\")\n","# for i in range(max_size_tool):\n","#     test_x[\"bq31_\" + str(i)] = bq31_split_vector.str[i]\n","\n","# # text 컬럼 전역 전처리\n","# for i in text_vars:\n","#     for idx, value in enumerate(full_x[i]):\n","#         if isna(value):\n","#             full_x[i][idx] = \"none\"\n","#         else:\n","#             value = text_extractor(value, \"both\", False).lower()\n","#             full_x[i][idx] = value\n","\n","# for i in text_vars:\n","#     for idx, value in enumerate(test_x[i]):\n","#         if isna(value):\n","#             test_x[i][idx] = \"none\"\n","#         else:\n","#             value = text_extractor(value, \"both\", False).lower()\n","#             test_x[i][idx] = value\n","\n","\n","# # \"bq4_1a\" 필요자격증\n","# # 기술사 - 기능장 - 기사 - 산업기사 - 기능사\n","# remove_text = [\"기술사\", \"기능장\", \"기사\", \"산업기사\", \"기능사\",\n","#                \"자격증\", \"자격\", \"면허증\", \"면허\", \"전문가\"]\n","# for idx, value in enumerate(full_x[\"bq4_1a\"]):\n","#     for i in remove_text:\n","#         value = value.replace(i, \"\")\n","#     full_x[\"bq4_1a\"][idx] = value\n","\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq4_1a\"].value_counts().index[full_x[\"bq4_1a\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq4_1a\"].value_counts().index[full_x[\"bq4_1a\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq4_1a\"].value_counts().index[full_x[\"bq4_1a\"].value_counts() > 9]\n","# print(len(high_freq))\n","\n","# for idx, value in enumerate(test_x[\"bq4_1a\"]):\n","#     for i in remove_text:\n","#         value = value.replace(i, \"\")\n","#     test_x[\"bq4_1a\"][idx] = value\n","\n","# # remove low frequency\n","# full_x[\"bq4_1a\"] = full_x[\"bq4_1a\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq4_1a\"] = test_x[\"bq4_1a\"].apply(lambda x: x if x in high_freq else \"none\")\n","# # print(full_x[\"bq4_1a\"].value_counts())\n","\n","# # \"bq5_2\" 요구훈련 종류\n","# # print(full_x[\"bq5_2\"].value_counts())\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq5_2\"].value_counts().index[full_x[\"bq5_2\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq5_2\"].value_counts().index[full_x[\"bq5_2\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq5_2\"].value_counts().index[full_x[\"bq5_2\"].value_counts() > 9]\n","# print(len(high_freq))\n","\n","# # remove low frequency\n","# full_x[\"bq5_2\"] = full_x[\"bq5_2\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq5_2\"] = test_x[\"bq5_2\"].apply(lambda x: x if x in high_freq else \"none\")\n","# # print(full_x[\"bq5_2\"].value_counts())\n","\n","\n","# # \"bq30\" 유사직업명\n","# print(full_x[\"bq30\"].value_counts())\n","# full_x[\"bq30\"] = full_x[\"bq30\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq30\"].value_counts().index[full_x[\"bq30\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq30\"].value_counts().index[full_x[\"bq30\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq30\"].value_counts().index[full_x[\"bq30\"].value_counts() > 9]\n","# print(len(high_freq))\n","# test_x[\"bq30\"] = test_x[\"bq30\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq30\"] = full_x[\"bq30\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq30\"] = test_x[\"bq30\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq30\"].value_counts())\n","\n","\n","\n","# # \"bq31\" 사용도구 및 프로그램 -> \"bq31_0\", \"bq31_1\", \"bq31_2\"\n","# bq31_vars = [\"bq31_0\", \"bq31_1\", \"bq31_2\"]\n","# max_size_tool = 3\n","# tmp = series()\n","# for i in range(max_size_tool):\n","#     full_x[\"bq31_\" + str(i)] = full_x[\"bq31_\" + str(i)].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","#     tmp = tmp.append(full_x[\"bq31_\" + str(i)])\n","# tmp.reset_index(drop=True, inplace=True)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(tmp.value_counts().index[tmp.value_counts() > i]) < 100:\n","#         high_freq = tmp.value_counts().index[tmp.value_counts() > i]\n","#         break\n","# # high_freq = tmp.value_counts().index[tmp.value_counts() > 2]\n","# print(len(high_freq))\n","# for i in range(max_size_tool):\n","#     test_x[\"bq31_\" + str(i)] = test_x[\"bq31_\" + str(i)].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# for i in range(max_size_tool):\n","#     full_x[\"bq31_\" + str(i)] = full_x[\"bq31_\" + str(i)].apply(lambda x: x if x in high_freq else \"none\")\n","#     test_x[\"bq31_\" + str(i)] = test_x[\"bq31_\" + str(i)].apply(lambda x: x if x in high_freq else \"none\")\n","\n","# # # transform to BOW\n","# # from sklearn.feature_extraction.text import CountVectorizer\n","# # bq31_bow_encoder = CountVectorizer()\n","\n","# # tmp = []\n","# # for i in zip(full_x[bq31_vars[0]], full_x[bq31_vars[1]], full_x[bq31_vars[2]]):\n","# #     tmp.append(\" \".join(i))\n","# # bow = bq31_bow_encoder.fit_transform(tmp)\n","# # full_x = pd.concat([full_x, dataframe(bow.toarray(), columns=[\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))])], axis=1)\n","\n","# # tmp = []\n","# # for i in zip(test_x[bq31_vars[0]], test_x[bq31_vars[1]], test_x[bq31_vars[2]]):\n","# #     tmp.append(\" \".join(i))\n","# # bow = bq31_bow_encoder.transform(tmp)\n","# # test_x = pd.concat([test_x, dataframe(bow.toarray(), columns=[\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))])], axis=1)\n","\n","\n","# # transform to Label Encoding\n","# tmp = tmp.apply(lambda x: x if x in high_freq else \"none\")\n","# bq31_encoder = copy.deepcopy(MyLabelEncoder())\n","# bq31_encoder.fit_transform(tmp.to_frame(name=\"tmp\"), [\"tmp\"])\n","\n","# for i in range(max_size_tool):\n","#     full_x[\"bq31_\" + str(i)] = bq31_encoder.transform(full_x[\"bq31_\" + str(i)].to_frame(name=\"tmp\"))\n","#     test_x[\"bq31_\" + str(i)] = bq31_encoder.transform(test_x[\"bq31_\" + str(i)].to_frame(name=\"tmp\"))\n","\n","\n","# # \"bq32\" 이전 직업\n","# print(full_x[\"bq32\"].value_counts())\n","# full_x[\"bq32\"] = full_x[\"bq32\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq32\"].value_counts().index[full_x[\"bq32\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq32\"].value_counts().index[full_x[\"bq32\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq32\"].value_counts().index[full_x[\"bq32\"].value_counts() > 2]\n","# print(len(high_freq))\n","# test_x[\"bq32\"] = test_x[\"bq32\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq32\"] = full_x[\"bq32\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq32\"] = test_x[\"bq32\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq32\"].value_counts())\n","\n","\n","# # \"bq33\" 전직가능직업\n","# print(full_x[\"bq33\"].value_counts())\n","# full_x[\"bq33\"] = full_x[\"bq33\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq33\"].value_counts().index[full_x[\"bq33\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq33\"].value_counts().index[full_x[\"bq33\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq33\"].value_counts().index[full_x[\"bq33\"].value_counts() > 2]\n","# print(len(high_freq))\n","# test_x[\"bq33\"] = test_x[\"bq33\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq33\"] = full_x[\"bq33\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq33\"] = test_x[\"bq33\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq33\"].value_counts())\n","\n","\n","# # \"bq34\" 신직업 발굴\n","# full_x[\"bq34\"] = full_x[\"bq34\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq34\"].value_counts().index[full_x[\"bq34\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq34\"].value_counts().index[full_x[\"bq34\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq34\"].value_counts().index[full_x[\"bq34\"].value_counts() > 2]\n","# len(high_freq)\n","# test_x[\"bq34\"] = test_x[\"bq34\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq34\"] = full_x[\"bq34\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq34\"] = test_x[\"bq34\"].apply(lambda x: x if x in high_freq else \"none\")\n","\n","# # \"bq38_1\" 전공\n","# print(full_x[\"bq38_1\"].value_counts())\n","# full_x[\"bq38_1\"] = full_x[\"bq38_1\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","# high_freq = None\n","# for i in range(1, 100):\n","#     if len(full_x[\"bq38_1\"].value_counts().index[full_x[\"bq38_1\"].value_counts() > i]) < 100:\n","#         high_freq = full_x[\"bq38_1\"].value_counts().index[full_x[\"bq38_1\"].value_counts() > i]\n","#         break\n","# # high_freq = full_x[\"bq38_1\"].value_counts().index[full_x[\"bq38_1\"].value_counts() > 2]\n","# print(len(high_freq))\n","# test_x[\"bq38_1\"] = test_x[\"bq38_1\"].apply(lambda x: \"none\" if x == \"없음\" or x == \"없다\" or x == \"모름\" or x == \"잘모르겠음\" else x)\n","\n","# # remove low frequency\n","# full_x[\"bq38_1\"] = full_x[\"bq38_1\"].apply(lambda x: x if x in high_freq else \"none\")\n","# test_x[\"bq38_1\"] = test_x[\"bq38_1\"].apply(lambda x: x if x in high_freq else \"none\")\n","# print(full_x[\"bq38_1\"].value_counts())\n","\n","# full_x.isna().sum()\n","# print(full_x.isna().sum().index[full_x.isna().sum() != 0])\n","# test_x.isna().sum()\n","# print(test_x.isna().sum().index[full_x.isna().sum() != 0])\n","\n","\n","\n","\n","# # age transformation\n","# full_x[\"bq37_age_cat\"] = pd.cut(full_x[\"bq37\"], [i * 10 for i in range(1, 10)], right=False).astype(\"object\")\n","# test_x[\"bq37_age_cat\"] = pd.cut(test_x[\"bq37\"], [i * 10 for i in range(1, 10)], right=False).astype(\"object\")\n","\n","# # === 불필요 컬럼 drop 및 이상치 제거 ===\n","# # 해당 업계 초봉 drop\n","# full_x.drop([\"bq41_2\"], axis=1, inplace=True)\n","# test_x.drop([\"bq41_2\"], axis=1, inplace=True)\n","\n","# # # 불필요 텍스트 컬럼 drop\n","# # full_x.drop([\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\", \"bq31_0\", \"bq31_1\", \"bq31_2\"], axis=1, inplace=True)\n","# # test_x.drop([\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\", \"bq31_0\", \"bq31_1\", \"bq31_2\"], axis=1, inplace=True)\n","# # text_vars = diff(text_vars, [\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\", \"bq31_0\", \"bq31_1\", \"bq31_2\"])\n","\n","# # 불필요 텍스트 컬럼 drop\n","# full_x.drop([\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\"], axis=1, inplace=True)\n","# test_x.drop([\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\"], axis=1, inplace=True)\n","# text_vars = diff(text_vars, [\"bq4_1b\", \"bq4_1c\", \"bq19_1\", \"bq31\"])\n","\n","# # 이상치 aq41_1 == 33\n","# full_y = full_y[~(full_x[\"aq41_1\"] == 33)]\n","# full_x = full_x[~(full_x[\"aq41_1\"] == 33)]\n","# full_x.reset_index(drop=True, inplace=True)\n","# full_y.reset_index(drop=True, inplace=True)\n","\n","# full_x[\"bq41_1\"].fillna(0.0, inplace=True)\n","# full_x[\"bq41_3\"].fillna(0.0, inplace=True)\n","# full_x[\"bq41_1_unemp\"] = [1 if i == 0 else 0 for i in full_x[\"bq41_1\"]]\n","# full_x[\"bq41_3_unemp\"] = [1 if i == 0 else 0 for i in full_x[\"bq41_3\"]]\n","\n","# test_x[\"bq41_1\"].fillna(0.0, inplace=True)\n","# test_x[\"bq41_3\"].fillna(0.0, inplace=True)\n","# test_x[\"bq41_1_unemp\"] = [1 if i == 0 else 0 for i in test_x[\"bq41_1\"]]\n","# test_x[\"bq41_3_unemp\"] = [1 if i == 0 else 0 for i in test_x[\"bq41_3\"]]\n","\n","# bin_vars = []\n","# ord_vars = list(full_x.columns[:82])\n","# # ord_vars = []\n","# # text_vars += [\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))]\n","# num_vars = [\"bq23\", \"bq37\", \"bq41_1\", \"bq41_3\"]\n","\n","\n","# full_x.isna().sum()\n","# print(full_x.isna().sum().index[full_x.isna().sum() != 0])\n","# test_x.isna().sum()\n","# print(test_x.isna().sum().index[full_x.isna().sum() != 0])\n","\n","\n","# full_x[diff(full_x.columns, text_vars)] = full_x[diff(full_x.columns, text_vars)].fillna(0.0)\n","# test_x[diff(full_x.columns, text_vars)] = test_x[diff(full_x.columns, text_vars)].fillna(0.0)\n","\n","# text_vars = [\"bq31_\" + str(i) for i in range(3)]\n","# cat_vars = diff(full_x.columns, num_vars + ord_vars + bin_vars + text_vars)\n","\n","# # columns length check\n","# print(\"columns lenght check\")\n","# print(len(full_x.columns) == len(num_vars) + len(ord_vars) + len(bin_vars) + len(cat_vars) + len(text_vars))\n","\n","\n","\n","# # full_x.isna().sum()\n","# # print(full_x.isna().sum().index[full_x.isna().sum() != 0])\n","# # test_x.isna().sum()\n","# # print(test_x.isna().sum().index[full_x.isna().sum() != 0])\n","\n","\n","# label_encoder = copy.deepcopy(MyLabelEncoder())\n","# full_x = label_encoder.fit_transform(full_x, cat_vars + bin_vars + ord_vars)\n","# for i in cat_vars:\n","#     print(full_x[i].value_counts().sort_index(), \"\\n\")\n","# test_x = label_encoder.transform(test_x)\n","# for i in cat_vars:\n","#     print(test_x[i].value_counts().sort_index(), \"\\n\")\n","\n","\n","# # string var check\n","# for i in full_x:\n","#     if full_x[i].dtype == \"object\":\n","#         print(i)\n","\n","# # print(full_x.isna().sum())\n","# # print(full_x.isna().sum().sum())\n","# # print(test_x.isna().sum())\n","# # print(test_x.isna().sum().sum())\n","\n","# knn_imputer = copy.deepcopy(MyKNNImputer())\n","# full_x = knn_imputer.fit_transform(full_x, full_y, cat_vars + bin_vars + ord_vars + text_vars)\n","# test_x = knn_imputer.transform(test_x)\n","\n","# print(full_x.isna().sum().sum())\n","# print(test_x.isna().sum().sum())\n","\n","# # string var check\n","# for i in full_x:\n","#     if full_x[i].dtype == \"object\":\n","#         print(i)\n","\n","# # numerical to discrete integer\n","# # for mlp embeddin layer\n","# kbins_encoder = KBinsDiscretizer(10, encode=\"ordinal\")\n","# full_x[num_vars] = kbins_encoder.fit_transform(full_x[num_vars])\n","# test_x[num_vars] = kbins_encoder.transform(test_x[num_vars])\n","\n","# # === one hot encoding ===\n","# # print(full_x.isna().sum().sum())\n","# # print(test_x.isna().sum().sum())\n","\n","# # print(full_x.shape[1] == len(cat_vars) + len(bin_vars) + len(ord_vars) + len(num_vars))\n","\n","# # print(full_x.head(20))\n","# # print(test_x.head(20))\n","\n","# # oh_encoder = copy.deepcopy(MyOneHotEncoder())\n","# # full_x_oh = oh_encoder.fit_transform(full_x, cat_vars + diff(text_vars, [\"bq31_bow\" + str(i) for i in range(len(bq31_bow_encoder.get_feature_names_out()))]))\n","# # test_x_oh = oh_encoder.transform(test_x)\n","\n","# # print(full_x_oh.isna().sum().sum())\n","# # print(test_x_oh.isna().sum().sum())\n","\n","# print(full_x.shape)\n","# print(test_x.shape)\n","# print(full_x_oh.shape)\n","# print(test_x_oh.shape)"],"metadata":{"id":"uWZ1oe0VHZHY","executionInfo":{"status":"ok","timestamp":1642077068602,"user_tz":-540,"elapsed":54309,"user":{"displayName":"김영준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpTdFUUaMn51B-vREgj8EQWx2hKK-I4nl4g_I8lA=s64","userId":"06606532799291918175"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2046bf36-6491-4f04-d230-b5f751e7bb06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["before removing dups 9486\n","after removing dups 9486\n","before removing invalid values on target 9486\n","after removing invalid values on target 9104\n","{'knowcode': {'110101': 0, '110102': 1, '110103': 2, '110104': 3, '110105': 4, '110201': 5, '110202': 6, '110203': 7, '11101': 8, '11102': 9, '11201': 10, '12101': 11, '12102': 12, '121101': 13, '121102': 14, '121103': 15, '121104': 16, '121105': 17, '121201': 18, '12201': 19, '122101': 20, '122102': 21, '122103': 22, '122104': 23, '122105': 24, '122201': 25, '122301': 26, '12301': 27, '12401': 28, '12402': 29, '13101': 30, '131101': 31, '131201': 32, '131202': 33, '131203': 34, '132002': 35, '132004': 36, '13201': 37, '13202': 38, '13203': 39, '13204': 40, '13305': 41, '133101': 42, '133201': 43, '133202': 44, '133203': 45, '133204': 46, '133205': 47, '133301': 48, '133302': 49, '13401': 50, '134101': 51, '134102': 52, '134201': 53, '134301': 54, '134302': 55, '134303': 56, '134401': 57, '135001': 58, '13501': 59, '136001': 60, '136002': 61, '13701': 62, '13902': 63, '140201': 64, '140204': 65, '140205': 66, '140206': 67, '140207': 68, '140301': 69, '140304': 70, '140305': 71, '140306': 72, '140401': 73, '140501': 74, '140502': 75, '140601': 76, '140701': 77, '14103': 78, '14201': 79, '14301': 80, '15101': 81, '151101': 82, '151105': 83, '151107': 84, '151108': 85, '151201': 86, '151301': 87, '15201': 88, '152101': 89, '152201': 90, '153101': 91, '153102': 92, '153103': 93, '153104': 94, '153105': 95, '153106': 96, '153201': 97, '153202': 98, '153203': 99, '153301': 100, '154101': 101, '154102': 102, '154103': 103, '154104': 104, '154201': 105, '155101': 106, '155102': 107, '155103': 108, '155104': 109, '155105': 110, '155106': 111, '155203': 112, '155301': 113, '155302': 114, '155303': 115, '155305': 116, '155401': 117, '155501': 118, '156101': 119, '156201': 120, '157101': 121, '157201': 122, '158201': 123, '158401': 124, '158402': 125, '158501': 126, '159104': 127, '16101': 128, '16201': 129, '16301': 130, '21001': 131, '211101': 132, '211201': 133, '212101': 134, '212102': 135, '212201': 136, '212301': 137, '212901': 138, '213001': 139, '214101': 140, '214102': 141, '214201': 142, '214301': 143, '214401': 144, '214501': 145, '215101': 146, '215105': 147, '22103': 148, '221101': 149, '221102': 150, '221201': 151, '221301': 152, '221401': 153, '222001': 154, '22201': 155, '22202': 156, '23101': 157, '231101': 158, '231102': 159, '231201': 160, '231301': 161, '231401': 162, '231501': 163, '23201': 164, '232101': 165, '232901': 166, '23301': 167, '23401': 168, '23402': 169, '23403': 170, '240101': 171, '240201': 172, '240301': 173, '24101': 174, '24203': 175, '24301': 176, '24402': 177, '24404': 178, '250201': 179, '250301': 180, '25101': 181, '25201': 182, '25301': 183, '25401': 184, '25402': 185, '26101': 186, '26102': 187, '26201': 188, '26301': 189, '26401': 190, '27101': 191, '27201': 192, '28101': 193, '28201': 194, '28202': 195, '28203': 196, '28204': 197, '28301': 198, '28401': 199, '28402': 200, '29101': 201, '29201': 202, '29202': 203, '29203': 204, '29303': 205, '29401': 206, '29501': 207, '29901': 208, '29902': 209, '29904': 210, '301004': 211, '301101': 212, '301102': 213, '301103': 214, '301104': 215, '301105': 216, '301106': 217, '301107': 218, '301108': 219, '301109': 220, '301110': 221, '301111': 222, '301112': 223, '301113': 224, '301201': 225, '301301': 226, '301401': 227, '302001': 228, '303001': 229, '305001': 230, '306101': 231, '306201': 232, '306301': 233, '306401': 234, '306501': 235, '306502': 236, '306601': 237, '306701': 238, '306901': 239, '306902': 240, '306903': 241, '306904': 242, '307101': 243, '307301': 244, '307401': 245, '307501': 246, '307601': 247, '31101': 248, '31201': 249, '31301': 250, '31302': 251, '31401': 252, '31403': 253, '31501': 254, '32101': 255, '32201': 256, '32301': 257, '32302': 258, '32401': 259, '32501': 260, '33201': 261, '33202': 262, '411101': 263, '411102': 264, '411103': 265, '411104': 266, '411105': 267, '411106': 268, '411201': 269, '411202': 270, '411301': 271, '412001': 272, '412002': 273, '412003': 274, '413101': 275, '413201': 276, '413202': 277, '414101': 278, '414102': 279, '414201': 280, '414301': 281, '414302': 282, '414303': 283, '414401': 284, '414501': 285, '414502': 286, '414503': 287, '414601': 288, '414602': 289, '414701': 290, '414702': 291, '414703': 292, '414901': 293, '414902': 294, '415101': 295, '415201': 296, '415202': 297, '415301': 298, '415404': 299, '415501': 300, '415502': 301, '415503': 302, '416101': 303, '416102': 304, '416103': 305, '416104': 306, '416105': 307, '416201': 308, '416202': 309, '416203': 310, '416204': 311, '416205': 312, '416301': 313, '416302': 314, '416303': 315, '416304': 316, '416401': 317, '416501': 318, '416601': 319, '416701': 320, '417102': 321, '417201': 322, '420101': 323, '420201': 324, '420202': 325, '420301': 326, '420401': 327, '420402': 328, '420403': 329, '420901': 330, '511101': 331, '511201': 332, '511301': 333, '511401': 334, '511402': 335, '511501': 336, '512101': 337, '512102': 338, '512201': 339, '512301': 340, '512401': 341, '521201': 342, '521303': 343, '521304': 344, '522101': 345, '522201': 346, '522202': 347, '523001': 348, '524001': 349, '531201': 350, '531301': 351, '531401': 352, '531501': 353, '531601': 354, '531701': 355, '532101': 356, '532201': 357, '532301': 358, '532401': 359, '541101': 360, '541201': 361, '541301': 362, '542001': 363, '550101': 364, '550201': 365, '561101': 366, '561301': 367, '561401': 368, '561501': 369, '561601': 370, '562301': 371, '562401': 372, '611001': 373, '612101': 374, '612201': 375, '612301': 376, '612501': 377, '613001': 378, '615101': 379, '615203': 380, '615301': 381, '615401': 382, '615501': 383, '615601': 384, '615701': 385, '616101': 386, '616201': 387, '617101': 388, '617901': 389, '621101': 390, '621102': 391, '621201': 392, '621202': 393, '621203': 394, '621301': 395, '621401': 396, '621402': 397, '621403': 398, '621901': 399, '622101': 400, '622201': 401, '622304': 402, '622901': 403, '623001': 404, '623002': 405, '624101': 406, '624201': 407, '624301': 408, '624401': 409, '701101': 410, '701201': 411, '701301': 412, '701401': 413, '701501': 414, '701601': 415, '701701': 416, '702101': 417, '702201': 418, '702301': 419, '702401': 420, '702501': 421, '702502': 422, '702601': 423, '702701': 424, '703101': 425, '703201': 426, '704001': 427, '705101': 428, '705201': 429, '705901': 430, '705902': 431, '706001': 432, '811101': 433, '811201': 434, '811301': 435, '811401': 436, '811501': 437, '811601': 438, '811901': 439, '812101': 440, '812102': 441, '812201': 442, '812301': 443, '812401': 444, '812901': 445, '813101': 446, '813201': 447, '814001': 448, '815001': 449, '816103': 450, '817101': 451, '817201': 452, '817301': 453, '821101': 454, '821201': 455, '822101': 456, '822301': 457, '823101': 458, '823301': 459, '824101': 460, '825101': 461, '825201': 462, '826101': 463, '826201': 464, '826301': 465, '826401': 466, '826901': 467, '826902': 468, '831101': 469, '831201': 470, '831301': 471, '832101': 472, '832201': 473, '833001': 474, '834001': 475, '835101': 476, '835201': 477, '836001': 478, '841101': 479, '842101': 480, '842201': 481, '842301': 482, '851101': 483, '851201': 484, '852101': 485, '852201': 486, '852301': 487, '852401': 488, '853101': 489, '853201': 490, '861101': 491, '861201': 492, '861301': 493, '862101': 494, '862201': 495, '862301': 496, '863101': 497, '863201': 498, '863301': 499, '863401': 500, '864101': 501, '864201': 502, '864301': 503, '871101': 504, '871201': 505, '872101': 506, '872201': 507, '872301': 508, '873101': 509, '873201': 510, '873301': 511, '873401': 512, '873501': 513, '881101': 514, '881201': 515, '882101': 516, '882201': 517, '882301': 518, '883101': 519, '883201': 520, '884101': 521, '884102': 522, '884201': 523, '885101': 524, '885201': 525, '885902': 526, '901101': 527, '901201': 528, '901301': 529, '901401': 530, '901501': 531, '902101': 532, '902201': 533, '903101': 534, '904101': 535, '904201': 536}}\n","134    137\n","132    106\n","211     78\n","143     62\n","374     60\n","      ... \n","61      15\n","69      15\n","77      15\n","93      15\n","0       15\n","Name: knowcode, Length: 537, dtype: int64\n","96\n","95\n","없다        6351\n","선생님        269\n","없음         244\n","기사          95\n","연구원         51\n","          ... \n","소방감          1\n","홍보실장         1\n","탁구강사         1\n","냉난방기술자       1\n","cpa          1\n","Name: bq30, Length: 1120, dtype: int64\n","76\n","none     8013\n","선생님       269\n","기사         95\n","연구원        51\n","기사님        50\n","교수님        29\n","교수         27\n","농부         26\n","의사선생님      25\n","원장님        24\n","엔지니어       23\n","간호사        23\n","강사         15\n","작가         15\n","가이드        14\n","전문의        13\n","주방장        12\n","개발자        11\n","수리기사       10\n","상담원         9\n","교도관         9\n","아줌마         9\n","pd          9\n","감독님         9\n","정비기사        8\n","원장          8\n","도우미         8\n","관제사         8\n","전기기사        8\n","목수          8\n","교감선생님       8\n","택배기사        8\n","설계사         7\n","이발사         7\n","지휘자         7\n","통관사         7\n","선생          7\n","청소부         7\n","검사원         7\n","디자이너        7\n","버스기사        7\n","미용사         6\n","은행원         6\n","상담사         6\n","감독          6\n","쌤           6\n","여사님         6\n","사장님         6\n","판매원         6\n","교장선생님       6\n","미싱사         6\n","감정사         6\n","공무원         6\n","노가다         5\n","이모님         5\n","펀드매니저       5\n","기장          5\n","작업치료사       5\n","의사          5\n","점원          5\n","기관사         5\n","장례사         5\n","조리사         5\n","아저씨         5\n","실장님         5\n","트럭기사        5\n","택시기사        5\n","잠수사         5\n","기공사         5\n","요리사         5\n","언더라이터       5\n","간호원         5\n","복덕방         5\n","소방관         5\n","주유원         5\n","수퍼바이저       5\n","Name: bq30, dtype: int64\n","95\n","없다            5496\n","none           248\n","없음             203\n","주부             140\n","회사원            115\n","              ... \n","사진관알바            1\n","에널리스트            1\n","에너지진단관련연구원       1\n","가구업체직원           1\n","고기집식당운영          1\n","Name: bq32, Length: 1452, dtype: int64\n","80\n","none      7609\n","주부         140\n","회사원        115\n","학생          96\n","자영업         83\n","사무직         75\n","거절          67\n","판매직         51\n","사무원         51\n","교사          48\n","학생없다        36\n","생산직         33\n","학원강사        30\n","연구원         28\n","무직          26\n","전임강사        23\n","농업          22\n","공무원         22\n","간호사         21\n","은행원         21\n","시간강사        17\n","서비스업        15\n","전업주부        15\n","영업직         15\n","용접공         15\n","사회복지사       14\n","대학생         14\n","유치원교사       14\n","선장          13\n","일반사무직       12\n","강사          12\n","판매원         12\n","동일          12\n","보험설계사       11\n","서비스직        11\n","교수          11\n","배관공         10\n","택시기사        10\n","의사          10\n","항해사          9\n","농사           9\n","의류판매원        9\n","단순노무직        9\n","직업군인         8\n","디자이너         8\n","일반간호사        8\n","수의사          8\n","가정주부         8\n","미용사          8\n","영업           8\n","개인사업         8\n","건설업          7\n","판매업          7\n","총무사무원        7\n","기관사          7\n","행정사무원        7\n","군인           7\n","일용직          6\n","미장공          6\n","금융사무원        6\n","경리사무원        6\n","식당운영         6\n","회계사무원        6\n","영업사원         6\n","초등교사         5\n","미싱사          5\n","음식점자영업       5\n","운동선수         5\n","택시운전         5\n","건설노동자        5\n","건축기사         5\n","유통업          5\n","알바           5\n","군인장교         5\n","교도관          5\n","대학강사         5\n","간호조무사        5\n","피부관리사        5\n","주방보조         5\n","회사원사무직       5\n","Name: bq32, dtype: int64\n","없다               6390\n","모름                415\n","none              353\n","없음                212\n","교수                 38\n","                 ... \n","행정서사                1\n","백호우                 1\n","잡지사에디터등앵커아나운서       1\n","화학시험연구원             1\n","의학계열교수연구원           1\n","Name: bq33, Length: 1347, dtype: int64\n","69\n","none       8748\n","교수           38\n","대학교수         21\n","학원강사         18\n","변호사          15\n","강사           14\n","세무사           9\n","연구원           9\n","장학사           9\n","의대교수          8\n","자영업           7\n","창업            7\n","대학강사          6\n","댄스강사          6\n","학원교사          6\n","택시기사          5\n","웹디자이너         5\n","사회복지사         5\n","컨설턴트          4\n","아나운서          4\n","인테리어          4\n","호텔관리사         4\n","물리치료사         4\n","관세사보세사        4\n","건축설계사         4\n","부품회사취직        4\n","공인중개사         4\n","요양보호사         4\n","공무원           4\n","출판사           4\n","상담사           4\n","컨설팅           4\n","미용사           4\n","항해사           3\n","웨딩플래너         3\n","지도자           3\n","정비기사          3\n","체육교사          3\n","법무사           3\n","작가            3\n","프로그램개발자       3\n","경비지도사         3\n","전기기술자         3\n","개인병원원장        3\n","심리상담가         3\n","래프팅지도자        3\n","보건교사          3\n","군무원           3\n","수선집           3\n","음식점운영         3\n","디자이너          3\n","호텔지배인         3\n","잘모름           3\n","보석감정사         3\n","교감교장          3\n","안전기사          3\n","웹툰작가          3\n","청소년지도사        3\n","식당운영          3\n","대리점           3\n","기계수리업         3\n","사진사           3\n","웹디자인          3\n","치위생사          3\n","보험설계사         3\n","행정사           3\n","유치원교사         3\n","방송기자          3\n","웹프로그래머        3\n","Name: bq33, dtype: int64\n","인문계       386\n","기계        381\n","경영학       334\n","none      263\n","기계공학      179\n","         ... \n","공간정보공학      1\n","미술치료전공      1\n","아동심리학       1\n","산업스포츠학      1\n","영상의학        1\n","Name: bq38_1, Length: 1396, dtype: int64\n","98\n","none      3556\n","인문계        386\n","기계         381\n","경영학        334\n","기계공학       179\n","전기         156\n","컴퓨터공학      154\n","의학         146\n","실업계        145\n","전자공학       140\n","경제학        129\n","행정학        114\n","인문         110\n","법학         108\n","토목공학        93\n","간호학         85\n","전기공학        84\n","상업          76\n","화학공학        72\n","전자          71\n","문           70\n","건축공학        67\n","화학          67\n","산업디자인       63\n","공고          63\n","국어국문학       63\n","문과          62\n","건축학         60\n","사회복지학       58\n","시각디자인       56\n","심리학         54\n","교육학         54\n","환경공학        51\n","체육학         49\n","토목          49\n","이           49\n","식품영양학       48\n","건축          47\n","신문방송학       47\n","회계학         46\n","경영          44\n","사회학         42\n","수학          40\n","통계학         39\n","이과          38\n","국문학         37\n","유아교육        35\n","인문고         33\n","공업          32\n","화공          32\n","물리학         31\n","재료공학        31\n","컴퓨터         30\n","생물학         30\n","영어영문학       29\n","디자인         29\n","실업          29\n","유아교육학       27\n","정보통신        27\n","실용음악        27\n","무역학         26\n","항해학         26\n","회계          26\n","물리치료학       26\n","기계과         26\n","약학          26\n","사회복지        25\n","금속공학        24\n","국문          24\n","여상          24\n","철학          24\n","신소재공학       23\n","연극영화        23\n","상업고         22\n","산업공학        22\n","컴퓨터학        22\n","상           22\n","문예창작        21\n","관광학         21\n","상고          21\n","무용학         21\n","정보통신공학      20\n","전산학         19\n","생명공학        19\n","전산          18\n","전기과         18\n","디자인학        18\n","도시공학        18\n","의예          18\n","사학          18\n","경호학         18\n","섬유공학        18\n","영문학         18\n","성악          17\n","식품공학        17\n","수의학         17\n","정보통신학       17\n","자동차공학       17\n","Name: bq38_1, dtype: int64\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq31', 'bq40', 'bq41_1', 'bq41_2', 'bq41_3'], dtype='object')\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq31', 'bq40', 'bq41_1', 'bq41_2', 'bq41_3'], dtype='object')\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq40'], dtype='object')\n","Index(['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2', 'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2', 'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2', 'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2', 'aq41_2', 'bq5_1', 'bq12_2', 'bq12_3', 'bq12_4', 'bq40'], dtype='object')\n","columns lenght check\n","True\n","WARNING : bq1 is not object or category\n","WARNING : bq2 is not object or category\n","WARNING : bq3 is not object or category\n","WARNING : bq4 is not object or category\n","WARNING : bq5 is not object or category\n","WARNING : bq5_1 is not object or category\n","WARNING : bq6 is not object or category\n","WARNING : bq7 is not object or category\n","WARNING : bq8_1 is not object or category\n","WARNING : bq8_2 is not object or category\n","WARNING : bq8_3 is not object or category\n","WARNING : bq9 is not object or category\n","WARNING : bq10 is not object or category\n","WARNING : bq11 is not object or category\n","WARNING : bq12_1 is not object or category\n","WARNING : bq12_2 is not object or category\n","WARNING : bq12_3 is not object or category\n","WARNING : bq12_4 is not object or category\n","WARNING : bq12_5 is not object or category\n","WARNING : bq13 is not object or category\n","WARNING : bq14 is not object or category\n","WARNING : bq15_1 is not object or category\n","WARNING : bq15_2 is not object or category\n","WARNING : bq15_3 is not object or category\n","WARNING : bq16 is not object or category\n","WARNING : bq17 is not object or category\n","WARNING : bq18_1 is not object or category\n","WARNING : bq18_2 is not object or category\n","WARNING : bq18_3 is not object or category\n","WARNING : bq18_4 is not object or category\n","WARNING : bq18_5 is not object or category\n","WARNING : bq18_6 is not object or category\n","WARNING : bq18_7 is not object or category\n","WARNING : bq19 is not object or category\n","WARNING : bq20 is not object or category\n","WARNING : bq21 is not object or category\n","WARNING : bq22 is not object or category\n","WARNING : bq24_1 is not object or category\n","WARNING : bq24_2 is not object or category\n","WARNING : bq24_3 is not object or category\n","WARNING : bq24_4 is not object or category\n","WARNING : bq24_5 is not object or category\n","WARNING : bq24_6 is not object or category\n","WARNING : bq24_7 is not object or category\n","WARNING : bq24_8 is not object or category\n","WARNING : bq25 is not object or category\n","WARNING : bq26 is not object or category\n","WARNING : bq27 is not object or category\n","WARNING : bq28 is not object or category\n","WARNING : bq29 is not object or category\n","WARNING : bq35 is not object or category\n","WARNING : bq36 is not object or category\n","WARNING : bq38 is not object or category\n","WARNING : bq39_1 is not object or category\n","WARNING : bq39_2 is not object or category\n","WARNING : bq40 is not object or category\n","WARNING : bq41_1_unemp is not object or category\n","WARNING : bq41_3_unemp is not object or category\n","WARNING : aq1_1 is not object or category\n","WARNING : aq1_2 is not object or category\n","WARNING : aq2_1 is not object or category\n","WARNING : aq2_2 is not object or category\n","WARNING : aq3_1 is not object or category\n","WARNING : aq3_2 is not object or category\n","WARNING : aq4_1 is not object or category\n","WARNING : aq4_2 is not object or category\n","WARNING : aq5_1 is not object or category\n","WARNING : aq5_2 is not object or category\n","WARNING : aq6_1 is not object or category\n","WARNING : aq6_2 is not object or category\n","WARNING : aq7_1 is not object or category\n","WARNING : aq7_2 is not object or category\n","WARNING : aq8_1 is not object or category\n","WARNING : aq8_2 is not object or category\n","WARNING : aq9_1 is not object or category\n","WARNING : aq9_2 is not object or category\n","WARNING : aq10_1 is not object or category\n","WARNING : aq10_2 is not object or category\n","WARNING : aq11_1 is not object or category\n","WARNING : aq11_2 is not object or category\n","WARNING : aq12_1 is not object or category\n","WARNING : aq12_2 is not object or category\n","WARNING : aq13_1 is not object or category\n","WARNING : aq13_2 is not object or category\n","WARNING : aq14_1 is not object or category\n","WARNING : aq14_2 is not object or category\n","WARNING : aq15_1 is not object or category\n","WARNING : aq15_2 is not object or category\n","WARNING : aq16_1 is not object or category\n","WARNING : aq16_2 is not object or category\n","WARNING : aq17_1 is not object or category\n","WARNING : aq17_2 is not object or category\n","WARNING : aq18_1 is not object or category\n","WARNING : aq18_2 is not object or category\n","WARNING : aq19_1 is not object or category\n","WARNING : aq19_2 is not object or category\n","WARNING : aq20_1 is not object or category\n","WARNING : aq20_2 is not object or category\n","WARNING : aq21_1 is not object or category\n","WARNING : aq21_2 is not object or category\n","WARNING : aq22_1 is not object or category\n","WARNING : aq22_2 is not object or category\n","WARNING : aq23_1 is not object or category\n","WARNING : aq23_2 is not object or category\n","WARNING : aq24_1 is not object or category\n","WARNING : aq24_2 is not object or category\n","WARNING : aq25_1 is not object or category\n","WARNING : aq25_2 is not object or category\n","WARNING : aq26_1 is not object or category\n","WARNING : aq26_2 is not object or category\n","WARNING : aq27_1 is not object or category\n","WARNING : aq27_2 is not object or category\n","WARNING : aq28_1 is not object or category\n","WARNING : aq28_2 is not object or category\n","WARNING : aq29_1 is not object or category\n","WARNING : aq29_2 is not object or category\n","WARNING : aq30_1 is not object or category\n","WARNING : aq30_2 is not object or category\n","WARNING : aq31_1 is not object or category\n","WARNING : aq31_2 is not object or category\n","WARNING : aq32_1 is not object or category\n","WARNING : aq32_2 is not object or category\n","WARNING : aq33_1 is not object or category\n","WARNING : aq33_2 is not object or category\n","WARNING : aq34_1 is not object or category\n","WARNING : aq34_2 is not object or category\n","WARNING : aq35_1 is not object or category\n","WARNING : aq35_2 is not object or category\n","WARNING : aq36_1 is not object or category\n","WARNING : aq36_2 is not object or category\n","WARNING : aq37_1 is not object or category\n","WARNING : aq37_2 is not object or category\n","WARNING : aq38_1 is not object or category\n","WARNING : aq38_2 is not object or category\n","WARNING : aq39_1 is not object or category\n","WARNING : aq39_2 is not object or category\n","WARNING : aq40_1 is not object or category\n","WARNING : aq40_2 is not object or category\n","WARNING : aq41_1 is not object or category\n","WARNING : aq41_2 is not object or category\n","0.0      142\n","1.0       22\n","2.0     1705\n","3.0      105\n","4.0       47\n","5.0      555\n","6.0      416\n","7.0      417\n","8.0      212\n","9.0      361\n","10.0     288\n","11.0      28\n","12.0     936\n","13.0     210\n","14.0     793\n","15.0     712\n","16.0     612\n","17.0     892\n","18.0     632\n","19.0      14\n","20.0       4\n","Name: bq1, dtype: int64 \n","\n","0.0    5921\n","1.0    1255\n","2.0     465\n","3.0     819\n","4.0     576\n","5.0      67\n","Name: bq2, dtype: int64 \n","\n","0.0    1648\n","1.0    3655\n","2.0    1188\n","3.0    1024\n","4.0     857\n","5.0     731\n","Name: bq3, dtype: int64 \n","\n","0.0    3992\n","1.0    5111\n","Name: bq4, dtype: int64 \n","\n","0.0     7216\n","1.0       61\n","2.0       18\n","3.0       16\n","4.0       12\n","5.0       39\n","6.0       14\n","7.0       15\n","8.0       16\n","9.0       14\n","10.0      16\n","11.0      16\n","12.0      23\n","13.0      58\n","14.0      10\n","15.0      20\n","16.0      10\n","17.0      10\n","18.0      16\n","19.0      11\n","20.0      15\n","21.0      11\n","22.0      16\n","23.0      26\n","24.0      23\n","25.0      14\n","26.0      11\n","27.0      17\n","28.0      17\n","29.0      17\n","30.0      14\n","31.0      13\n","32.0      20\n","33.0      22\n","34.0      10\n","35.0      34\n","36.0      18\n","37.0      15\n","38.0      17\n","39.0      10\n","40.0      12\n","41.0      14\n","42.0      15\n","43.0      16\n","44.0      10\n","45.0      11\n","46.0      14\n","47.0      15\n","48.0      17\n","49.0      11\n","50.0      16\n","51.0      10\n","52.0      52\n","53.0      10\n","54.0      10\n","55.0      17\n","56.0      14\n","57.0     149\n","58.0      13\n","59.0      15\n","60.0      13\n","61.0      12\n","62.0      14\n","63.0     106\n","64.0      18\n","65.0      49\n","66.0      13\n","67.0      22\n","68.0      15\n","69.0      12\n","70.0      83\n","71.0      13\n","72.0      10\n","73.0      14\n","74.0      14\n","75.0      11\n","76.0      15\n","77.0      12\n","78.0      13\n","79.0      21\n","80.0      12\n","81.0      10\n","82.0      10\n","83.0      39\n","84.0      11\n","85.0      14\n","86.0      13\n","87.0      11\n","88.0      12\n","89.0      16\n","90.0      11\n","91.0      10\n","92.0      22\n","93.0      14\n","94.0      15\n","95.0      11\n","Name: bq4_1a, dtype: int64 \n","\n","0.0    4347\n","1.0    4756\n","Name: bq5, dtype: int64 \n","\n","0.0    4756\n","1.0     566\n","2.0     972\n","3.0     975\n","4.0     733\n","5.0     536\n","6.0     565\n","Name: bq5_1, dtype: int64 \n","\n","0.0        3\n","1.0     8458\n","2.0        4\n","3.0        3\n","4.0        3\n","5.0        5\n","6.0        4\n","7.0        3\n","8.0        4\n","9.0        5\n","10.0       3\n","11.0       3\n","12.0       4\n","13.0       8\n","14.0       5\n","15.0       3\n","16.0       4\n","17.0       4\n","18.0       3\n","19.0       3\n","20.0      10\n","21.0       4\n","22.0       3\n","23.0       3\n","24.0       5\n","25.0      12\n","26.0       3\n","27.0       7\n","28.0       3\n","29.0       4\n","30.0       3\n","31.0       7\n","32.0       3\n","33.0       4\n","34.0       3\n","35.0       3\n","36.0       3\n","37.0       3\n","38.0       7\n","39.0      18\n","40.0       3\n","41.0       4\n","42.0       4\n","43.0       5\n","44.0       4\n","45.0      91\n","46.0       3\n","47.0       3\n","48.0       3\n","49.0       3\n","50.0       3\n","51.0      17\n","52.0      11\n","53.0       3\n","54.0       4\n","55.0       3\n","56.0       4\n","57.0       3\n","58.0       3\n","59.0       3\n","60.0       3\n","61.0       6\n","62.0       7\n","63.0       3\n","64.0       3\n","65.0       5\n","66.0       4\n","67.0       3\n","68.0      11\n","69.0      15\n","70.0      90\n","71.0      17\n","72.0       5\n","73.0       3\n","74.0       5\n","75.0       5\n","76.0       7\n","77.0       3\n","78.0       3\n","79.0       3\n","80.0       4\n","81.0       3\n","82.0       3\n","83.0       3\n","84.0       6\n","85.0       8\n","86.0      12\n","87.0      18\n","88.0       8\n","89.0       3\n","90.0       5\n","91.0       3\n","92.0       3\n","93.0       3\n","94.0       3\n","Name: bq5_2, dtype: int64 \n","\n","0.0     509\n","1.0    1022\n","2.0    1324\n","3.0    1055\n","4.0    1393\n","5.0    1836\n","6.0    1964\n","Name: bq6, dtype: int64 \n","\n","0.0     737\n","1.0    2344\n","2.0     468\n","3.0    1743\n","4.0    3107\n","5.0     517\n","6.0     187\n","Name: bq7, dtype: int64 \n","\n","0.0     167\n","1.0     986\n","2.0    2918\n","3.0    4199\n","4.0     833\n","Name: bq8_1, dtype: int64 \n","\n","0.0     618\n","1.0    1818\n","2.0    3292\n","3.0    2798\n","4.0     577\n","Name: bq8_2, dtype: int64 \n","\n","0.0     792\n","1.0    2113\n","2.0    3469\n","3.0    2345\n","4.0     384\n","Name: bq8_3, dtype: int64 \n","\n","0.0     110\n","1.0     875\n","2.0    2197\n","3.0    5039\n","4.0     882\n","Name: bq9, dtype: int64 \n","\n","0.0      75\n","1.0     688\n","2.0    2645\n","3.0    4810\n","4.0     885\n","Name: bq10, dtype: int64 \n","\n","0.0     353\n","1.0    2154\n","2.0    3640\n","3.0    2728\n","4.0     228\n","Name: bq11, dtype: int64 \n","\n","0.0     197\n","1.0    1843\n","2.0    4082\n","3.0    2600\n","4.0     381\n","Name: bq12_1, dtype: int64 \n","\n","0.0    1554\n","1.0     166\n","2.0    1068\n","3.0    4029\n","4.0    2007\n","5.0     279\n","Name: bq12_2, dtype: int64 \n","\n","0.0    1279\n","1.0      59\n","2.0     499\n","3.0    3500\n","4.0    3227\n","5.0     539\n","Name: bq12_3, dtype: int64 \n","\n","0.0     834\n","1.0      14\n","2.0     166\n","3.0    2865\n","4.0    4423\n","5.0     801\n","Name: bq12_4, dtype: int64 \n","\n","0.0      26\n","1.0     476\n","2.0    4370\n","3.0    3806\n","4.0     425\n","Name: bq12_5, dtype: int64 \n","\n","0.0     246\n","1.0    2042\n","2.0    3461\n","3.0    3178\n","4.0     176\n","Name: bq13, dtype: int64 \n","\n","0.0     292\n","1.0    2072\n","2.0    4043\n","3.0    2520\n","4.0     176\n","Name: bq14, dtype: int64 \n","\n","0.0     677\n","1.0    3787\n","2.0    2987\n","3.0    1552\n","4.0     100\n","Name: bq15_1, dtype: int64 \n","\n","0.0     182\n","1.0    1442\n","2.0    3473\n","3.0    3455\n","4.0     551\n","Name: bq15_2, dtype: int64 \n","\n","0.0     217\n","1.0    1550\n","2.0    4153\n","3.0    2770\n","4.0     413\n","Name: bq15_3, dtype: int64 \n","\n","0.0     194\n","1.0    1737\n","2.0    3320\n","3.0    3609\n","4.0     243\n","Name: bq16, dtype: int64 \n","\n","0.0     180\n","1.0    2395\n","2.0    4901\n","3.0    1551\n","4.0      76\n","Name: bq17, dtype: int64 \n","\n","0.0     140\n","1.0    1764\n","2.0    3987\n","3.0    2973\n","4.0     239\n","Name: bq18_1, dtype: int64 \n","\n","0.0     219\n","1.0    1990\n","2.0    3751\n","3.0    2772\n","4.0     371\n","Name: bq18_2, dtype: int64 \n","\n","0.0     909\n","1.0    2695\n","2.0    2931\n","3.0    2070\n","4.0     498\n","Name: bq18_3, dtype: int64 \n","\n","0.0     361\n","1.0    2198\n","2.0    3595\n","3.0    2532\n","4.0     417\n","Name: bq18_4, dtype: int64 \n","\n","0.0     533\n","1.0    2682\n","2.0    3694\n","3.0    2008\n","4.0     186\n","Name: bq18_5, dtype: int64 \n","\n","0.0     466\n","1.0    3340\n","2.0    3837\n","3.0    1321\n","4.0     139\n","Name: bq18_6, dtype: int64 \n","\n","0.0     181\n","1.0    1688\n","2.0    4550\n","3.0    2452\n","4.0     232\n","Name: bq18_7, dtype: int64 \n","\n","0.0     474\n","1.0    3056\n","2.0    3100\n","3.0    2257\n","4.0     216\n","Name: bq19, dtype: int64 \n","\n","0.0     518\n","1.0    3490\n","2.0    4288\n","3.0     807\n","Name: bq20, dtype: int64 \n","\n","0.0     466\n","1.0    3265\n","2.0    4131\n","3.0    1094\n","4.0     147\n","Name: bq21, dtype: int64 \n","\n","0.0    2004\n","1.0    1936\n","2.0    1289\n","3.0    1721\n","4.0     731\n","5.0    1422\n","Name: bq22, dtype: int64 \n","\n","0.0    2429\n","1.0    6674\n","Name: bq24_1, dtype: int64 \n","\n","0.0    3541\n","1.0    5562\n","Name: bq24_2, dtype: int64 \n","\n","0.0    3831\n","1.0    5272\n","Name: bq24_3, dtype: int64 \n","\n","0.0    2321\n","1.0    6782\n","Name: bq24_4, dtype: int64 \n","\n","0.0    1811\n","1.0    7292\n","Name: bq24_5, dtype: int64 \n","\n","0.0    1467\n","1.0    7636\n","Name: bq24_6, dtype: int64 \n","\n","0.0    1530\n","1.0    7573\n","Name: bq24_7, dtype: int64 \n","\n","0.0    1413\n","1.0    7690\n","Name: bq24_8, dtype: int64 \n","\n","0.0      23\n","1.0     618\n","2.0    3261\n","3.0    4842\n","4.0     359\n","Name: bq25, dtype: int64 \n","\n","0.0      17\n","1.0     308\n","2.0    3305\n","3.0    4626\n","4.0     847\n","Name: bq26, dtype: int64 \n","\n","0.0      50\n","1.0     842\n","2.0    3590\n","3.0    4288\n","4.0     333\n","Name: bq27, dtype: int64 \n","\n","0.0     108\n","1.0    1111\n","2.0    3818\n","3.0    3807\n","4.0     259\n","Name: bq28, dtype: int64 \n","\n","0.0     814\n","1.0    3553\n","2.0    3925\n","3.0     774\n","4.0      37\n","Name: bq29, dtype: int64 \n","\n","0.0     8012\n","1.0        9\n","2.0       14\n","3.0       23\n","4.0        5\n","5.0        6\n","6.0        9\n","7.0        6\n","8.0       15\n","9.0       11\n","10.0       7\n","11.0       6\n","12.0       8\n","13.0       8\n","14.0       9\n","15.0      27\n","16.0      29\n","17.0       6\n","18.0       5\n","19.0       5\n","20.0      95\n","21.0      50\n","22.0       5\n","23.0       5\n","24.0      26\n","25.0       8\n","26.0       7\n","27.0       8\n","28.0       6\n","29.0       6\n","30.0       7\n","31.0       5\n","32.0       6\n","33.0       6\n","34.0       9\n","35.0       7\n","36.0     269\n","37.0       7\n","38.0       5\n","39.0      10\n","40.0       5\n","41.0       5\n","42.0       6\n","43.0       5\n","44.0       9\n","45.0       5\n","46.0      23\n","47.0       6\n","48.0      51\n","49.0       5\n","50.0       8\n","51.0      24\n","52.0       6\n","53.0       5\n","54.0      25\n","55.0       5\n","56.0       7\n","57.0      15\n","58.0       5\n","59.0       5\n","60.0       5\n","61.0       8\n","62.0      13\n","63.0       5\n","64.0       8\n","65.0       5\n","66.0      12\n","67.0       5\n","68.0       7\n","69.0       7\n","70.0       8\n","71.0       5\n","72.0       7\n","73.0       5\n","74.0       6\n","75.0       5\n","Name: bq30, dtype: int64 \n","\n","0.0     7609\n","1.0        8\n","2.0       21\n","3.0        5\n","4.0       12\n","5.0        8\n","6.0       67\n","7.0        5\n","8.0        7\n","9.0        5\n","10.0       6\n","11.0      22\n","12.0       5\n","13.0      48\n","14.0      11\n","15.0       7\n","16.0       5\n","17.0       6\n","18.0       7\n","19.0       9\n","20.0      22\n","21.0       9\n","22.0       5\n","23.0      14\n","24.0      12\n","25.0       8\n","26.0      26\n","27.0       5\n","28.0       8\n","29.0       6\n","30.0      10\n","31.0      11\n","32.0      51\n","33.0      74\n","34.0      14\n","35.0      33\n","36.0      15\n","37.0      11\n","38.0      13\n","39.0       8\n","40.0      17\n","41.0       6\n","42.0       5\n","43.0      28\n","44.0       8\n","45.0       6\n","46.0      15\n","47.0      15\n","48.0       5\n","49.0      14\n","50.0       5\n","51.0      21\n","52.0       5\n","53.0       9\n","54.0      10\n","55.0       8\n","56.0      12\n","57.0       6\n","58.0      83\n","59.0      15\n","60.0      23\n","61.0       5\n","62.0     140\n","63.0       8\n","64.0       5\n","65.0       7\n","66.0      10\n","67.0       5\n","68.0       7\n","69.0      12\n","70.0      51\n","71.0       5\n","72.0      96\n","73.0      36\n","74.0      30\n","75.0       9\n","76.0       7\n","77.0       6\n","78.0     115\n","79.0       5\n","Name: bq32, dtype: int64 \n","\n","0.0     8747\n","1.0       14\n","2.0        3\n","3.0        4\n","4.0        3\n","5.0        4\n","6.0        4\n","7.0        4\n","8.0        3\n","9.0       38\n","10.0       3\n","11.0       3\n","12.0       3\n","13.0       6\n","14.0      21\n","15.0       6\n","16.0       3\n","17.0       3\n","18.0       4\n","19.0       4\n","20.0       3\n","21.0       3\n","22.0      15\n","23.0       3\n","24.0       3\n","25.0       3\n","26.0       4\n","27.0       3\n","28.0       5\n","29.0       4\n","30.0       9\n","31.0       3\n","32.0       3\n","33.0       3\n","34.0       4\n","35.0       3\n","36.0       9\n","37.0       4\n","38.0       3\n","39.0       5\n","40.0       3\n","41.0       3\n","42.0       3\n","43.0       3\n","44.0       3\n","45.0       8\n","46.0       4\n","47.0       7\n","48.0       3\n","49.0       3\n","50.0       9\n","51.0       3\n","52.0       3\n","53.0       3\n","54.0       7\n","55.0       3\n","56.0       3\n","57.0       4\n","58.0       3\n","59.0       4\n","60.0       4\n","61.0       5\n","62.0       3\n","63.0      18\n","64.0       6\n","65.0       3\n","66.0       3\n","67.0       4\n","68.0       3\n","Name: bq33, dtype: int64 \n","\n","0.0        2\n","1.0     9067\n","2.0        3\n","3.0        3\n","4.0        2\n","5.0        2\n","6.0        3\n","7.0        2\n","8.0        2\n","9.0        2\n","10.0       4\n","11.0       2\n","12.0       4\n","13.0       3\n","14.0       2\n","Name: bq34, dtype: int64 \n","\n","0.0     404\n","1.0    2647\n","2.0    3862\n","3.0    2092\n","4.0      98\n","Name: bq35, dtype: int64 \n","\n","0.0    6218\n","1.0    2885\n","Name: bq36, dtype: int64 \n","\n","0.0     263\n","1.0    1985\n","2.0    1261\n","3.0    4291\n","4.0     945\n","5.0     358\n","Name: bq38, dtype: int64 \n","\n","0.0     3555\n","1.0       85\n","2.0       47\n","3.0       67\n","4.0       60\n","5.0       44\n","6.0      334\n","7.0      129\n","8.0       18\n","9.0       63\n","10.0      32\n","11.0      21\n","12.0      54\n","13.0      24\n","14.0      37\n","15.0      63\n","16.0      24\n","17.0     381\n","18.0     179\n","19.0      26\n","20.0      18\n","21.0      29\n","22.0      18\n","23.0      26\n","24.0      21\n","25.0      70\n","26.0      62\n","27.0      21\n","28.0      26\n","29.0      31\n","30.0     108\n","31.0      18\n","32.0      25\n","33.0      58\n","34.0      42\n","35.0      22\n","36.0      63\n","37.0      22\n","38.0      21\n","39.0      76\n","40.0      22\n","41.0      19\n","42.0      30\n","43.0      18\n","44.0      17\n","45.0      17\n","46.0      40\n","47.0      56\n","48.0      17\n","49.0      48\n","50.0      47\n","51.0      23\n","52.0      29\n","53.0     145\n","54.0      27\n","55.0      54\n","56.0      26\n","57.0      24\n","58.0      23\n","59.0      18\n","60.0      29\n","61.0      35\n","62.0      27\n","63.0      18\n","64.0     146\n","65.0      49\n","66.0      38\n","67.0     110\n","68.0     386\n","69.0      33\n","70.0      17\n","71.0      31\n","72.0     156\n","73.0      84\n","74.0      18\n","75.0      18\n","76.0      19\n","77.0      71\n","78.0     140\n","79.0      27\n","80.0      20\n","81.0      17\n","82.0      24\n","83.0      49\n","84.0      30\n","85.0     154\n","86.0      22\n","87.0      49\n","88.0      93\n","89.0      39\n","90.0      26\n","91.0     114\n","92.0      32\n","93.0      67\n","94.0      72\n","95.0      51\n","96.0      26\n","97.0      46\n","Name: bq38_1, dtype: int64 \n","\n","0.0    7832\n","1.0    1271\n","Name: bq39_1, dtype: int64 \n","\n","0.0    6622\n","1.0     217\n","2.0     806\n","3.0     187\n","4.0     594\n","5.0     648\n","6.0      29\n","Name: bq39_2, dtype: int64 \n","\n","0.0    1271\n","1.0    6806\n","2.0    1026\n","Name: bq40, dtype: int64 \n","\n","0.0       2\n","1.0    1013\n","2.0    3407\n","3.0    2524\n","4.0    1697\n","5.0     391\n","6.0      67\n","7.0       2\n","Name: bq37_age_cat, dtype: int64 \n","\n","0.0    7804\n","1.0    1299\n","Name: bq41_1_unemp, dtype: int64 \n","\n","0.0    7817\n","1.0    1286\n","Name: bq41_3_unemp, dtype: int64 \n","\n","0.0      161\n","1.0       20\n","2.0     1750\n","3.0      129\n","4.0       50\n","5.0      557\n","6.0      439\n","7.0      433\n","8.0      207\n","9.0      397\n","10.0     290\n","11.0      29\n","12.0     998\n","13.0     203\n","14.0     819\n","15.0     749\n","16.0     642\n","17.0     949\n","18.0     652\n","19.0       8\n","20.0       4\n","Name: bq1, dtype: int64 \n","\n","0.0    6121\n","1.0    1314\n","2.0     494\n","3.0     890\n","4.0     582\n","5.0      85\n","Name: bq2, dtype: int64 \n","\n","0.0    1716\n","1.0    3738\n","2.0    1250\n","3.0    1135\n","4.0     900\n","5.0     747\n","Name: bq3, dtype: int64 \n","\n","0.0    4053\n","1.0    5433\n","Name: bq4, dtype: int64 \n","\n","0.0     7668\n","1.0       64\n","2.0       17\n","3.0       17\n","4.0        9\n","5.0       34\n","6.0       11\n","7.0       14\n","8.0       19\n","9.0       13\n","10.0      19\n","11.0      17\n","12.0      24\n","13.0      65\n","14.0       7\n","15.0      13\n","16.0       9\n","17.0      12\n","18.0      12\n","19.0      11\n","20.0      15\n","21.0      11\n","22.0      21\n","23.0      21\n","24.0      26\n","25.0      15\n","26.0       7\n","27.0      16\n","28.0      16\n","29.0      18\n","30.0      12\n","31.0      12\n","32.0      20\n","33.0      21\n","34.0       6\n","35.0      40\n","36.0      27\n","37.0      10\n","38.0      16\n","39.0       8\n","40.0      12\n","41.0      13\n","42.0      16\n","43.0      22\n","44.0      10\n","45.0       7\n","46.0      17\n","47.0      15\n","48.0      16\n","49.0       8\n","50.0      14\n","51.0       6\n","52.0      43\n","53.0       9\n","54.0      11\n","55.0      14\n","56.0      14\n","57.0     143\n","58.0      10\n","59.0      16\n","60.0      11\n","61.0      13\n","62.0      13\n","63.0     117\n","64.0      13\n","65.0      43\n","66.0      18\n","67.0      16\n","68.0      18\n","69.0      15\n","70.0      72\n","71.0       5\n","72.0       7\n","73.0      15\n","74.0      12\n","75.0      12\n","76.0      16\n","77.0       4\n","78.0       7\n","79.0      23\n","80.0      15\n","81.0       6\n","82.0       8\n","83.0      51\n","84.0       7\n","85.0      11\n","86.0      12\n","87.0      10\n","88.0       5\n","89.0      17\n","90.0      12\n","91.0       6\n","92.0      27\n","93.0      13\n","94.0      23\n","95.0       4\n","Name: bq4_1a, dtype: int64 \n","\n","0.0    4712\n","1.0    4774\n","Name: bq5, dtype: int64 \n","\n","0.0    4774\n","1.0     650\n","2.0    1071\n","3.0    1047\n","4.0     790\n","5.0     585\n","6.0     569\n","Name: bq5_1, dtype: int64 \n","\n","1.0     8963\n","5.0        6\n","6.0        1\n","7.0        1\n","8.0        3\n","9.0        1\n","11.0       1\n","12.0       3\n","13.0       1\n","14.0       4\n","15.0       1\n","17.0      11\n","19.0       1\n","20.0       8\n","23.0       1\n","25.0       6\n","26.0       3\n","27.0       9\n","28.0       2\n","30.0       1\n","31.0       5\n","32.0       3\n","33.0       2\n","35.0       3\n","38.0       4\n","39.0      34\n","40.0       2\n","41.0       5\n","43.0       1\n","44.0       5\n","45.0      71\n","46.0       3\n","47.0       5\n","48.0       3\n","49.0       2\n","50.0       1\n","51.0      16\n","52.0      14\n","54.0       3\n","56.0      10\n","58.0       2\n","59.0       3\n","60.0       7\n","61.0      12\n","62.0      10\n","63.0       2\n","65.0       3\n","66.0       4\n","67.0       5\n","68.0      13\n","69.0       9\n","70.0      89\n","71.0      12\n","72.0       3\n","73.0       9\n","74.0       1\n","75.0       4\n","76.0       7\n","78.0       3\n","80.0       6\n","81.0       2\n","82.0       2\n","83.0       5\n","84.0       1\n","85.0      13\n","86.0      14\n","87.0      21\n","88.0       2\n","91.0       2\n","94.0       1\n","Name: bq5_2, dtype: int64 \n","\n","0.0     480\n","1.0    1148\n","2.0    1357\n","3.0    1075\n","4.0    1466\n","5.0    1902\n","6.0    2058\n","Name: bq6, dtype: int64 \n","\n","0.0     810\n","1.0    2416\n","2.0     507\n","3.0    1753\n","4.0    3266\n","5.0     542\n","6.0     192\n","Name: bq7, dtype: int64 \n","\n","0.0     153\n","1.0     994\n","2.0    3021\n","3.0    4380\n","4.0     938\n","Name: bq8_1, dtype: int64 \n","\n","0.0     659\n","1.0    1930\n","2.0    3345\n","3.0    2895\n","4.0     657\n","Name: bq8_2, dtype: int64 \n","\n","0.0     837\n","1.0    2224\n","2.0    3541\n","3.0    2433\n","4.0     451\n","Name: bq8_3, dtype: int64 \n","\n","0.0     116\n","1.0     931\n","2.0    2242\n","3.0    5256\n","4.0     941\n","Name: bq9, dtype: int64 \n","\n","0.0      67\n","1.0     768\n","2.0    2751\n","3.0    4943\n","4.0     957\n","Name: bq10, dtype: int64 \n","\n","0.0     379\n","1.0    2214\n","2.0    3865\n","3.0    2811\n","4.0     217\n","Name: bq11, dtype: int64 \n","\n","0.0     232\n","1.0    1963\n","2.0    4269\n","3.0    2604\n","4.0     418\n","Name: bq12_1, dtype: int64 \n","\n","0.0    1609\n","1.0     160\n","2.0    1130\n","3.0    4179\n","4.0    2108\n","5.0     300\n","Name: bq12_2, dtype: int64 \n","\n","0.0    1332\n","1.0      54\n","2.0     521\n","3.0    3611\n","4.0    3454\n","5.0     514\n","Name: bq12_3, dtype: int64 \n","\n","0.0     884\n","1.0      12\n","2.0     183\n","3.0    2930\n","4.0    4657\n","5.0     820\n","Name: bq12_4, dtype: int64 \n","\n","0.0      25\n","1.0     498\n","2.0    4613\n","3.0    3938\n","4.0     412\n","Name: bq12_5, dtype: int64 \n","\n","0.0     253\n","1.0    2146\n","2.0    3691\n","3.0    3186\n","4.0     210\n","Name: bq13, dtype: int64 \n","\n","0.0     317\n","1.0    2194\n","2.0    4204\n","3.0    2569\n","4.0     202\n","Name: bq14, dtype: int64 \n","\n","0.0     805\n","1.0    3883\n","2.0    3015\n","3.0    1669\n","4.0     114\n","Name: bq15_1, dtype: int64 \n","\n","0.0     201\n","1.0    1532\n","2.0    3528\n","3.0    3623\n","4.0     602\n","Name: bq15_2, dtype: int64 \n","\n","0.0     229\n","1.0    1627\n","2.0    4304\n","3.0    2835\n","4.0     491\n","Name: bq15_3, dtype: int64 \n","\n","0.0     207\n","1.0    1890\n","2.0    3377\n","3.0    3741\n","4.0     271\n","Name: bq16, dtype: int64 \n","\n","0.0     205\n","1.0    2472\n","2.0    5188\n","3.0    1567\n","4.0      54\n","Name: bq17, dtype: int64 \n","\n","0.0     143\n","1.0    1852\n","2.0    4046\n","3.0    3156\n","4.0     289\n","Name: bq18_1, dtype: int64 \n","\n","0.0     225\n","1.0    2069\n","2.0    3738\n","3.0    3010\n","4.0     444\n","Name: bq18_2, dtype: int64 \n","\n","0.0    1000\n","1.0    2765\n","2.0    3024\n","3.0    2168\n","4.0     529\n","Name: bq18_3, dtype: int64 \n","\n","0.0     347\n","1.0    2202\n","2.0    3787\n","3.0    2723\n","4.0     427\n","Name: bq18_4, dtype: int64 \n","\n","0.0     567\n","1.0    2737\n","2.0    3877\n","3.0    2090\n","4.0     215\n","Name: bq18_5, dtype: int64 \n","\n","0.0     515\n","1.0    3390\n","2.0    4006\n","3.0    1448\n","4.0     127\n","Name: bq18_6, dtype: int64 \n","\n","0.0     182\n","1.0    1702\n","2.0    4690\n","3.0    2642\n","4.0     270\n","Name: bq18_7, dtype: int64 \n","\n","0.0     511\n","1.0    3159\n","2.0    3196\n","3.0    2389\n","4.0     231\n","Name: bq19, dtype: int64 \n","\n","0.0     564\n","1.0    3594\n","2.0    4535\n","3.0     793\n","Name: bq20, dtype: int64 \n","\n","0.0     550\n","1.0    3348\n","2.0    4317\n","3.0    1123\n","4.0     148\n","Name: bq21, dtype: int64 \n","\n","0.0    2070\n","1.0    1947\n","2.0    1286\n","3.0    1842\n","4.0     840\n","5.0    1501\n","Name: bq22, dtype: int64 \n","\n","0.0    2520\n","1.0    6966\n","Name: bq24_1, dtype: int64 \n","\n","0.0    3642\n","1.0    5844\n","Name: bq24_2, dtype: int64 \n","\n","0.0    3938\n","1.0    5548\n","Name: bq24_3, dtype: int64 \n","\n","0.0    2345\n","1.0    7141\n","Name: bq24_4, dtype: int64 \n","\n","0.0    1847\n","1.0    7639\n","Name: bq24_5, dtype: int64 \n","\n","0.0    1546\n","1.0    7940\n","Name: bq24_6, dtype: int64 \n","\n","0.0    1605\n","1.0    7881\n","Name: bq24_7, dtype: int64 \n","\n","0.0    1450\n","1.0    8036\n","Name: bq24_8, dtype: int64 \n","\n","0.0      26\n","1.0     707\n","2.0    3314\n","3.0    5096\n","4.0     343\n","Name: bq25, dtype: int64 \n","\n","0.0      14\n","1.0     317\n","2.0    3465\n","3.0    4773\n","4.0     917\n","Name: bq26, dtype: int64 \n","\n","0.0      54\n","1.0     950\n","2.0    3648\n","3.0    4486\n","4.0     348\n","Name: bq27, dtype: int64 \n","\n","0.0      97\n","1.0    1148\n","2.0    3952\n","3.0    4010\n","4.0     279\n","Name: bq28, dtype: int64 \n","\n","0.0     821\n","1.0    3611\n","2.0    4217\n","3.0     801\n","4.0      36\n","Name: bq29, dtype: int64 \n","\n","0.0     8464\n","1.0        5\n","2.0       18\n","3.0       20\n","5.0       11\n","6.0       15\n","7.0        2\n","8.0       13\n","9.0       11\n","10.0       7\n","11.0       5\n","12.0       6\n","13.0       7\n","14.0       5\n","15.0      16\n","16.0      25\n","17.0       4\n","19.0       2\n","20.0      81\n","21.0      44\n","22.0       6\n","23.0       5\n","24.0      32\n","25.0       8\n","26.0       6\n","27.0      12\n","28.0       2\n","29.0       1\n","30.0       4\n","31.0       4\n","32.0      19\n","33.0       9\n","34.0       4\n","35.0       7\n","36.0     277\n","37.0       9\n","38.0       3\n","39.0      10\n","40.0       2\n","41.0       4\n","42.0       2\n","43.0      10\n","44.0       7\n","45.0       3\n","46.0      17\n","47.0       7\n","48.0      71\n","49.0       6\n","50.0       5\n","51.0      12\n","52.0       1\n","53.0      13\n","54.0      14\n","55.0       4\n","56.0       6\n","57.0      13\n","58.0       7\n","59.0       3\n","60.0       2\n","61.0      13\n","62.0       8\n","63.0       1\n","64.0       4\n","65.0       5\n","66.0      14\n","67.0       1\n","68.0      10\n","69.0       4\n","70.0       9\n","71.0       9\n","72.0       3\n","73.0       6\n","74.0       7\n","75.0       4\n","Name: bq30, dtype: int64 \n","\n","0.0     7963\n","1.0        2\n","2.0       23\n","3.0        4\n","4.0       12\n","5.0        7\n","6.0       68\n","7.0        4\n","8.0       10\n","9.0        6\n","10.0      10\n","11.0      18\n","12.0       3\n","13.0      40\n","14.0      18\n","15.0       7\n","16.0       5\n","17.0       2\n","18.0       3\n","19.0      16\n","20.0      17\n","21.0       9\n","22.0       6\n","23.0       4\n","24.0      13\n","25.0       7\n","26.0      12\n","27.0       2\n","28.0       9\n","29.0      10\n","30.0       4\n","31.0      11\n","32.0      46\n","33.0      99\n","34.0      13\n","35.0      24\n","36.0      15\n","37.0      12\n","38.0      15\n","39.0       5\n","40.0       8\n","41.0       3\n","42.0       2\n","43.0      27\n","44.0       8\n","45.0       5\n","46.0      16\n","47.0      14\n","48.0       8\n","49.0      16\n","50.0       4\n","51.0      22\n","52.0       6\n","53.0       7\n","54.0       5\n","55.0      11\n","56.0       4\n","57.0       4\n","58.0      89\n","59.0      20\n","60.0      19\n","61.0       6\n","62.0     155\n","63.0      13\n","64.0       3\n","65.0      12\n","66.0       6\n","67.0       4\n","68.0      17\n","69.0      23\n","70.0      58\n","71.0       5\n","72.0     120\n","73.0      30\n","74.0      26\n","75.0      12\n","76.0       2\n","77.0       8\n","78.0     128\n","79.0       6\n","Name: bq32, dtype: int64 \n","\n","0.0     9166\n","1.0       19\n","2.0        2\n","3.0        3\n","4.0        3\n","5.0        6\n","6.0        3\n","7.0        1\n","9.0       57\n","10.0       1\n","11.0       1\n","12.0       3\n","13.0       9\n","14.0      36\n","15.0       4\n","16.0       1\n","17.0       1\n","18.0       3\n","19.0       3\n","20.0       1\n","21.0       8\n","22.0      17\n","23.0       3\n","28.0       8\n","29.0      12\n","30.0      10\n","31.0       3\n","32.0       3\n","34.0       7\n","35.0       1\n","36.0      13\n","37.0       3\n","38.0       3\n","39.0       4\n","40.0       3\n","41.0       1\n","42.0       1\n","43.0       3\n","44.0       2\n","45.0       7\n","46.0       2\n","47.0       5\n","50.0       4\n","53.0       2\n","54.0       3\n","55.0       3\n","56.0       2\n","58.0       2\n","59.0       3\n","60.0       2\n","61.0       1\n","62.0       1\n","63.0      17\n","64.0       1\n","65.0       2\n","68.0       1\n","Name: bq33, dtype: int64 \n","\n","1.0     9474\n","2.0        2\n","3.0        1\n","4.0        2\n","5.0        1\n","6.0        2\n","7.0        1\n","8.0        1\n","13.0       1\n","14.0       1\n","Name: bq34, dtype: int64 \n","\n","0.0     375\n","1.0    2789\n","2.0    3967\n","3.0    2255\n","4.0     100\n","Name: bq35, dtype: int64 \n","\n","0.0    6551\n","1.0    2935\n","Name: bq36, dtype: int64 \n","\n","0.0     278\n","1.0    2116\n","2.0    1279\n","3.0    4405\n","4.0     994\n","5.0     414\n","Name: bq38, dtype: int64 \n","\n","0.0     3725\n","1.0       80\n","2.0       57\n","3.0       57\n","4.0       69\n","5.0       53\n","6.0      314\n","7.0      115\n","8.0       17\n","9.0       76\n","10.0      36\n","11.0      25\n","12.0      56\n","13.0      22\n","14.0      42\n","15.0      64\n","16.0      16\n","17.0     384\n","18.0     177\n","19.0      33\n","20.0      12\n","21.0      36\n","22.0      12\n","23.0      42\n","24.0      26\n","25.0      73\n","26.0      85\n","27.0      13\n","28.0      25\n","29.0      33\n","30.0     126\n","31.0      18\n","32.0      19\n","33.0      75\n","34.0      64\n","35.0      34\n","36.0      59\n","37.0      25\n","38.0      35\n","39.0      64\n","40.0      24\n","41.0      16\n","42.0      29\n","43.0      20\n","44.0      12\n","45.0      16\n","46.0      36\n","47.0      52\n","48.0      19\n","49.0      44\n","50.0      48\n","51.0      18\n","52.0      26\n","53.0     131\n","54.0      17\n","55.0      49\n","56.0      26\n","57.0      28\n","58.0      27\n","59.0      25\n","60.0      31\n","61.0      34\n","62.0      22\n","63.0      18\n","64.0     153\n","65.0      47\n","66.0      39\n","67.0     131\n","68.0     435\n","69.0      22\n","70.0      13\n","71.0      27\n","72.0     148\n","73.0     112\n","74.0      25\n","75.0      25\n","76.0      29\n","77.0      65\n","78.0     126\n","79.0      40\n","80.0      27\n","81.0      15\n","82.0      24\n","83.0      67\n","84.0      20\n","85.0     166\n","86.0      23\n","87.0      49\n","88.0      85\n","89.0      47\n","90.0      26\n","91.0     100\n","92.0      35\n","93.0      68\n","94.0      83\n","95.0      61\n","96.0      25\n","97.0      66\n","Name: bq38_1, dtype: int64 \n","\n","0.0    8153\n","1.0    1333\n","Name: bq39_1, dtype: int64 \n","\n","0.0    6827\n","1.0     229\n","2.0     886\n","3.0     211\n","4.0     609\n","5.0     683\n","6.0      41\n","Name: bq39_2, dtype: int64 \n","\n","0.0    1333\n","1.0    7046\n","2.0    1107\n","Name: bq40, dtype: int64 \n","\n","0.0       8\n","1.0    1147\n","2.0    3456\n","3.0    2657\n","4.0    1745\n","5.0     415\n","6.0      55\n","7.0       3\n","Name: bq37_age_cat, dtype: int64 \n","\n","0.0    8115\n","1.0    1371\n","Name: bq41_1_unemp, dtype: int64 \n","\n","0.0    8144\n","1.0    1342\n","Name: bq41_3_unemp, dtype: int64 \n","\n","0\n","0\n","(9103, 155)\n","(9486, 155)\n","(9103, 986)\n","(9486, 986)\n"]}]},{"cell_type":"markdown","source":["# Preprocessing - 2018"],"metadata":{"id":"MfLV64Rur4Du"}},{"cell_type":"code","source":["full_x.info(verbose=True, null_counts=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4a7DvHjr2k-k","executionInfo":{"status":"ok","timestamp":1642218779079,"user_tz":-540,"elapsed":358,"user":{"displayName":"김영준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpTdFUUaMn51B-vREgj8EQWx2hKK-I4nl4g_I8lA=s64","userId":"06606532799291918175"}},"outputId":"5514ac57-f0d1-4459-b0f1-f1cef3ad607e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9072 entries, 0 to 9071\n","Data columns (total 139 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   cq1      9072 non-null   int64  \n"," 1   cq2      9072 non-null   int64  \n"," 2   cq3      9072 non-null   int64  \n"," 3   cq4      9072 non-null   int64  \n"," 4   cq5      9072 non-null   int64  \n"," 5   cq6      9072 non-null   int64  \n"," 6   cq7      9072 non-null   int64  \n"," 7   cq8      9072 non-null   int64  \n"," 8   cq9      9072 non-null   int64  \n"," 9   cq10     9072 non-null   int64  \n"," 10  cq11     9072 non-null   int64  \n"," 11  cq12     9072 non-null   int64  \n"," 12  cq13     9072 non-null   int64  \n"," 13  cq14     9072 non-null   int64  \n"," 14  cq15     9072 non-null   int64  \n"," 15  cq16     9072 non-null   int64  \n"," 16  cq17     9072 non-null   int64  \n"," 17  cq18     9072 non-null   float64\n"," 18  cq19     9072 non-null   float64\n"," 19  cq20     9072 non-null   float64\n"," 20  cq21     9072 non-null   float64\n"," 21  cq22     9072 non-null   float64\n"," 22  cq23     9072 non-null   float64\n"," 23  cq24     9072 non-null   float64\n"," 24  cq25     9072 non-null   float64\n"," 25  cq26     9072 non-null   float64\n"," 26  cq27     9072 non-null   float64\n"," 27  cq28     9072 non-null   float64\n"," 28  cq29     9072 non-null   float64\n"," 29  cq30     9072 non-null   float64\n"," 30  cq31     9072 non-null   float64\n"," 31  cq32     9072 non-null   float64\n"," 32  cq33     9072 non-null   float64\n"," 33  cq34     9072 non-null   float64\n"," 34  cq35     9072 non-null   float64\n"," 35  cq36     9072 non-null   float64\n"," 36  cq37     9072 non-null   float64\n"," 37  cq38     9072 non-null   float64\n"," 38  cq39     9072 non-null   float64\n"," 39  cq40     9072 non-null   float64\n"," 40  cq41     9072 non-null   float64\n"," 41  cq42     9072 non-null   float64\n"," 42  cq43     9072 non-null   float64\n"," 43  cq44     9072 non-null   float64\n"," 44  cq45     9072 non-null   float64\n"," 45  cq46     9072 non-null   float64\n"," 46  cq47     9072 non-null   float64\n"," 47  cq48     9072 non-null   float64\n"," 48  cq49     9072 non-null   float64\n"," 49  cq50_1   9072 non-null   float64\n"," 50  cq50_2   9072 non-null   float64\n"," 51  cq50_3   9072 non-null   float64\n"," 52  cq50_4   9072 non-null   float64\n"," 53  cq50_5   9072 non-null   float64\n"," 54  cq50_6   9072 non-null   float64\n"," 55  cq50_7   9072 non-null   float64\n"," 56  cq50_8   9072 non-null   float64\n"," 57  iq1      9072 non-null   float64\n"," 58  iq2      9072 non-null   float64\n"," 59  iq3      9072 non-null   float64\n"," 60  iq4      9072 non-null   float64\n"," 61  iq5      9072 non-null   float64\n"," 62  iq6      9072 non-null   float64\n"," 63  bq1      9072 non-null   float64\n"," 64  bq2      9072 non-null   float64\n"," 65  bq3      9072 non-null   float64\n"," 66  bq4      9056 non-null   object \n"," 67  bq4_1a   3994 non-null   object \n"," 68  bq4_1b   1353 non-null   object \n"," 69  bq4_1c   398 non-null    object \n"," 70  bq5      9062 non-null   float64\n"," 71  bq5_1    4715 non-null   object \n"," 72  bq5_2    4726 non-null   object \n"," 73  bq6      9072 non-null   float64\n"," 74  bq7      9072 non-null   float64\n"," 75  bq8_1    9072 non-null   float64\n"," 76  bq8_2    9072 non-null   float64\n"," 77  bq8_3    9072 non-null   float64\n"," 78  bq9      9072 non-null   float64\n"," 79  bq10     9072 non-null   float64\n"," 80  bq11     9072 non-null   float64\n"," 81  bq12_1   9071 non-null   float64\n"," 82  bq12_2   7898 non-null   float64\n"," 83  bq12_3   8064 non-null   float64\n"," 84  bq12_4   8322 non-null   float64\n"," 85  bq12_5   9072 non-null   float64\n"," 86  bq13     9072 non-null   float64\n"," 87  bq14     9072 non-null   float64\n"," 88  bq15     9072 non-null   float64\n"," 89  bq16     9072 non-null   float64\n"," 90  bq17     9072 non-null   float64\n"," 91  bq18     9072 non-null   float64\n"," 92  bq19     9072 non-null   float64\n"," 93  bq20     9072 non-null   float64\n"," 94  bq21     9071 non-null   float64\n"," 95  bq221    7116 non-null   float64\n"," 96  bq222    1275 non-null   float64\n"," 97  bq223    9070 non-null   float64\n"," 98  bq231    6822 non-null   float64\n"," 99  bq232    9072 non-null   float64\n"," 100 bq233    9072 non-null   float64\n"," 101 bq234    9041 non-null   float64\n"," 102 bq235    1336 non-null   float64\n"," 103 bq241    5495 non-null   float64\n"," 104 bq242    1542 non-null   float64\n"," 105 bq243    133 non-null    float64\n"," 106 bq244    474 non-null    float64\n"," 107 bq245    1553 non-null   float64\n"," 108 bq25     9069 non-null   float64\n"," 109 bq25_1   8242 non-null   float64\n"," 110 bq26_1   9069 non-null   float64\n"," 111 bq26_1a  6687 non-null   float64\n"," 112 bq26_2   9069 non-null   float64\n"," 113 bq26_2a  7295 non-null   float64\n"," 114 bq26_3   9066 non-null   float64\n"," 115 bq26_3a  6506 non-null   float64\n"," 116 bq26_4   9064 non-null   float64\n"," 117 bq26_4a  6276 non-null   float64\n"," 118 bq27     9072 non-null   float64\n"," 119 bq28     9072 non-null   object \n"," 120 bq28_1   9052 non-null   object \n"," 121 bq29     5451 non-null   object \n"," 122 bq30     9052 non-null   object \n"," 123 bq31     5654 non-null   object \n"," 124 bq32     5025 non-null   object \n"," 125 bq33     3813 non-null   object \n"," 126 bq34     9072 non-null   object \n"," 127 bq35     9072 non-null   object \n"," 128 bq36     9071 non-null   object \n"," 129 bq37     9072 non-null   object \n"," 130 bq37_1   8587 non-null   object \n"," 131 bq38     9071 non-null   float64\n"," 132 bq38_1   7777 non-null   float64\n"," 133 bq38_2   1295 non-null   float64\n"," 134 bq39     7777 non-null   float64\n"," 135 bq40     9069 non-null   object \n"," 136 bq41_1   7802 non-null   float64\n"," 137 bq41_2   7684 non-null   float64\n"," 138 bq41_3   1248 non-null   float64\n","dtypes: float64(103), int64(17), object(19)\n","memory usage: 9.6+ MB\n"]}]},{"cell_type":"code","source":["a = [\"bq221\", \"bq222\", \"bq223\", \"bq231\", \"bq232\", \"bq233\", \"bq234\",\n","     \"bq235\", \"bq241\", \"bq242\", \"bq243\", \"bq244\", \"bq245\"]"],"metadata":{"id":"RoGvJIas6NLm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ===== Preprocessing =====\n","target_year = \"2018\"\n","target_var = \"knowcode\"\n","full_x = read_csv(folder_path + \"train/KNOW_\" + target_year + \".csv\", dtype={target_var: str}, na_values=[\"\", \" \"], encoding=\"utf-8\")\n","full_x.drop([\"idx\"], axis=1, inplace=True)\n","print(\"before removing dups\", full_x.shape[0])\n","full_x.drop_duplicates(inplace=True)\n","print(\"after removing dups\", full_x.shape[0])\n","\n","print(\"before removing invalid values on target\", full_x.shape[0])\n","full_x[target_var].replace(\" \", \"\", inplace=True)\n","full_x = full_x[(full_x[target_var] != \"9999999\") & (full_x[target_var] != nan)]\n","print(\"after removing invalid values on target\", full_x.shape[0])\n","full_x.reset_index(drop=True, inplace=True)\n","\n","full_y = full_x[target_var].to_frame()\n","target_encoder = copy.deepcopy(MyLabelEncoder())\n","full_y = target_encoder.fit_transform(full_y, [target_var])\n","print(target_encoder.dic_cat)\n","full_y.isna().sum()\n","full_y[target_var] = full_y[target_var].astype(\"int\")\n","print(full_y[target_var].value_counts())\n","full_x.drop([target_var], axis=1, inplace=True)\n","\n","test_x = read_csv(folder_path + \"test/KNOW_\" + target_year + \"_test.csv\", dtype={target_var: str}, na_values=[\"\", \" \"], encoding=\"utf-8\")\n","submission_idx_start = test_x[\"idx\"].iloc[0]\n","submission_idx_end = test_x[\"idx\"][-1:].iloc[0]\n","test_x.drop([\"idx\"], axis=1, inplace=True)\n","\n","\n","\n","# # # text feature 정리\n","# # \"bq4_1a\" 필요자격증1\n","# # \"bq4_1b\" 필요자격증2\n","# # \"bq4_1c\" 필요자격증3\n","# # \"bq5_2\" 요구훈련종류\n","# # \"bq19_1\" : 향후 일자리 변화 이유\n","# # \"bq30\" : 유사직업명\n","# # \"bq31\" : 사용도구 및 프로그램\n","# # \"bq32\" : 이전직업\n","# # \"bq33\" : 전직 가능 직업\n","# # \"bq34\" : 신직업 발굴\n","# # \"bq38_1\" : 전공\n","\n","\n","# # # 자격증 컬럼 처리\n","# # 기술사 - 기능장 - 기사 - 산업기사 - 기능사\n","# remove_text = [\"기술사\", \"기능장\", \"기사\", \"산업기사\", \"기능사\",\n","#                \"자격증\", \"자격\", \"면허증\", \"면허\", \"전문가\"]\n","\n","# text_vars = [\"bq4_1b\", \"bq4_1c\", \"bq5_2\", \"bq19_1\",\n","#              \"bq30\", \"bq31\", \"bq32\", \"bq33\", \"bq34\", \"bq38_1\"]\n","\n","# # check low frequency word\n","# low_freq = full_x[\"bq4_1a\"].value_counts().index[full_x[\"bq4_1a\"].value_counts() < 2]\n","\n","# full_x[\"bq4_1a\"] = full_x[\"bq4_1a\"].str.lower()\n","# for idx, value in enumerate(full_x[\"bq4_1a\"]):\n","#     # break\n","#     # 띄어쓰기 제거\n","#     if isna(value) or value in low_freq:\n","#         full_x[\"bq4_1a\"][idx] = \"없음\"\n","#     else:\n","#         value = value.replace(\" \", \"\")\n","#         for i in remove_text:\n","#             value = value.replace(i, \"\")\n","#         value = re.sub('[1-9급()<>]', \"\", value)\n","#         full_x[\"bq4_1a\"][idx] = value\n","\n","# test_x[\"bq4_1a\"] = test_x[\"bq4_1a\"].str.lower()\n","# for idx, value in enumerate(test_x[\"bq4_1a\"]):\n","#     # break\n","#     # 띄어쓰기 제거\n","#     if isna(value) or value in low_freq:\n","#         test_x[\"bq4_1a\"][idx] = \"없음\"\n","#     else:\n","#         value = value.replace(\" \", \"\")\n","#         for i in remove_text:\n","#             value = value.replace(i, \"\")\n","#         value = re.sub('[1-9급()<>]', \"\", value)\n","#         test_x[\"bq4_1a\"][idx] = value\n","\n","\n","# full_x.drop(text_vars, axis=1, inplace=True)\n","# test_x.drop(text_vars, axis=1, inplace=True)\n","\n","\n","\n","# full_x.isna().sum()\n","# print(full_x.isna().sum().index[full_x.isna().sum() != 0])\n","# test_x.isna().sum()\n","# print(test_x.isna().sum().index[full_x.isna().sum() != 0])\n","\n","# # age transformation\n","# full_x[\"bq37\"] = pd.cut(full_x[\"bq37\"], [i * 10 for i in range(1, 10)]).astype(\"object\")\n","# test_x[\"bq37\"] = pd.cut(test_x[\"bq37\"], [i * 10 for i in range(1, 10)]).astype(\"object\")\n","\n","# # 이상치 aq41_1 == 33\n","# full_y = full_y[~(full_x[\"aq41_1\"] == 33)]\n","# full_x = full_x[~(full_x[\"aq41_1\"] == 33)]\n","\n","# # # 해당 업계 초봉, 자격증 컬럼 drop\n","# # full_x.drop([\"bq4_1a\", \"bq41_2\"], axis=1, inplace=True)\n","# # test_x.drop([\"bq4_1a\", \"bq41_2\"], axis=1, inplace=True)\n","\n","# # 해당 업계 초봉 drop\n","# full_x.drop([\"bq41_2\"], axis=1, inplace=True)\n","# test_x.drop([\"bq41_2\"], axis=1, inplace=True)\n","\n","# bin_vars = []\n","# ord_vars = list(full_x.columns[:82])\n","# num_vars = [\"bq23\", \"bq41_1\", \"bq41_3\"]\n","# cat_vars = diff(full_x.columns, num_vars + ord_vars + bin_vars)\n","\n","# for i in cat_vars:\n","#     try:\n","#         full_x[i] = full_x[i].fillna(0.0).astype(\"int\")\n","#         test_x[i] = test_x[i].fillna(0.0).astype(\"int\")\n","#     except:\n","#         pass\n","\n","# label_encoder = copy.deepcopy(MyLabelEncoder())\n","# full_x = label_encoder.fit_transform(full_x, cat_vars)\n","# for i in cat_vars:\n","#     print(full_x[i].value_counts().sort_index(), \"\\n\")\n","# test_x = label_encoder.transform(test_x)\n","# for i in cat_vars:\n","#     print(test_x[i].value_counts().sort_index(), \"\\n\")\n","\n","# print(full_x.isna().sum())\n","# print(test_x.isna().sum())\n","\n","# knn_imputer = copy.deepcopy(MyKNNImputer())\n","# full_x = knn_imputer.fit_transform(full_x, full_y, cat_vars + ord_vars)\n","# test_x = knn_imputer.transform(test_x)\n","\n","# print(full_x.isna().sum().sum())\n","# print(test_x.isna().sum().sum())\n","\n","# print(full_x.shape[1] == len(cat_vars) + len(bin_vars) + len(ord_vars) + len(num_vars))\n","\n","# print(full_x.head(20))\n","# print(test_x.head(20))\n","\n","# oh_encoder = MyOneHotEncoder()\n","# full_x_oh = oh_encoder.fit_transform(full_x, cat_vars)\n","# test_x_oh = oh_encoder.transform(test_x)\n","\n","# print(full_x_oh.isna().sum().sum())\n","# print(test_x_oh.isna().sum().sum())\n","\n","# print(full_x.shape)\n","# print(test_x.shape)\n","# print(full_x_oh.shape)\n","# print(test_x_oh.shape)"],"metadata":{"id":"Db61s9n_s85i","executionInfo":{"status":"ok","timestamp":1642218540540,"user_tz":-540,"elapsed":3477,"user":{"displayName":"김영준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpTdFUUaMn51B-vREgj8EQWx2hKK-I4nl4g_I8lA=s64","userId":"06606532799291918175"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"583bf681-83a1-4dc1-bbd2-944f478e79a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["before removing dups 9072\n","after removing dups 9072\n","before removing invalid values on target 9072\n","after removing invalid values on target 9072\n","{'knowcode': {'110101': 0, '110102': 1, '110103': 2, '110104': 3, '110105': 4, '110201': 5, '110202': 6, '110203': 7, '11101': 8, '11102': 9, '11201': 10, '12101': 11, '12102': 12, '121101': 13, '121102': 14, '121103': 15, '121104': 16, '121105': 17, '121201': 18, '12201': 19, '122101': 20, '122102': 21, '122103': 22, '122104': 23, '122105': 24, '122201': 25, '122301': 26, '12301': 27, '12401': 28, '12402': 29, '13101': 30, '131101': 31, '131201': 32, '131202': 33, '131203': 34, '132002': 35, '132004': 36, '13201': 37, '13202': 38, '13203': 39, '13204': 40, '13305': 41, '133101': 42, '133201': 43, '133202': 44, '133203': 45, '133204': 46, '133205': 47, '133301': 48, '133302': 49, '133901': 50, '13401': 51, '134101': 52, '134102': 53, '134103': 54, '134201': 55, '134301': 56, '134302': 57, '134303': 58, '134401': 59, '135001': 60, '13501': 61, '136001': 62, '136002': 63, '13601': 64, '13701': 65, '13901': 66, '13902': 67, '140101': 68, '140201': 69, '140204': 70, '140205': 71, '140206': 72, '140207': 73, '140301': 74, '140304': 75, '140305': 76, '140306': 77, '140401': 78, '140501': 79, '140502': 80, '140503': 81, '140601': 82, '140602': 83, '140701': 84, '14103': 85, '14201': 86, '14301': 87, '15101': 88, '151101': 89, '151102': 90, '151105': 91, '151106': 92, '151107': 93, '151108': 94, '151201': 95, '151301': 96, '15201': 97, '152101': 98, '152201': 99, '153101': 100, '153103': 101, '153104': 102, '153105': 103, '153106': 104, '153201': 105, '153202': 106, '153203': 107, '153301': 108, '154101': 109, '154102': 110, '154103': 111, '154104': 112, '154201': 113, '155101': 114, '155102': 115, '155103': 116, '155104': 117, '155105': 118, '155106': 119, '155203': 120, '155301': 121, '155302': 122, '155303': 123, '155304': 124, '155305': 125, '155306': 126, '155401': 127, '155501': 128, '156101': 129, '156201': 130, '157101': 131, '157201': 132, '158201': 133, '158401': 134, '158402': 135, '158501': 136, '159103': 137, '159104': 138, '16101': 139, '16201': 140, '16301': 141, '21001': 142, '211101': 143, '211201': 144, '212101': 145, '212102': 146, '212201': 147, '212301': 148, '212901': 149, '213001': 150, '214101': 151, '214102': 152, '214201': 153, '214301': 154, '214401': 155, '214501': 156, '215101': 157, '215102': 158, '215105': 159, '22103': 160, '221101': 161, '221102': 162, '221201': 163, '221301': 164, '221401': 165, '222001': 166, '22201': 167, '22202': 168, '23101': 169, '231101': 170, '231102': 171, '231201': 172, '231301': 173, '231401': 174, '231501': 175, '23201': 176, '232101': 177, '232901': 178, '23301': 179, '23401': 180, '23402': 181, '23403': 182, '240101': 183, '240102': 184, '240201': 185, '240301': 186, '24101': 187, '24203': 188, '24301': 189, '24402': 190, '24404': 191, '250201': 192, '250301': 193, '25101': 194, '25201': 195, '25301': 196, '25401': 197, '25402': 198, '26101': 199, '26102': 200, '26103': 201, '26201': 202, '26301': 203, '26401': 204, '27101': 205, '27201': 206, '28101': 207, '28201': 208, '28202': 209, '28203': 210, '28204': 211, '28301': 212, '28302': 213, '28401': 214, '28402': 215, '29101': 216, '29201': 217, '29202': 218, '29203': 219, '29204': 220, '29303': 221, '29401': 222, '29501': 223, '29901': 224, '29902': 225, '29903': 226, '29904': 227, '301004': 228, '301101': 229, '301102': 230, '301103': 231, '301104': 232, '301105': 233, '301106': 234, '301107': 235, '301108': 236, '301109': 237, '301110': 238, '301111': 239, '301112': 240, '301113': 241, '301201': 242, '301301': 243, '301401': 244, '302001': 245, '303001': 246, '303002': 247, '304003': 248, '305001': 249, '306101': 250, '306201': 251, '306301': 252, '306401': 253, '306501': 254, '306502': 255, '306601': 256, '306701': 257, '306901': 258, '306902': 259, '306903': 260, '306904': 261, '307101': 262, '307102': 263, '307201': 264, '307301': 265, '307401': 266, '307501': 267, '307601': 268, '31101': 269, '31102': 270, '31201': 271, '31301': 272, '31302': 273, '31401': 274, '31402': 275, '31403': 276, '31501': 277, '32101': 278, '32201': 279, '32301': 280, '32302': 281, '32401': 282, '32501': 283, '33201': 284, '33202': 285, '411101': 286, '411102': 287, '411103': 288, '411104': 289, '411105': 290, '411106': 291, '411201': 292, '411202': 293, '411301': 294, '412001': 295, '412002': 296, '412003': 297, '413101': 298, '413102': 299, '413201': 300, '413202': 301, '414101': 302, '414102': 303, '414201': 304, '414301': 305, '414302': 306, '414303': 307, '414401': 308, '414501': 309, '414502': 310, '414503': 311, '414601': 312, '414602': 313, '414701': 314, '414702': 315, '414703': 316, '414901': 317, '414902': 318, '415101': 319, '415201': 320, '415202': 321, '415301': 322, '415404': 323, '415501': 324, '415502': 325, '415503': 326, '415504': 327, '416101': 328, '416102': 329, '416103': 330, '416104': 331, '416105': 332, '416201': 333, '416202': 334, '416203': 335, '416204': 336, '416205': 337, '416301': 338, '416302': 339, '416303': 340, '416304': 341, '416401': 342, '416501': 343, '416601': 344, '416701': 345, '416901': 346, '417102': 347, '417201': 348, '420101': 349, '420201': 350, '420202': 351, '420301': 352, '420401': 353, '420402': 354, '420403': 355, '420901': 356, '420902': 357, '511101': 358, '511201': 359, '511301': 360, '511302': 361, '511401': 362, '511402': 363, '511501': 364, '511502': 365, '512101': 366, '512102': 367, '512201': 368, '512301': 369, '512401': 370, '521101': 371, '521201': 372, '521303': 373, '521304': 374, '522101': 375, '522201': 376, '522202': 377, '523001': 378, '524001': 379, '531201': 380, '531301': 381, '531401': 382, '531501': 383, '531601': 384, '531701': 385, '532101': 386, '532201': 387, '532301': 388, '532401': 389, '541101': 390, '541201': 391, '541301': 392, '542001': 393, '550101': 394, '550102': 395, '550201': 396, '561101': 397, '561201': 398, '561301': 399, '561401': 400, '561501': 401, '561601': 402, '562101': 403, '562301': 404, '562401': 405, '611001': 406, '612101': 407, '612201': 408, '612301': 409, '612401': 410, '613001': 411, '614001': 412, '615101': 413, '615203': 414, '615301': 415, '615401': 416, '615501': 417, '615601': 418, '615701': 419, '616101': 420, '616201': 421, '617101': 422, '617901': 423, '621101': 424, '621102': 425, '621201': 426, '621202': 427, '621203': 428, '621301': 429, '621401': 430, '621402': 431, '621403': 432, '621901': 433, '622101': 434, '622201': 435, '622304': 436, '622901': 437, '623001': 438, '623002': 439, '624101': 440, '624201': 441, '624301': 442, '624401': 443, '701101': 444, '701201': 445, '701301': 446, '701401': 447, '701501': 448, '701601': 449, '701602': 450, '701701': 451, '702101': 452, '702201': 453, '702301': 454, '702401': 455, '702501': 456, '702502': 457, '702601': 458, '702701': 459, '703101': 460, '703201': 461, '704001': 462, '705101': 463, '705201': 464, '705901': 465, '705902': 466, '706001': 467, '811101': 468, '811201': 469, '811301': 470, '811401': 471, '811501': 472, '811601': 473, '811901': 474, '812101': 475, '812102': 476, '812201': 477, '812301': 478, '812401': 479, '812402': 480, '812901': 481, '812902': 482, '813101': 483, '813201': 484, '814001': 485, '815001': 486, '816103': 487, '817101': 488, '817201': 489, '817301': 490, '821101': 491, '821201': 492, '822101': 493, '822301': 494, '823101': 495, '823301': 496, '824101': 497, '825101': 498, '825201': 499, '826101': 500, '826201': 501, '826301': 502, '826401': 503, '826901': 504, '826902': 505, '831101': 506, '831201': 507, '831301': 508, '832101': 509, '832201': 510, '833001': 511, '834001': 512, '835101': 513, '835201': 514, '836001': 515, '841101': 516, '841201': 517, '842101': 518, '842201': 519, '842301': 520, '851101': 521, '851201': 522, '852101': 523, '852201': 524, '852301': 525, '852401': 526, '853101': 527, '853201': 528, '861101': 529, '861201': 530, '861301': 531, '862101': 532, '862201': 533, '862301': 534, '863101': 535, '863201': 536, '863301': 537, '863401': 538, '864101': 539, '864201': 540, '864301': 541, '871101': 542, '871201': 543, '872101': 544, '872201': 545, '872301': 546, '873101': 547, '873201': 548, '873301': 549, '873401': 550, '873501': 551, '881101': 552, '881201': 553, '882101': 554, '882201': 555, '882301': 556, '883101': 557, '883201': 558, '884101': 559, '884102': 560, '884201': 561, '885101': 562, '885201': 563, '885901': 564, '885902': 565, '901101': 566, '901201': 567, '901301': 568, '901401': 569, '901501': 570, '902101': 571, '902201': 572, '903101': 573, '904101': 574, '904201': 575}}\n","41     45\n","436    45\n","323    45\n","188    31\n","228    31\n","       ..\n","101    15\n","117    15\n","290    14\n","50     13\n","114    10\n","Name: knowcode, Length: 576, dtype: int64\n"]}]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"N_aP6eTcthir"}},{"cell_type":"code","source":["# ===== modeling =====\n","from datetime import timezone\n","timezone_kst = timezone(timedelta(hours=9))\n","\n","# <10-folds inference>\n","\n","# fold spliter setting\n","kfolds_spliter = StratifiedKFold(10, random_state=1234, shuffle=True)\n","# cut_off = 0.5\n","\n","# result container setting\n","val_prob = np.zeros((full_x.shape[0], len(full_y.value_counts())))\n","test_prob = np.zeros((test_x.shape[0], len(full_y.value_counts())))\n","val_perf = []\n","\n","# optuna function\n","def optuna_objective_function(trial: Trial, train_x, train_y, val_x, val_y, model_name, ntrees=None, eta=None):\n","    if model_name == \"CAT_GBM\":\n","        tuning_params = {\n","            # \"n_estimators\" : trial.suggest_int(\"n_estimators\", 500, 5000, step=500),\n","            # \"learning_rate\" : trial.suggest_categorical(\"learning_rate\", [1e-3, 5e-3, 1e-2, 5e-2, 1e-1]),\n","            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8, step=1),\n","            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.05, 0.95, step=0.05),\n","            # \"rsm\": trial.suggest_float(\"rsm\", 0.5, 0.9, step=0.05),\n","            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.01, 10.0, step=0.01),\n","            \"random_strength\": trial.suggest_float(\"random_strength\", 0.01, 1.5, step=0.01),\n","            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 3, 99, step=2),  \n","            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1.0, 3.0, step=0.01)\n","        }\n","\n","        model = cat.CatBoostClassifier(boosting_type=\"Plain\", loss_function=\"MultiClass\", task_type=\"GPU\",\n","                                    n_estimators=int(ntrees * 0.2),\n","                                    learning_rate=eta / 10,\n","                                    one_hot_max_size=3, leaf_estimation_method=\"Gradient\",\n","                                    # leaf_estimation_iterations=5,\n","                                    # max_ctr_complexity=2,\n","                                    logging_level=\"Silent\", random_state=fold, thread_count=cpu_count(),\n","                                    **tuning_params)\n","        model.fit(train_x, train_y, cat_features=categoIdx)\n","    elif model_name == \"CAT_ORD\":\n","        tuning_params = {\n","            # \"n_estimators\" : trial.suggest_int(\"n_estimators\", 500, 5000, step=500),\n","            # \"learning_rate\" : trial.suggest_categorical(\"learning_rate\", [1e-3, 5e-3, 1e-2, 5e-2, 1e-1]),\n","            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8, step=1),\n","            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.05, 0.95, step=0.05),\n","            # \"rsm\": trial.suggest_float(\"rsm\", 0.5, 0.9, step=0.05),\n","            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 0.01, 10.0, step=0.01),\n","            \"random_strength\": trial.suggest_float(\"random_strength\", 0.01, 1.5, step=0.01),\n","            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 3, 99, step=2),\n","            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1.0, 3.0, step=0.01)\n","        }\n","\n","        model = cat.CatBoostClassifier(boosting_type=\"Ordered\", loss_function=\"MultiClass\", task_type=\"GPU\",\n","                                    n_estimators=int(ntrees * 0.2),\n","                                    learning_rate=eta / 10,\n","                                    one_hot_max_size=3, leaf_estimation_method=\"Gradient\",\n","                                    # leaf_estimation_iterations=5,\n","                                    # max_ctr_complexity=2,\n","                                    logging_level=\"Silent\", random_state=fold, thread_count=cpu_count(),\n","                                    **tuning_params)\n","        model.fit(train_x, train_y, cat_features=categoIdx)\n","    elif model_name == \"XGB_GBT\":\n","        tuning_params = {\n","            # \"n_estimators\" : trial.suggest_int(\"n_estimators\", 500, 5000, step=500),\n","            # \"learning_rate\" : trial.suggest_categorical(\"learning_rate\", [1e-2, 5e-2, 1e-1]),\n","            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 8, step=1),\n","            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.95, step=0.05),\n","            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 0.95, step=0.05),\n","            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 10.0, step=0.01),\n","            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0.01, 10.0, step=0.01),\n","            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0, step=0.01),\n","            \"max_delta_step\":  trial.suggest_float(\"max_delta_step\", 0.0, 10.0, step=0.01)\n","            # \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1.0, 3.0, step=0.01)\n","        }\n","        model = xgb.XGBClassifier(booster=\"gbtree\", objective=\"multi:softmax\",\n","                                tree_method=\"gpu_hist\", gpu_id=0, sampling_method=\"gradient_based\",\n","                                n_estimators=int(ntrees * 0.2),\n","                                learning_rate=eta / 10,\n","                                random_state=fold, verbosity=0, use_label_encoder=False,\n","                                **tuning_params)     \n","        model.fit(train_x, train_y, verbose=False)\n","    # default randomforest\n","    else:\n","        tuning_params = {\n","            \"num_leaves\": trial.suggest_categorical(\"num_leaves\", [pow(2, i) - 1 for i in [4, 5, 6, 7, 8]]),\n","            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.9, step=0.05),\n","            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 0.9, step=0.05),\n","            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 10.0, step=0.01),\n","            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50, step=5),\n","            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-4, 1e-2),\n","            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 0.5, 2.0, step=0.01)\n","        }\n","        model = lgb.LGBMClassifier(boosting_type=\"rf\", objective=\"binary\", force_row_wise=True,\n","                                   n_estimators=int(ntrees * 0.2), subsample_freq=1, device_type=\"gpu\", gpu_device_id=0,\n","                                   n_jobs=cpu_count(), random_state=fold, **tuning_params)\n","        model.fit(train_x, train_y, categorical_feature=categoIdx,\n","                  callbacks=[lgb.callback.log_evaluation(period=np.inf, show_stdv=False)])\n","\n","    prob = model.predict_proba(val_x)\n","    pred = prob.argmax(axis=1)\n","    opt_score = metrics.f1_score(val_y, pred, average=\"macro\")\n","\n","    trial.report(opt_score, step=trial.number)\n","    if trial.should_prune():\n","        raise optuna.exceptions.TrialPruned()\n","\n","    return opt_score"],"metadata":{"id":"IreqTIO2foMR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import losses as tf_loss\n","hiddenLayers = 256\n","dropoutRate = 1 / 2**2\n","\n","def createNN_LP_V1(nCols, n_classes): \n","    # === input layers ===\n","    B0_input = layers.Input(shape=nCols, dtype=\"float32\", name=\"B0_input\")\n","    B0_embedding = layers.Embedding(input_dim=1024, output_dim=8, name=\"B0_embedding\")(B0_input)\n","    B0_flatten = layers.Flatten()(B0_embedding)\n","    # B0_dense = layers.Dense(hiddenLayers * 2, kernel_regularizer=\"l1\")(B0_flatten)\n","    B0_dropout = layers.Dropout(0.5)(B0_flatten)\n","\n","    # === learning layers ===\n","    B1_dense = tfa.layers.WeightNormalization(\n","        layers.Dense(\n","            units=hiddenLayers, activation=\"selu\"), name=\"B1_dense\"\n","    )(B0_dropout)\n","    B1_dropout = layers.Dropout(rate=dropoutRate, name=\"B1_dropout\")(B1_dense)\n","    B1_concat = layers.Concatenate(name=\"B1_concat\")([B0_dropout, B1_dropout])\n","\n","    B2_dense = tfa.layers.WeightNormalization(\n","        layers.Dense(\n","            units=hiddenLayers, activation=\"relu\"), name=\"B2_dense\"\n","    )(B1_concat)\n","    B2_dropout = layers.Dropout(rate=dropoutRate, name=\"B2_dropout\")(B2_dense)\n","    B2_concat = layers.Concatenate(name=\"B2_concat\")([B0_dropout, B1_dropout, B2_dropout])\n","\n","    B3_dense = tfa.layers.WeightNormalization(\n","        layers.Dense(\n","            units=hiddenLayers, activation=\"elu\"), name=\"B3_dense\"\n","    )(B2_concat)\n","\n","    layer_classifier = layers.Dense(n_classes, activation=\"softmax\", name=\"classifier\")(B3_dense)\n","\n","    return Model(B0_input, layer_classifier)\n","\n","# creating the dataset\n","def create_dataset(x=None, y=None, batch_size=None,shuffle=False):\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","    dataset = dataset.shuffle(1024, reshuffle_each_iteration=True) if shuffle else dataset\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset"],"metadata":{"id":"xGbB7gRrtFRB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XGBoost try1"],"metadata":{"id":"W3LkYyMRtjKR"}},{"cell_type":"code","source":["# ===== modeling =====\n","model_name = \"XGBoost_Gbtree_Try1\"\n","ntrees = 5000\n","eta = 1e-2\n","def xgb_f1_score(predt: np.ndarray, dtrain: xgb.DMatrix):\n","    return 'F1', -metrics.f1_score(dtrain.get_label(), predt.argmax(axis=1), average=\"macro\")\n","\n","total_time = time()\n","seed_everything()\n","for fold, (nonkIdx, kIdx) in enumerate(kfolds_spliter.split(full_x, full_y)):\n","\n","    fold_time = time()\n","    print(\"===== Fold\", fold+1, \"Prediction =====\\n\")\n","    fold_dir = \"fold_\" + str(fold)\n","    wnb_init_info = {\"project\": \"dacon_jobknow_recommendation\",\n","                     \"group\": model_name,\n","                     \"name\": fold_dir + \"_optuna\"}\n","\n","    print(\"<XGBoost>\")\n","\n","    \n","    optuna_cb = [optuna_wnbcallback(metric_name=\"f1_optuna\",\n","                                    wandb_kwargs=wnb_init_info)]\n","    wandb.config.step = 0\n","\n","    train_ds_x = full_x_oh.iloc[nonkIdx].reset_index(drop=True).copy()\n","    train_ds_y = full_y.iloc[nonkIdx].reset_index(drop=True).copy()\n","    val_ds_x = full_x_oh.iloc[kIdx].reset_index(drop=True).copy()\n","    val_ds_y = full_y.iloc[kIdx].reset_index(drop=True).copy()\n","    test_ds_x = test_x_oh.copy()\n","    \n","    optuna_timout = int(12 * 3600 / kfolds_spliter.get_n_splits())\n","    # optuna_pruner = pruners.MedianPruner(n_warmup_steps=150, interval_steps=5, n_min_trials=20)\n","    optuna_study = create_study(direction='maximize', sampler=TPESampler())\n","    optuna_study.optimize(lambda trial: optuna_objective_function(\n","        trial, train_ds_x, train_ds_y, val_ds_x, val_ds_y, \"XGB_GBT\", ntrees, eta),\n","                          n_jobs=1, n_trials=300, timeout=optuna_timout, callbacks=optuna_cb)\n","    \n","    # optuna_plt.plot_optimization_history(optuna_study).show(renderer=\"browser\")\n","    # optuna_plt.plot_param_importances(optuna_study).show(renderer=\"browser\")\n","\n","    model = xgb.XGBClassifier(booster=\"gbtree\", objective=\"multi:softmax\",\n","                            tree_method=\"gpu_hist\", gpu_id=0, sampling_method=\"gradient_based\",\n","                            n_estimators=ntrees,\n","                            learning_rate=eta,\n","                            random_state=fold, verbosity=0, use_label_encoder=False,\n","                            **optuna_study.best_params)\n","\n","    model.fit(train_ds_x, train_ds_y, eval_metric=xgb_f1_score, verbose=False,\n","              eval_set=[(val_ds_x, val_ds_y)], early_stopping_rounds=int(ntrees * 0.2))\n","\n","    # model.fit(train_ds_x, train_ds_y, verbose=False)\n","    \n","    print(\"tuned params --->\", optuna_study.best_params)\n","    print(\"best trees --->\", model.best_iteration, \"\\n\")\n","\n","    prob = model.predict_proba(val_ds_x)\n","    pred = prob.argmax(axis=1)\n","    val_perf.append(metrics.f1_score(val_ds_y, pred, average=\"macro\"))\n","    val_prob[kIdx] = prob\n","    \n","    print(\"Fold running time --->\", np.round(time() - fold_time, 3))\n","    print(model_name, \"Fold\", fold + 1, \"F1 Score --->\", val_perf[-1])\n","    print(model_name, \"Average F1 Score --->\", np.mean(val_perf), \"\\n\\n\")\n","    # cm = wandb.plot.confusion_matrix(\n","    #     y_true=list(val_ds_y),\n","    #     preds=pred,\n","    #     class_names=[0, 1])\n","    wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration}, commit=True)\n","    \n","    prob = model.predict_proba(test_ds_x)\n","    test_prob += prob / kfolds_spliter.get_n_splits()\n","    wandb.finish()"],"metadata":{"id":"XK49HOeffoKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# wandb.finish()"],"metadata":{"id":"jOwPprzoxzoO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # ===== modeling =====\n","\n","# model_name = \"XGBoost_Gbtree_Try2\"\n","# ntrees = 5000\n","# eta = 1e-2\n","# def xgb_f1_score(predt: np.ndarray, dtrain: xgb.DMatrix):\n","#     return 'F1', -metrics.f1_score(dtrain.get_label(), predt.argmax(axis=1), average=\"macro\")\n","\n","# total_time = time()\n","# seed_everything()\n","# for fold, (nonkIdx, kIdx) in enumerate(kfolds_spliter.split(full_x, full_y)):\n","\n","#     fold_time = time()\n","#     print(\"===== Fold\", fold+1, \"Prediction =====\\n\")\n","#     fold_dir = \"fold_\" + str(fold)\n","#     # wnb_init_info = {\"project\": \"dacon_jobknow_recommendation\",\n","#     #                  \"group\": model_name,\n","#     #                  \"name\": fold_dir + \"_optuna\"}\n","\n","#     print(\"<XGBoost>\")\n","\n","#     wandb.init(project=\"dacon_jobknow_recommendation\",\n","#                group=model_name,\n","#                name=fold_dir)\n","#     # optuna_cb = [optuna_wnbcallback(metric_name=\"f1_optuna\",\n","#     #                                 wandb_kwargs=wnb_init_info)]\n","#     wandb.config.step = 0\n","\n","#     train_ds_x = full_x_oh.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     train_ds_y = full_y.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     val_ds_x = full_x_oh.iloc[kIdx].reset_index(drop=True).copy()\n","#     val_ds_y = full_y.iloc[kIdx].reset_index(drop=True).copy()\n","#     test_ds_x = test_x_oh.copy()\n","    \n","#     # optuna_timout = int(18 * 3600 / kfolds_spliter.get_n_splits())\n","#     # # optuna_pruner = pruners.MedianPruner(n_warmup_steps=150, interval_steps=5, n_min_trials=20)\n","#     # optuna_study = create_study(direction='maximize', sampler=TPESampler())\n","#     # optuna_study.optimize(lambda trial: optuna_objective_function(\n","#     #     trial, train_ds_x, train_ds_y, val_ds_x, val_ds_y, \"XGB_GBT\", ntrees, eta),\n","#     #                       n_jobs=1, n_trials=10, timeout=optuna_timout, callbacks=optuna_cb)\n","    \n","#     # break\n","    \n","#     # optuna_plt.plot_optimization_history(optuna_study).show(renderer=\"browser\")\n","#     # optuna_plt.plot_param_importances(optuna_study).show(renderer=\"browser\")\n","\n","#     model = xgb.XGBClassifier(booster=\"gbtree\", objective=\"multi:softmax\",\n","#                             tree_method=\"gpu_hist\", gpu_id=0, sampling_method=\"gradient_based\",\n","#                             n_estimators=ntrees,\n","#                             learning_rate=eta,\n","#                             subsample=0.8, colsample_bytree=0.8,\n","#                             random_state=fold, verbosity=0, use_label_encoder=False)\n","\n","#     model.fit(train_ds_x, train_ds_y, eval_metric=xgb_f1_score, verbose=False,\n","#               eval_set=[(val_ds_x, val_ds_y)], early_stopping_rounds=int(ntrees * 0.2))\n","\n","#     # model.fit(train_ds_x, train_ds_y, verbose=False)\n","    \n","#     # print(\"tuned params --->\", optuna_study.best_params)\n","#     print(\"best trees --->\", model.best_iteration, \"\\n\")\n","\n","#     prob = model.predict_proba(val_ds_x)\n","#     pred = prob.argmax(axis=1)\n","#     val_perf.append(metrics.f1_score(val_ds_y, pred, average=\"macro\"))\n","#     val_prob[kIdx] = prob\n","    \n","#     print(\"Fold running time --->\", np.round(time() - fold_time, 3))\n","#     print(model_name, \"Fold\", fold + 1, \"F1 Score --->\", val_perf[-1])\n","#     print(model_name, \"Average F1 Score --->\", np.mean(val_perf), \"\\n\\n\")\n","#     # cm = wandb.plot.confusion_matrix(\n","#     #     y_true=list(val_ds_y),\n","#     #     preds=pred,\n","#     #     class_names=[0, 1])\n","#     # wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration, \"conf_mat\": cm}, commit=True)\n","#     wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration}, commit=True)\n","    \n","#     prob = model.predict_proba(test_ds_x)\n","#     test_prob += prob / kfolds_spliter.get_n_splits()\n","#     wandb.finish()"],"metadata":{"id":"dPE6v7-cxR8S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XGBoost try2 (no tuning) - more text prep"],"metadata":{"id":"UafjQF6xoUy7"}},{"cell_type":"code","source":["# # ===== modeling =====\n","# model_name = \"XGBoost_Gbtree_Try2\"\n","# ntrees = 5000\n","# eta = 1e-2\n","# def xgb_f1_score(predt: np.ndarray, dtrain: xgb.DMatrix):\n","#     return 'F1', -metrics.f1_score(dtrain.get_label(), predt.argmax(axis=1), average=\"macro\")\n","\n","# total_time = time()\n","# seed_everything()\n","# for fold, (nonkIdx, kIdx) in enumerate(kfolds_spliter.split(full_x, full_y)):\n","\n","#     fold_time = time()\n","#     print(\"===== Fold\", fold+1, \"Prediction =====\\n\")\n","#     fold_dir = \"fold_\" + str(fold)\n","#     # wnb_init_info = {\"project\": \"dacon_jobknow_recommendation\",\n","#     #                  \"group\": model_name,\n","#     #                  \"name\": fold_dir + \"_optuna\"}\n","\n","#     print(\"<XGBoost>\")\n","\n","#     wandb.init(project=\"dacon_jobknow_recommendation\",\n","#                group=model_name,\n","#                name=fold_dir)\n","#     # optuna_cb = [optuna_wnbcallback(metric_name=\"f1_optuna\",\n","#     #                                 wandb_kwargs=wnb_init_info)]\n","#     wandb.config.step = 0\n","\n","#     train_ds_x = full_x_oh.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     train_ds_y = full_y.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     val_ds_x = full_x_oh.iloc[kIdx].reset_index(drop=True).copy()\n","#     val_ds_y = full_y.iloc[kIdx].reset_index(drop=True).copy()\n","#     test_ds_x = test_x_oh.copy()\n","    \n","#     # optuna_timout = int(18 * 3600 / kfolds_spliter.get_n_splits())\n","#     # # optuna_pruner = pruners.MedianPruner(n_warmup_steps=150, interval_steps=5, n_min_trials=20)\n","#     # optuna_study = create_study(direction='maximize', sampler=TPESampler())\n","#     # optuna_study.optimize(lambda trial: optuna_objective_function(\n","#     #     trial, train_ds_x, train_ds_y, val_ds_x, val_ds_y, \"XGB_GBT\", ntrees, eta),\n","#     #                       n_jobs=1, n_trials=10, timeout=optuna_timout, callbacks=optuna_cb)\n","    \n","#     # break\n","    \n","#     # optuna_plt.plot_optimization_history(optuna_study).show(renderer=\"browser\")\n","#     # optuna_plt.plot_param_importances(optuna_study).show(renderer=\"browser\")\n","\n","#     model = xgb.XGBClassifier(booster=\"gbtree\", objective=\"multi:softmax\",\n","#                             tree_method=\"gpu_hist\", gpu_id=0, sampling_method=\"gradient_based\",\n","#                             n_estimators=ntrees,\n","#                             learning_rate=eta,\n","#                             subsample=0.8, colsample_bytree=0.8,\n","#                             random_state=fold, verbosity=0, use_label_encoder=False)\n","\n","#     model.fit(train_ds_x, train_ds_y, eval_metric=xgb_f1_score, verbose=False,\n","#               eval_set=[(val_ds_x, val_ds_y)], early_stopping_rounds=int(ntrees * 0.2))\n","\n","#     # model.fit(train_ds_x, train_ds_y, verbose=False)\n","    \n","#     # print(\"tuned params --->\", optuna_study.best_params)\n","#     print(\"best trees --->\", model.best_iteration, \"\\n\")\n","\n","#     prob = model.predict_proba(val_ds_x)\n","#     pred = prob.argmax(axis=1)\n","#     val_perf.append(metrics.f1_score(val_ds_y, pred, average=\"macro\"))\n","#     val_prob[kIdx] = prob\n","    \n","#     print(\"Fold running time --->\", np.round(time() - fold_time, 3))\n","#     print(model_name, \"Fold\", fold + 1, \"F1 Score --->\", val_perf[-1])\n","#     print(model_name, \"Average F1 Score --->\", np.mean(val_perf), \"\\n\\n\")\n","#     # cm = wandb.plot.confusion_matrix(\n","#     #     y_true=list(val_ds_y),\n","#     #     preds=pred,\n","#     #     class_names=[0, 1])\n","#     # wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration, \"conf_mat\": cm}, commit=True)\n","#     wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration}, commit=True)\n","    \n","#     prob = model.predict_proba(test_ds_x)\n","#     test_prob += prob / kfolds_spliter.get_n_splits()\n","#     wandb.finish()"],"metadata":{"id":"_CFeG4rkoQo9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XGBoost try3 (no tuning) - more text prep"],"metadata":{"id":"NF4P-srF7FBZ"}},{"cell_type":"code","source":["# # ===== modeling =====\n","# model_name = \"XGBoost_Gbtree_Try3\"\n","# ntrees = 5000\n","# eta = 1e-2\n","# def xgb_f1_score(predt: np.ndarray, dtrain: xgb.DMatrix):\n","#     return 'F1', -metrics.f1_score(dtrain.get_label(), predt.argmax(axis=1), average=\"macro\")\n","\n","# total_time = time()\n","# seed_everything()\n","# for fold, (nonkIdx, kIdx) in enumerate(kfolds_spliter.split(full_x, full_y)):\n","\n","#     fold_time = time()\n","#     print(\"===== Fold\", fold+1, \"Prediction =====\\n\")\n","#     print(\"Start Time :\", datetime.utcnow().astimezone(timezone_kst))\n","#     fold_dir = \"fold_\" + str(fold)\n","#     # wnb_init_info = {\"project\": \"dacon_jobknow_recommendation\",\n","#     #                  \"group\": model_name,\n","#     #                  \"name\": fold_dir + \"_optuna\"}\n","\n","#     print(\"<XGBoost>\")\n","\n","\n","#     wandb.init(project=\"dacon_jobknow_recommendation\",\n","#                group=model_name,\n","#                name=fold_dir)\n","#     # optuna_cb = [optuna_wnbcallback(metric_name=\"f1_optuna\",\n","#     #                                 wandb_kwargs=wnb_init_info)]\n","#     wandb.config.step = 0\n","\n","#     train_ds_x = full_x_oh.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     train_ds_y = full_y.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     val_ds_x = full_x_oh.iloc[kIdx].reset_index(drop=True).copy()\n","#     val_ds_y = full_y.iloc[kIdx].reset_index(drop=True).copy()\n","#     test_ds_x = test_x_oh.copy()\n","    \n","#     # optuna_timout = int(18 * 3600 / kfolds_spliter.get_n_splits())\n","#     # # optuna_pruner = pruners.MedianPruner(n_warmup_steps=150, interval_steps=5, n_min_trials=20)\n","#     # optuna_study = create_study(direction='maximize', sampler=TPESampler())\n","#     # optuna_study.optimize(lambda trial: optuna_objective_function(\n","#     #     trial, train_ds_x, train_ds_y, val_ds_x, val_ds_y, \"XGB_GBT\", ntrees, eta),\n","#     #                       n_jobs=1, n_trials=10, timeout=optuna_timout, callbacks=optuna_cb)\n","    \n","#     # break\n","    \n","#     # optuna_plt.plot_optimization_history(optuna_study).show(renderer=\"browser\")\n","#     # optuna_plt.plot_param_importances(optuna_study).show(renderer=\"browser\")\n","\n","#     model = xgb.XGBClassifier(booster=\"gbtree\", objective=\"multi:softmax\",\n","#                             tree_method=\"gpu_hist\", gpu_id=0, sampling_method=\"gradient_based\",\n","#                             n_estimators=ntrees,\n","#                             learning_rate=eta,\n","#                             subsample=0.8, colsample_bynode=0.5,\n","#                             random_state=fold, verbosity=0, use_label_encoder=False)\n","\n","#     model.fit(train_ds_x, train_ds_y, eval_metric=xgb_f1_score, verbose=False,\n","#               eval_set=[(val_ds_x, val_ds_y)], early_stopping_rounds=int(ntrees * 0.2))\n","\n","#     # model.fit(train_ds_x, train_ds_y, verbose=False)\n","    \n","#     # print(\"tuned params --->\", optuna_study.best_params)\n","#     print(\"best trees --->\", model.best_iteration, \"\\n\")\n","\n","#     prob = model.predict_proba(val_ds_x)\n","#     pred = prob.argmax(axis=1)\n","#     val_perf.append(metrics.f1_score(val_ds_y, pred, average=\"macro\"))\n","#     val_prob[kIdx] = prob\n","    \n","#     print(\"Fold running time --->\", np.round(time() - fold_time, 3))\n","#     print(model_name, \"Fold\", fold + 1, \"F1 Score --->\", val_perf[-1])\n","#     print(model_name, \"Average F1 Score --->\", np.mean(val_perf), \"\\n\\n\")\n","#     # cm = wandb.plot.confusion_matrix(\n","#     #     y_true=list(val_ds_y),\n","#     #     preds=pred,\n","#     #     class_names=[0, 1])\n","#     # wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration, \"conf_mat\": cm}, commit=True)\n","#     wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration}, commit=True)\n","    \n","#     prob = model.predict_proba(test_ds_x)\n","#     test_prob += prob / kfolds_spliter.get_n_splits()\n","#     wandb.finish()"],"metadata":{"id":"nz1aEDpu7RX9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# XGBoost try4 (no tuning) - more text prep"],"metadata":{"id":"ntZWxsfi82Uh"}},{"cell_type":"code","source":["# # ===== modeling =====\n","# model_name = \"XGBoost_Gbtree_Try4\"\n","# ntrees = 5000\n","# eta = 1e-2\n","# def xgb_f1_score(predt: np.ndarray, dtrain: xgb.DMatrix):\n","#     return 'F1', -metrics.f1_score(dtrain.get_label(), predt.argmax(axis=1), average=\"macro\")\n","\n","# total_time = time()\n","# seed_everything()\n","# for fold, (nonkIdx, kIdx) in enumerate(kfolds_spliter.split(full_x, full_y)):\n","\n","#     fold_time = time()\n","#     print(\"===== Fold\", fold+1, \"Prediction =====\\n\")\n","#     print(\"Start Time :\", datetime.utcnow().astimezone(timezone_kst))\n","#     fold_dir = \"fold_\" + str(fold)\n","#     # wnb_init_info = {\"project\": \"dacon_jobknow_recommendation\",\n","#     #                  \"group\": model_name,\n","#     #                  \"name\": fold_dir + \"_optuna\"}\n","\n","#     print(\"<XGBoost>\")\n","\n","\n","#     wandb.init(project=\"dacon_jobknow_recommendation\",\n","#                group=model_name,\n","#                name=fold_dir)\n","#     # optuna_cb = [optuna_wnbcallback(metric_name=\"f1_optuna\",\n","#     #                                 wandb_kwargs=wnb_init_info)]\n","#     wandb.config.step = 0\n","\n","#     train_ds_x = full_x_oh.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     train_ds_y = full_y.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     val_ds_x = full_x_oh.iloc[kIdx].reset_index(drop=True).copy()\n","#     val_ds_y = full_y.iloc[kIdx].reset_index(drop=True).copy()\n","#     test_ds_x = test_x_oh.copy()\n","    \n","#     # optuna_timout = int(18 * 3600 / kfolds_spliter.get_n_splits())\n","#     # # optuna_pruner = pruners.MedianPruner(n_warmup_steps=150, interval_steps=5, n_min_trials=20)\n","#     # optuna_study = create_study(direction='maximize', sampler=TPESampler())\n","#     # optuna_study.optimize(lambda trial: optuna_objective_function(\n","#     #     trial, train_ds_x, train_ds_y, val_ds_x, val_ds_y, \"XGB_GBT\", ntrees, eta),\n","#     #                       n_jobs=1, n_trials=10, timeout=optuna_timout, callbacks=optuna_cb)\n","    \n","#     # break\n","    \n","#     # optuna_plt.plot_optimization_history(optuna_study).show(renderer=\"browser\")\n","#     # optuna_plt.plot_param_importances(optuna_study).show(renderer=\"browser\")\n","\n","#     model = xgb.XGBClassifier(booster=\"gbtree\", objective=\"multi:softmax\",\n","#                             tree_method=\"gpu_hist\", gpu_id=0, sampling_method=\"gradient_based\",\n","#                             n_estimators=ntrees,\n","#                             learning_rate=eta,\n","#                             subsample=0.8, colsample_bynode=0.8,\n","#                             random_state=fold, verbosity=0, use_label_encoder=False)\n","\n","#     model.fit(train_ds_x, train_ds_y, eval_metric=xgb_f1_score, verbose=False,\n","#               eval_set=[(val_ds_x, val_ds_y)], early_stopping_rounds=int(ntrees * 0.2))\n","\n","#     # model.fit(train_ds_x, train_ds_y, verbose=False)\n","    \n","#     # print(\"tuned params --->\", optuna_study.best_params)\n","#     print(\"best trees --->\", model.best_iteration, \"\\n\")\n","\n","#     prob = model.predict_proba(val_ds_x)\n","#     pred = prob.argmax(axis=1)\n","#     val_perf.append(metrics.f1_score(val_ds_y, pred, average=\"macro\"))\n","#     val_prob[kIdx] = prob\n","    \n","#     print(\"Fold running time --->\", np.round(time() - fold_time, 3))\n","#     print(model_name, \"Fold\", fold + 1, \"F1 Score --->\", val_perf[-1])\n","#     print(model_name, \"Average F1 Score --->\", np.mean(val_perf), \"\\n\\n\")\n","#     # cm = wandb.plot.confusion_matrix(\n","#     #     y_true=list(val_ds_y),\n","#     #     preds=pred,\n","#     #     class_names=[0, 1])\n","#     # wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration, \"conf_mat\": cm}, commit=True)\n","#     wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration}, commit=True)\n","    \n","#     prob = model.predict_proba(test_ds_x)\n","#     test_prob += prob / kfolds_spliter.get_n_splits()\n","#     wandb.finish()"],"metadata":{"id":"Ojzm_JlE82pf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CatBoost - GBM try1 (no tuning)"],"metadata":{"id":"R-cueubJN45-"}},{"cell_type":"code","source":["# # ===== modeling =====\n","# model_name = \"CatBoost_GBM_Try1\"\n","# total_time = time()\n","# seed_everything()\n","# for fold, (nonkIdx, kIdx) in enumerate(kfolds_spliter.split(full_x, full_y)):\n","\n","#     fold_time = time()\n","#     print(\"===== Fold\", fold+1, \"Prediction =====\\n\")\n","#     fold_dir = \"fold_\" + str(fold)\n","#     # wnb_init_info = {\"project\": \"dacon_jobknow_recommendation\",\n","#     #                  \"group\": model_name,\n","#     #                  \"name\": fold_dir + \"_optuna\"}\n","\n","#     print(\"<CatBoost - GBM>\")\n","#     ntrees = 5000\n","#     eta = 1e-2\n","    \n","#     wandb.init(project=\"dacon_jobknow_recommendation\",\n","#                group=model_name,\n","#                name=fold_dir)\n","#     # optuna_cb = [optuna_wnbcallback(metric_name=\"f1_optuna\",\n","#     #                                 wandb_kwargs=wnb_init_info)]\n","#     wandb.config.step = 0\n","\n","#     train_ds_x = full_x.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     train_ds_y = full_y.iloc[nonkIdx].reset_index(drop=True).copy()\n","#     val_ds_x = full_x.iloc[kIdx].reset_index(drop=True).copy()\n","#     val_ds_y = full_y.iloc[kIdx].reset_index(drop=True).copy()\n","#     test_ds_x = test_x.copy()\n","    \n","#     # optuna_timout = int(18 * 3600 / kfolds_spliter.get_n_splits())\n","#     # # optuna_pruner = pruners.MedianPruner(n_warmup_steps=150, interval_steps=5, n_min_trials=20)\n","#     # optuna_study = create_study(direction='maximize', sampler=TPESampler())\n","#     # optuna_study.optimize(lambda trial: optuna_objective_function(\n","#     #     trial, train_ds_x, train_ds_y, val_ds_x, val_ds_y, \"XGB_GBT\", ntrees, eta),\n","#     #                       n_jobs=1, n_trials=10, timeout=optuna_timout, callbacks=optuna_cb)\n","    \n","#     # break\n","    \n","#     # optuna_plt.plot_optimization_history(optuna_study).show(renderer=\"browser\")\n","#     # optuna_plt.plot_param_importances(optuna_study).show(renderer=\"browser\")\n","\n","#     model = cat.CatBoostClassifier(boosting_type=\"Plain\", loss_function=\"MultiClass\", task_type=\"GPU\",\n","#                                 n_estimators=ntrees,\n","#                                 learning_rate=eta,       \n","#                                 one_hot_max_size=3, leaf_estimation_method=\"Gradient\",\n","#                                 eval_metric=\"TotalF1:average=Macro\",\n","#                                 # leaf_estimation_iterations=5,\n","#                                 # max_ctr_complexity=2,\n","#                                 logging_level=\"Silent\", random_state=fold, thread_count=cpu_count())\n","\n","#     model.fit(train_ds_x, train_ds_y, cat_features=categoIdx,\n","#               eval_set=[(val_ds_x, val_ds_y)], use_best_model=True,\n","#               early_stopping_rounds=int(ntrees * 0.2))\n","\n","#     # model.fit(train_ds_x, train_ds_y, verbose=False)\n","    \n","#     # print(\"tuned params --->\", optuna_study.best_params)\n","#     print(\"best trees --->\", model.best_iteration_, \"\\n\")\n","\n","#     prob = model.predict_proba(val_ds_x)\n","#     pred = prob.argmax(axis=1)\n","#     val_perf.append(metrics.f1_score(val_ds_y, pred, average=\"macro\"))\n","#     val_prob[kIdx] = prob\n","    \n","#     print(\"Fold running time --->\", np.round(time() - fold_time, 3))\n","#     print(model_name, \"Fold\", fold + 1, \"F1 Score --->\", val_perf[-1])\n","#     print(model_name, \"Average F1 Score --->\", np.mean(val_perf), \"\\n\\n\")\n","#     # cm = wandb.plot.confusion_matrix(\n","#     #     y_true=list(val_ds_y),\n","#     #     preds=pred,\n","#     #     class_names=[0, 1])\n","#     # wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration, \"conf_mat\": cm}, commit=True)\n","#     wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration_}, commit=True)\n","    \n","#     prob = model.predict_proba(test_ds_x)\n","#     test_prob += prob / kfolds_spliter.get_n_splits()\n","#     wandb.finish()"],"metadata":{"id":"Fz6XnM5SN8cM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# wandb.finish()"],"metadata":{"id":"EtGf9IiBN8ge"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MLP_LP_V1 try1"],"metadata":{"id":"u94f-9W1qWgs"}},{"cell_type":"code","source":["# ===== modeling =====\n","model_name = \"MLP_LP_Try2\"\n","epochs = 100\n","patient_epochs = 20\n","batch_size = 16\n","eta = 1e-3\n","weight_decay = 1e-4\n","model_save_flag = False\n","checkpoint_filepath = folder_path + 'models/tmp_checkpoint/'\n","target_onehot = copy.deepcopy(MyOneHotEncoder())\n","target_onehot.fit_transform(full_y.copy(), target_var)\n","\n","total_time = time()\n","seed_everything()\n","for fold, (nonkIdx, kIdx) in enumerate(kfolds_spliter.split(full_x, full_y)):\n","\n","    fold_time = time()\n","    print(\"===== Fold\", fold+1, \"Prediction =====\\n\")\n","    tf.keras.backend.clear_session()\n","    fold_dir = \"fold_\" + str(fold)\n","    log_dir = folder_path + \"models/\" + model_name + \"/logs/\" + fold_dir\n","    if os.path.isdir(log_dir): shutil.rmtree(log_dir)\n","    createFolder(log_dir)\n","    \n","    tensorboard_callback = tf_callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","    try:\n","        wandb.tensorboard.patch(root_logdir=log_dir)\n","    except:\n","        pass\n","    \n","    wandb.init(\n","        project=\"dacon_jobknow_recommendation\",\n","        group=model_name,\n","        name=fold_dir\n","    ); wandb.config.step = 0\n","\n","    print(\"<MLP - LP>\")\n","\n","    train_ds_x = full_x.iloc[nonkIdx].reset_index(drop=True).copy()\n","    train_ds_y = target_onehot.transform(full_y.iloc[nonkIdx].reset_index(drop=True).copy())\n","    train_ds = create_dataset(train_ds_x, train_ds_y, batch_size, True)\n","    val_ds_x = full_x.iloc[kIdx].reset_index(drop=True).copy()\n","    val_ds_y = target_onehot.transform(full_y.iloc[kIdx].reset_index(drop=True).copy())\n","    val_ds = create_dataset(val_ds_x, val_ds_y, batch_size, False)\n","    test_ds_x = test_x.copy()\n","    test_ds = create_dataset(test_ds_x, None, batch_size, False)\n","\n","    cb_reduceLR = tf_callbacks.ReduceLROnPlateau(patience=1, factor=0.6, min_lr=1e-7)\n","    cb_earlyStopping = tf_callbacks.EarlyStopping(patience=patient_epochs, monitor='val_f1', mode='max')\n","    cb_modelsave = tf_callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_f1', mode='max',\n","                                                save_weights_only=True, save_best_only=True)\n","\n","    model = createNN_LP_V1(train_ds_x.shape[1], len(full_y[target_var].unique()))\n","    model.compile(\n","        optimizer=tfa.optimizers.AdamW(learning_rate=eta, weight_decay=weight_decay),\n","        loss=tf_loss.CategoricalCrossentropy(),\n","        metrics=tfa.metrics.F1Score(num_classes=len(full_y[target_var].unique()), average=\"macro\", threshold=None, name=\"f1\")\n","    )\n","    model.fit(train_ds, validation_data=val_ds, epochs=epochs, verbose=0,\n","            callbacks=[cb_reduceLR, cb_earlyStopping, cb_modelsave, tensorboard_callback, TqdmCallback(verbose=0)])\n","    model.load_weights(checkpoint_filepath)\n","    \n","    # print(\"tuned params --->\", optuna_study.best_params)\n","    # print(\"best trees --->\", model.best_iteration_, \"\\n\")\n","\n","    prob = model.predict(val_ds_x)\n","    pred = prob.argmax(axis=1)\n","    val_perf.append(metrics.f1_score(full_y.iloc[kIdx].reset_index(drop=True).copy(), pred, average=\"macro\"))\n","    val_prob[kIdx] = prob\n","    \n","    print(\"Fold running time --->\", np.round(time() - fold_time, 3))\n","    print(model_name, \"Fold\", fold + 1, \"F1 Score --->\", val_perf[-1])\n","    print(model_name, \"Average F1 Score --->\", np.mean(val_perf), \"\\n\\n\")\n","    # cm = wandb.plot.confusion_matrix(\n","    #     y_true=list(val_ds_y),\n","    #     preds=pred,\n","    #     class_names=[0, 1])\n","    # wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration, \"conf_mat\": cm}, commit=True)\n","    # wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1], \"ntrees\": model.best_iteration_}, commit=True)\n","    wandb.log(data={\"fold\": fold, \"f1_final\": val_perf[-1]}, commit=True)\n","    \n","    prob = model.predict(test_ds_x)\n","    test_prob += prob / kfolds_spliter.get_n_splits()\n","    wandb.finish()"],"metadata":{"id":"9a5a7DaHqWzv","executionInfo":{"status":"ok","timestamp":1642078676002,"user_tz":-540,"elapsed":1607408,"user":{"displayName":"김영준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpTdFUUaMn51B-vREgj8EQWx2hKK-I4nl4g_I8lA=s64","userId":"06606532799291918175"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["266eab0221de4f00b9af6e909fbe27e1","ef1123b29c1b4db5a7ddcbef4ddd2450","9f106752c55348a39e7b39b566da9cde","191781a442ca4ccba2ad99bc9330fc75","18eb0a20b2c3431f8a93a6b72bea408d","ab8d217706ef4cca847e3a0b2e98f5de","e7e3bf85e7b0408b804edd71791fbd67","4642344519be42cab06d22579424c8d4","04d820ef6aad4665aee0dba52bb62398","5d44299c12d44f7fb667f625a41159d7","b0dc257e8d854ebd9998b4c7cbb1f2f2","6dd9acae06154778a37fce5f7cf90846","243b8426e7924e8b822617944cf15d63","fa906a4652a7432b802f087c6e875edd","14e14e2473774b0bbdd590e7f2b2b3a7","c60f8dc7fed94bbda9100ec58dcefe62","817b7e2c23a94d0ab7388ce0d80b716e","1ef8954fcde94d2a86d5466009bf7d43","14f55666656f4a659a759b53d3950af0","10cd30555e5c4862bf11fcada4652779","c25c382b90744c0ca3282a7670bfe12f","2698bf3995cc40dcb3a4da97e40629f0","91deb63e220b435ba11c333ffd43bcb7","05d827240a554434b67a7bf4124c7528","89f6381fa5ca4507b1799ccb448b16f0","6a4ca70c862446cd8d5f41764000bd57","9425d0d96ae24b318f21138fc5672843","f7284ca83cd04f4d9a30f244399a5921","de1bef17884440fa963ca3bc0a1ec1b4","e6eac27c2bb44bcc89db5a6b2389e15c","01d128a0bad7479591fc552f04b37bff","d780bdf7ea0c4255b2168b378a3b092c","567b39286a9b4181848f390888a9588e","fd0795eab1484476ad85e4351c44173c","b32c4490e4554a16838d6f67ede6c573","a1129f8f45f243af9fe580983e929922","8e7f060e61744e0cad2a83f11c5d078c","6ae46dc727114ee2bbb259f52a57e5c4","9a9eabe130f14d0194df5cfb266616fb","97d0d69e7dd24638a852b703cf193525","46e7be95151f4ad6afe15ee8032e03ad","b04434deff784eb38c03ebecdb462722","5d02ac9e7ab54ebe818ee82d8fdb1d56","593c8d83bcba4dc8af38aaf6d95a8667","e0adacc0aa1d4b6f935745178dfe46e5","9321fa7955d04a2d82d32ad479cc225b","d4778eee479542d3b7d93c0878a5d43f","113e6a33a57e45f9975c459a55b59641","5645584eab4a47b4b9afa90113320921","97eedb95cfd8471dbd0afb82d003a6c4","f7ede8b0f425449c8e94f31a67f98c3c","6034584e940e4470add0a48703f24982","b940ccc1448049358437a1c4d25200b3","d42584c3fd884bc1b0edcbe262872cb9","efed9f858b32446e99c54706861c7009","a7533f94baca476cb404575dcb0f6a3e","15120b138a7346be82aeac21a6eeaec6","3d4de893122542f7963e763ce1b75c26","e9bf1adbf6a2484188a692417327ad32","baefe5abfd7543489a4f926873957dca","9e5c916b3cd04e47843cf78fae13416d","c148b6fad3d44b33a0946974f3a463d2","f7f96c4b8ce04bafb5fe3c15aef74bc0","86685a2778994ac9bf7003721b6eee86","c087c15355e34fd1aed1d997e6e483df","b2b70217a0cb4b72a1e819a0f7de245d","9afe933928914e3aac53772615b8e6f8","d9842cb3aac24c10bbd45ecc43419c57","8b75cbafed6a4749b1df30d2c7dd8d26","4e33cae76dd94258a9c291d552ad6747","80d039e86e0a43ffaf500d1055674a02","cfc895a52ec84735a36122efd67f4af6","e96d9dbefc3046b28eb9508f37a62c86","e2179c5f2f454f3a8e740c5bb5d84419","d8e3579bd91140299432595393749afe","4dad28fe22bd4e9badc466f8423e0d24","a1d9dca933644a2283f51df860bda6ba","78a33037bc2648e29c36a8297a8643e0","20b46448e91d4ec4b729fdd39b66fbc3","b1ce4e4d1aa34aa985c43efddfeddc12","92bca27680a248c8a04e613b28495bd4","3d250ef1325f4bd99108992c35a94d4b","1c24c210563d44b69f33f057d25a366d","8fe793515bb842a78ac45fb8e5cef7d3","04339ab6d7e14a74b78674ca779d6aeb","12a12b15fadc47338aa3afbeeeb7b5f6","2f24855224b64dae85287bd1ae170baa","756bd9584e08431b8a389bfeba2b23ba","befef100f6174de098198822c87797f5","3dc118186094480aad113ab6790e2c6d","fec3eddaf34741779a879783c1595952","8ff99bfe7fa547a0bb24693271750f21","bf2ccbae97f84af984418d5e40baf366","01a3b340ea6a4e9fb40d5d0abeedd7f0","07e5fa8e684a468796a69734f040415b","77986159db104a3b888323e0696bd8ab","4e04a16382c7439881e538a06623dcca","f0cc9d2c6fd241c0b15eb949deadfe11","40d6ab41bfe148cf8ef560c9fe82edac","2a684a7dc38944da930823431295f770","1801fedb41c6401e9ab2240efdd860a7","683e50242af9454b8759db0c5e74480e","da2bb6830c574ec2a953b971cea5ebca","d0ad118543e2493680e9a46a3ecddcbd","71b6ea34cbe341d88ad3cf5841d8ec7e","a71421c678944ecb973b3f25d202da2f","be0ed6d342b241fbb2fc3a86cef99d1c","ddf07745a7844ca79a689a664afd7c2d","19fabfd6d24a425391693012391008ea","3a0b601de642411fb57ee9c27261675c","00182dcc1f5944ca9bdf7ebeb75448be","2e82fe30d2564834827f51dcbac898dd","b14f2039d0ab4708be2f5132b0a5db92","f7d9166bdfa3403fa51d58aafc57bad4","645667eed2ec4f61a7948c21a9426ecf","e1507257fa194969a3f05a1aa19c10db","1e22b66a74f44913977d77a816108bcd","22850fe2524444b5aa5b4825971a1a56","0f09fffb70a24dff8a5e1ba1bb7adc32","a84d6f6a2c234cf08140faab9e23b076","4137009bf83342ef8eba32e95b6bd1ad","a2d28bd8d7dc4335800d36edd13a4b15","2165031c30b84cb3bb49cb72e04c7683","71ef43d581454a7d8745eb2cec80eae8","38766e1ff1da44bab73fa0522ea55027","b316f22a56244e2390d45cdd9650b4f0","bb5d1e366a934fc09e6ae10a9eed5e2e","8a9650d67a5541ca9a4876c41623f098","423204a1a60a4a5889d50f3d726cfa33","633f41b1bc674f18be6af8c958dfa27d","059a6b8a1a4b4075849afae2ce44906a","b831c7327d674c25a7050e8a4c7eb82f","6dbd6b3c4cfb48149cac39b9bec3f3ce","26d9537cf8294a15837b3e8222875209","d98307dd2df241f4bf9d208353a07357","74e31d8a9e524275a75ad2c7dcd76f4f","80b7ad96d4a848c389fcabb530324469","9c101cd520694f988bb39fae04c3d72f","d62fe8705fe843f8a071f7131c10b875","3b52d3d9667d497492bfed3067380f8e","46f6148b64104a028dfbf537163efd01","2e58f8816f0447b1a4fd3cc1d0d122ee","ef4d1d359ab14ebba6566da072e6f978","944c6459f7d74a29b0ddd51f0eee3420","1970d70befc343589cbd3d38d984ec66","97c77d526afe4313a7f924b08a12da61","030cb10a780e4bf495647ffabe427876","6f8c4f46412442e886ad40b56f7dd2de","2f8389a9c4d34861a6ce8f2ff1a21fbc","bac6c46dea8942bd8cdf909d845134d0","4fbaf01e84564addb61cb0c83e7a0aa5","0e2d8f3a48ed4cb79bc5c47c584e3919","8400cd0d50414cfbb1328225c40650c1","b6b8c5e9737945b4a3680baa1789a6b6","9e8afbd9845c462ebb8730d520bfd5d3","a0f6b01ed4244986a454221c47d14764","9d4f4e3b0c4944d8b03b61275b617633","2583f97592fc47bd91747a4fc5f1d148","4e5da099438b4b7f8bbb0731fe753a69","8da9e10e479042fe87f5447d558fe3ba","40da3d70cbce490abd4e56d6278f1713","3d60309655e84b118f6a303b09215cc9","e8c0744901604fe99bfc2832d1ea8fe7","72d8829538fb417ca56ed4f0faa4b35a","4e75b53e232048e9b0df32311bee5530","48542afafa7f4aa7abe8ab6321b3bf42","d82e27900b1a4a2aa2c47dde4d5e39fc","9598817c316c46c88d97d9876906e61f","3532d926e8cb486ea7e85f9e371a227c","c34c087230564c5fbc7cfaaac89819ed","bb186a98d0dc463aa5dc40623be2cac8","64138e7a003c40b3b0df3194573acd45","45897eb7caf24bd9984f97c486a6b1a3","3e73078150ce4faca525601d2e4eeda8","abe99ce4afcd4862944ddae8489ba71a","e095847cdac14aada4d90ba0358f1314","b354155120ae4e579f15fa382816324c","0588d17aba03486a85a4434eb4f530b5","1f68d422ac1f421586d3bbcf00816e19","3d4ec30bb53940e3afb527221a3fb92f","1bdadc262955456aa87b9fa207597207","673562dc5cf544e4a5a9dd39331afc14","4b9fb8c28e414d438cbf2f32ddbb281b","0df3ef10239e465ab542f0e2def443c9","e9327d8a17ef4043b432fcb7cafa470d","1180f92faabb4087aa8dbd4c6c689d1a","39a7e534a2d945c0b06441e05bea08bc","5dbd1a4554964bf1a704c7ea9c963d5c","4905303ff97e42e390a4edd18abd00f0","8782ca14e4b44a1ca9ff78717875f201"]},"outputId":"5dab9b35-52ba-4052-817e-ab3b8de9e001"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING : knowcode is not object or category\n","===== Fold 1 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3u41pp21\" target=\"_blank\">fold_0</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"266eab0221de4f00b9af6e909fbe27e1","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0079s). Check your callbacks.\n","Fold running time ---> 139.75\n","MLP_LP_Try2 Fold 1 F1 Score ---> 0.4512723671941549\n","MLP_LP_Try2 Average F1 Score ---> 0.4512723671941549 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 8585... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6dd9acae06154778a37fce5f7cf90846","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.62MB of 0.62MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▆▇▇▇▇█████████████████▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>█▅▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▅▅▆▆▇▇▇███</td></tr><tr><td>train/epoch_lr</td><td>██████▅▅▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▆▆▆▇▇▇▇▇████████████████████████▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇███</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▆▆▆▇▇▇▇▇████████████████████████▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇███</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.45127</td></tr><tr><td>fold</td><td>0</td></tr><tr><td>global_step</td><td>19456</td></tr><tr><td>train/epoch_f1</td><td>0.73789</td></tr><tr><td>train/epoch_loss</td><td>5.68484</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>37</td></tr><tr><td>validation/epoch_f1</td><td>0.40496</td></tr><tr><td>validation/epoch_loss</td><td>5.84086</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.40496</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.84086</td></tr><tr><td>validation/global_step</td><td>37</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_0</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3u41pp21\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3u41pp21</a><br/>\n","Find logs at: <code>./wandb/run-20220113_123107-3u41pp21/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 2 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/mco3x923\" target=\"_blank\">fold_1</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10cd30555e5c4862bf11fcada4652779","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_1/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_train_batch_end` time: 0.0074s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_1/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 158.112\n","MLP_LP_Try2 Fold 2 F1 Score ---> 0.4571902926083055\n","MLP_LP_Try2 Average F1 Score ---> 0.4542313299012302 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 9268... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01d128a0bad7479591fc552f04b37bff","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.60MB of 0.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▅▆▆▆▇▇███████████████████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>▇▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/epoch_lr</td><td>██████████▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▅▆▆▇▇▇▇██████████████████▇████▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▆▇▇▇███</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▅▆▆▇▇▇▇██████████████████▇████▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▆▇▇▇███</td></tr><tr><td>validation/global_step</td><td>▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▇▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.45719</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>global_step</td><td>21504</td></tr><tr><td>train/epoch_f1</td><td>0.76279</td></tr><tr><td>train/epoch_loss</td><td>5.83991</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>41</td></tr><tr><td>validation/epoch_f1</td><td>0.41398</td></tr><tr><td>validation/epoch_loss</td><td>5.95629</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.41398</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.95629</td></tr><tr><td>validation/global_step</td><td>41</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_1</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/mco3x923\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/mco3x923</a><br/>\n","Find logs at: <code>./wandb/run-20220113_123339-mco3x923/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 3 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3j1ta39s\" target=\"_blank\">fold_2</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a9eabe130f14d0194df5cfb266616fb","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_2/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0071s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_2/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 160.979\n","MLP_LP_Try2 Fold 3 F1 Score ---> 0.44705695194522005\n","MLP_LP_Try2 Average F1 Score ---> 0.45183987058256014 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 10015... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97eedb95cfd8471dbd0afb82d003a6c4","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.60MB of 0.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▅▆▇▇▇▇▇████████████████▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>▇▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>train/epoch_lr</td><td>███████▅▅▅▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▆▆▆▆▇▇▇▇▇██████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▅▅▆▆▇▇▇▇████</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▆▆▆▆▇▇▇▇▇██████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▅▅▆▆▇▇▇▇████</td></tr><tr><td>validation/global_step</td><td>▁▁▂▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.44706</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>global_step</td><td>22016</td></tr><tr><td>train/epoch_f1</td><td>0.73758</td></tr><tr><td>train/epoch_loss</td><td>5.9774</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>42</td></tr><tr><td>validation/epoch_f1</td><td>0.38543</td></tr><tr><td>validation/epoch_loss</td><td>6.06206</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.38543</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>6.06206</td></tr><tr><td>validation/global_step</td><td>42</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_2</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3j1ta39s\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3j1ta39s</a><br/>\n","Find logs at: <code>./wandb/run-20220113_123629-3j1ta39s/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 4 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/22ujp42e\" target=\"_blank\">fold_3</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d4de893122542f7963e763ce1b75c26","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_3/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0068s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_3/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 152.875\n","MLP_LP_Try2 Fold 4 F1 Score ---> 0.47132068221453693\n","MLP_LP_Try2 Average F1 Score ---> 0.45671007349055437 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 10776... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b75cbafed6a4749b1df30d2c7dd8d26","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.60MB of 0.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▅▆▆▇▇▇▇████████████████████▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>█▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▅▆▆▇▇▇██</td></tr><tr><td>train/epoch_lr</td><td>█████████▅▅▅▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▅▆▆▆▆▆▇▇▇██▇██████▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇██</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▅▆▆▆▆▆▇▇▇██▇██████▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇██</td></tr><tr><td>validation/global_step</td><td>▁▃▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.47132</td></tr><tr><td>fold</td><td>3</td></tr><tr><td>global_step</td><td>21033</td></tr><tr><td>train/epoch_f1</td><td>0.77667</td></tr><tr><td>train/epoch_loss</td><td>5.65391</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>validation/epoch_f1</td><td>0.42434</td></tr><tr><td>validation/epoch_loss</td><td>5.82451</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.42434</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.82451</td></tr><tr><td>validation/global_step</td><td>40</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_3</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/22ujp42e\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/22ujp42e</a><br/>\n","Find logs at: <code>./wandb/run-20220113_123921-22ujp42e/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 5 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/1a5svvct\" target=\"_blank\">fold_4</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1d9dca933644a2283f51df860bda6ba","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_4/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_train_batch_end` time: 0.0077s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_4/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 157.211\n","MLP_LP_Try2 Fold 5 F1 Score ---> 0.4543406207004284\n","MLP_LP_Try2 Average F1 Score ---> 0.4562361829325292 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 11507... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"756bd9584e08431b8a389bfeba2b23ba","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.59MB of 0.59MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▅▆▆▇▇▇▇█████████████████▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▅▅▆▆▇▇▇███</td></tr><tr><td>train/epoch_lr</td><td>█████████▅▅▅▄▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇███████████████████▇█▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇▇██</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇███████████████████▇█▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇▇██</td></tr><tr><td>validation/global_step</td><td>▁▁▂▁▁▁▁▁▁▁▁▁▆▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.45434</td></tr><tr><td>fold</td><td>4</td></tr><tr><td>global_step</td><td>21546</td></tr><tr><td>train/epoch_f1</td><td>0.76127</td></tr><tr><td>train/epoch_loss</td><td>5.77749</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>41</td></tr><tr><td>validation/epoch_f1</td><td>0.40282</td></tr><tr><td>validation/epoch_loss</td><td>5.91319</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.40282</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.91319</td></tr><tr><td>validation/global_step</td><td>41</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_4</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/1a5svvct\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/1a5svvct</a><br/>\n","Find logs at: <code>./wandb/run-20220113_124205-1a5svvct/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 6 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3co361r7\" target=\"_blank\">fold_5</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77986159db104a3b888323e0696bd8ab","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_5/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0072s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_5/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 137.411\n","MLP_LP_Try2 Fold 6 F1 Score ---> 0.4733398796179399\n","MLP_LP_Try2 Average F1 Score ---> 0.45908679904676436 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 12254... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be0ed6d342b241fbb2fc3a86cef99d1c","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.62MB of 0.62MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▆▆▇▇▇▇███████████████████▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>█▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▅▅▆▆▇▇▇███</td></tr><tr><td>train/epoch_lr</td><td>███████▅▅▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▅▅▆▆▇▇▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇███</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▅▅▆▆▇▇▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▇▇▇███</td></tr><tr><td>validation/global_step</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.47334</td></tr><tr><td>fold</td><td>5</td></tr><tr><td>global_step</td><td>18981</td></tr><tr><td>train/epoch_f1</td><td>0.76304</td></tr><tr><td>train/epoch_loss</td><td>5.63056</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>36</td></tr><tr><td>validation/epoch_f1</td><td>0.40861</td></tr><tr><td>validation/epoch_loss</td><td>5.79854</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.40861</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.79854</td></tr><tr><td>validation/global_step</td><td>36</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_5</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3co361r7\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3co361r7</a><br/>\n","Find logs at: <code>./wandb/run-20220113_124454-3co361r7/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 7 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/ni7g4b5r\" target=\"_blank\">fold_6</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"645667eed2ec4f61a7948c21a9426ecf","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_6/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0072s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_6/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 137.314\n","MLP_LP_Try2 Fold 7 F1 Score ---> 0.47120378184329964\n","MLP_LP_Try2 Average F1 Score ---> 0.4608177965891265 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 12923... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b316f22a56244e2390d45cdd9650b4f0","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.60MB of 0.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▅▆▇▇▇▇██████████████████████▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>█▆▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▅▆▆▇▇▇█</td></tr><tr><td>train/epoch_lr</td><td>████████▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▅▆▆▆▆▇▇█▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▅▆▆▇▇██</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▅▆▆▆▆▇▇█▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▅▆▆▇▇██</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▅▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.4712</td></tr><tr><td>fold</td><td>6</td></tr><tr><td>global_step</td><td>18981</td></tr><tr><td>train/epoch_f1</td><td>0.77319</td></tr><tr><td>train/epoch_loss</td><td>5.22083</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>36</td></tr><tr><td>validation/epoch_f1</td><td>0.41191</td></tr><tr><td>validation/epoch_loss</td><td>5.49208</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.41191</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.49208</td></tr><tr><td>validation/global_step</td><td>36</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_6</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/ni7g4b5r\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/ni7g4b5r</a><br/>\n","Find logs at: <code>./wandb/run-20220113_124723-ni7g4b5r/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 8 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3gnezdpx\" target=\"_blank\">fold_7</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26d9537cf8294a15837b3e8222875209","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_7/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0078s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_7/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 152.284\n","MLP_LP_Try2 Fold 8 F1 Score ---> 0.4715126586634966\n","MLP_LP_Try2 Average F1 Score ---> 0.46215465434842273 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 13589... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1970d70befc343589cbd3d38d984ec66","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.60MB of 0.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▅▆▆▆▆▇▇▇███████████████████▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▅▆▆▇▇▇██</td></tr><tr><td>train/epoch_lr</td><td>███████████▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation/epoch_f1</td><td>▁▄▅▅▆▆▇▆▇▇▇▇███████████████████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▅▆▆▇▇▇██</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▄▅▅▆▆▇▆▇▇▇▇███████████████████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▅▆▆▇▇▇██</td></tr><tr><td>validation/global_step</td><td>▁▂▁▁▁▁▁▄▁▁▁▁▆▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.47151</td></tr><tr><td>fold</td><td>7</td></tr><tr><td>global_step</td><td>20520</td></tr><tr><td>train/epoch_f1</td><td>0.78631</td></tr><tr><td>train/epoch_loss</td><td>5.39599</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>39</td></tr><tr><td>validation/epoch_f1</td><td>0.43463</td></tr><tr><td>validation/epoch_loss</td><td>5.62457</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.43463</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.62457</td></tr><tr><td>validation/global_step</td><td>39</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_7</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3gnezdpx\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/3gnezdpx</a><br/>\n","Find logs at: <code>./wandb/run-20220113_124952-3gnezdpx/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 9 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/2dgc0k1x\" target=\"_blank\">fold_8</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8400cd0d50414cfbb1328225c40650c1","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_8/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_train_batch_end` time: 0.0079s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_8/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 141.135\n","MLP_LP_Try2 Fold 9 F1 Score ---> 0.4582826804893844\n","MLP_LP_Try2 Average F1 Score ---> 0.46172443503075183 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 14302... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72d8829538fb417ca56ed4f0faa4b35a","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.62MB of 0.62MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▆▆▇▇▇▇████████████████▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>█▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▅▆▆▇▇▇███</td></tr><tr><td>train/epoch_lr</td><td>████████▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>validation/epoch_f1</td><td>▁▄▄▅▆▆▆▆▇▇▇▇▇▇▇█▇█████████▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▅▅▆▆▇▇███</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▄▄▅▆▆▆▆▇▇▇▇▇▇▇█▇█████████▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▄▄▅▅▆▆▇▇███</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.45828</td></tr><tr><td>fold</td><td>8</td></tr><tr><td>global_step</td><td>19494</td></tr><tr><td>train/epoch_f1</td><td>0.76285</td></tr><tr><td>train/epoch_loss</td><td>5.54783</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>37</td></tr><tr><td>validation/epoch_f1</td><td>0.39996</td></tr><tr><td>validation/epoch_loss</td><td>5.74365</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.39996</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>5.74365</td></tr><tr><td>validation/global_step</td><td>37</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_8</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/2dgc0k1x\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/2dgc0k1x</a><br/>\n","Find logs at: <code>./wandb/run-20220113_125236-2dgc0k1x/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["===== Fold 10 Prediction =====\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/1hulv4bn\" target=\"_blank\">fold_9</a></strong> to <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<MLP - LP>\n","WARNING : knowcode is not object or category\n","WARNING : knowcode is not object or category\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64138e7a003c40b3b0df3194573acd45","version_minor":0,"version_major":2},"text/plain":["0epoch [00:00, ?epoch/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_9/train\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0075s). Check your callbacks.\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in /content/drive/MyDrive/Colab Notebooks/projects/Dacon/jobknow_recommendation/models/MLP_LP_Try2/logs/fold_9/validation\n"]},{"output_type":"stream","name":"stdout","text":["Fold running time ---> 154.423\n","MLP_LP_Try2 Fold 10 F1 Score ---> 0.45404319998556986\n","MLP_LP_Try2 Average F1 Score ---> 0.4609563115262336 \n","\n","\n"]},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 14986... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b9fb8c28e414d438cbf2f32ddbb281b","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 0.59MB of 0.59MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\">\n","<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>▁</td></tr><tr><td>fold</td><td>▁</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/epoch_f1</td><td>▁▂▃▄▅▅▆▆▇▇▇█████████████████▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train/epoch_loss</td><td>▇▅▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▄▅▅▆▆▆▇▇▇████</td></tr><tr><td>train/epoch_lr</td><td>███████▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>validation/epoch_f1</td><td>▁▃▅▆▆▆▆▇▇▇█████████████████████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/epoch_loss</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>▁▃▅▆▆▆▆▇▇▇█████████████████████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▃▄▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▃▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n","<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_final</td><td>0.45404</td></tr><tr><td>fold</td><td>9</td></tr><tr><td>global_step</td><td>21033</td></tr><tr><td>train/epoch_f1</td><td>0.7366</td></tr><tr><td>train/epoch_loss</td><td>5.94255</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/global_step</td><td>40</td></tr><tr><td>validation/epoch_f1</td><td>0.38784</td></tr><tr><td>validation/epoch_loss</td><td>6.03375</td></tr><tr><td>validation/evaluation_f1_vs_iterations</td><td>0.38784</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>6.03375</td></tr><tr><td>validation/global_step</td><td>40</td></tr></table>\n","</div></div>\n","Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n","<br/>Synced <strong style=\"color:#cdcd00\">fold_9</strong>: <a href=\"https://wandb.ai/frony/dacon_jobknow_recommendation/runs/1hulv4bn\" target=\"_blank\">https://wandb.ai/frony/dacon_jobknow_recommendation/runs/1hulv4bn</a><br/>\n","Find logs at: <code>./wandb/run-20220113_125508-1hulv4bn/logs</code><br/>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}}]},{"cell_type":"code","source":["# wandb.finish()"],"metadata":{"id":"ujoq7Xf0tpbV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Submission"],"metadata":{"id":"NGsDNsh4VI3c"}},{"cell_type":"code","source":["print(model_name)\n","createFolder(folder_path + \"models/\" + model_name + \"/\")\n","dataframe(val_prob).to_csv(folder_path + \"models/\" + model_name + \"/val_prob_\" + target_year + \".csv\", index=False)\n","dataframe(test_prob).to_csv(folder_path + \"models/\" + model_name + \"/test_prob_\" + target_year + \".csv\", index=False)\n","submission = read_csv(folder_path + \"sample_submission.csv\")\n","submission[target_var][submission_idx_start:submission_idx_end+1] = [list(target_encoder.dic_cat[\"knowcode\"].keys())[list(target_encoder.dic_cat[\"knowcode\"].values()).index(i)] for i in test_prob.argmax(axis=1)]\n","submission.to_csv(folder_path + \"models/\" + model_name + \"/submission_\" + model_name + \"_\" + target_year + \".csv\", index=False)\n","submission.head(10)"],"metadata":{"id":"WJzMAE9H2BDD","executionInfo":{"status":"ok","timestamp":1642078696326,"user_tz":-540,"elapsed":20326,"user":{"displayName":"김영준","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpTdFUUaMn51B-vREgj8EQWx2hKK-I4nl4g_I8lA=s64","userId":"06606532799291918175"}},"colab":{"base_uri":"https://localhost:8080/","height":380},"outputId":"c8039709-7ea3-4b9c-9db5-15ddde438e56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MLP_LP_Try2\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-32023b1b-a362-460e-ae17-dfbcd5a82d9d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>knowcode</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>29401</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>155203</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>416101</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>121102</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>412003</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>414503</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>232101</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>12102</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>212101</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>841101</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32023b1b-a362-460e-ae17-dfbcd5a82d9d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-32023b1b-a362-460e-ae17-dfbcd5a82d9d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-32023b1b-a362-460e-ae17-dfbcd5a82d9d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   idx knowcode\n","0    0    29401\n","1    1   155203\n","2    2   416101\n","3    3   121102\n","4    4   412003\n","5    5   414503\n","6    6   232101\n","7    7    12102\n","8    8   212101\n","9    9   841101"]},"metadata":{},"execution_count":33}]}]}