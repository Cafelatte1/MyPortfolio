{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "from numpy import random as np_rnd\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random as rnd\n",
    "from nltk.corpus import stopwords\n",
    "import time \n",
    "import sentencepiece as spm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_polynomial_decay_schedule_with_warmup\n",
    "\n",
    "from eunjeon import Mecab\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences as tf_pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_addons as tfa\n",
    "from eunjeon import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # python random\n",
    "    rnd.seed(seed)\n",
    "    # numpy random\n",
    "    np_rnd.seed(seed)\n",
    "    # RAPIDS random\n",
    "    try:\n",
    "        cupy.random.seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "    # tf random\n",
    "    try:\n",
    "        tf_rnd.set_seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "    # pytorch random\n",
    "    try:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def pickleIO(obj, src, op=\"r\"):\n",
    "    if op==\"w\":\n",
    "        with open(src, op + \"b\") as f:\n",
    "            pickle.dump(obj, f)\n",
    "    elif op==\"r\":\n",
    "        with open(src, op + \"b\") as f:\n",
    "            tmp = pickle.load(f)\n",
    "        return tmp\n",
    "    else:\n",
    "        print(\"unknown operation\")\n",
    "        return obj\n",
    "    \n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print('Error: Creating directory. ' + directory)\n",
    "\n",
    "def findIdx(data_x, col_names):\n",
    "    return [int(i) for i, j in enumerate(data_x) if j in col_names]\n",
    "\n",
    "def diff(first, second):\n",
    "    second = set(second)\n",
    "    return [item for item in first if item not in second]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Block\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_dim, max_len, num_layers=2, dropout_p=0.5):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_len = max_len\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.lin_embed = nn.Linear(embed_dim + (embed_dim // 4) + (embed_dim // 4 // 4), embed_dim)\n",
    "        # learing layer for latent vector\n",
    "        self.gru = nn.LSTM(self.embed_dim, self.embed_dim, num_layers=self.num_layers, dropout=self.dropout_p/4, bidirectional=False, batch_first=True)\n",
    "        # learning block\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(self.dropout_p),\n",
    "            nn.Linear(self.embed_dim, self.embed_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout_p),\n",
    "            nn.Linear(self.embed_dim * 2, self.embed_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, input, input_pos, input_cat, last_hc, global_embedding_layer, pos_embedding, cat_embedding):\n",
    "        # input (B, SEQ)\n",
    "        # embedding (B, SEQ, EMBED)\n",
    "        embed = torch.cat([\n",
    "            global_embedding_layer(input),\n",
    "            pos_embedding(input_pos),\n",
    "            cat_embedding(input_cat),\n",
    "        ], dim=-1)\n",
    "        embed = self.lin_embed(embed)\n",
    "        # GRU (B, SEQ, hidden_layer_size)\n",
    "        output, (hn, cn) = self.gru(embed, last_hc)\n",
    "        # linear transformation on output\n",
    "        output = self.lin(output) + output\n",
    "        return output, (hn, cn)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, embed_dim, max_len, num_layers=2, dropout_p=0.5):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.lin_embed = nn.Linear(embed_dim + (embed_dim // 4) + (embed_dim // 4 // 4), embed_dim)\n",
    "        # learing layer for new latent vector with recent hidden cell state\n",
    "        self.gru = nn.LSTM(self.embed_dim, self.embed_dim, num_layers=self.num_layers, dropout=self.dropout_p/4, bidirectional=False, batch_first=True)\n",
    "        # learning block\n",
    "        self.lin1 = nn.Sequential(\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(self.embed_dim, self.embed_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(self.embed_dim * 2, self.embed_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # learning block\n",
    "        self.lin2 = nn.Sequential(\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(self.embed_dim * 3, self.embed_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(self.embed_dim * 4, self.embed_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(self.embed_dim, self.output_size)\n",
    "\n",
    "    def forward(self, input, input_pos, input_cat, encoder_output, last_hc, last_hidden_state, global_embedding_layer, pos_embedding, cat_embedding):\n",
    "        # input (B, 1) - only one token\n",
    "        embed = torch.cat([\n",
    "            global_embedding_layer(input),\n",
    "            pos_embedding(input_pos),\n",
    "            cat_embedding(input_cat),\n",
    "        ], dim=-1)\n",
    "        embed = self.lin_embed(embed)\n",
    "        # GRU (B, SEQ, hidden_layer_size)\n",
    "        output, (hn, cn) = self.gru(embed, last_hc)\n",
    "        # linear transformation on output\n",
    "        output = self.lin1(output) + output\n",
    "        # (B, 1, EMBED) * (B, EMBED, SEQ) -> (B, 1, SEQ)\n",
    "        attn_weights = F.softmax(torch.bmm(output, encoder_output.transpose(1, 2)), dim=-1)\n",
    "        # (B, 1, SEQ) * (B, EMBED, SEQ) -> (B, 1, EMBED)\n",
    "        attn_applied = torch.bmm(attn_weights, encoder_output)\n",
    "        # linear transformation (attention ouptut + output + last output)\n",
    "        output = self.lin2(torch.cat([attn_applied, output, last_hidden_state], dim=-1))\n",
    "        # get probablity\n",
    "        output_prob = self.classifier(output)\n",
    "\n",
    "        return output, output_prob, (hn, cn)\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, encoder_block, decoder_block, input_size, embed_dim, feature_max_len,  label_max_len, cat_size):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(input_size, embed_dim)\n",
    "        self.encoder_pos_embedding = nn.Embedding(feature_max_len, embed_dim // 4)\n",
    "        self.decoder_pos_embedding = nn.Embedding(label_max_len, embed_dim // 4)\n",
    "        self.cat_embedding = nn.Embedding(cat_size, embed_dim // 4 // 4)\n",
    "        self.encoder_block = encoder_block\n",
    "        self.decoder_block = decoder_block\n",
    "    def get_encoder_output(self, input, input_pos, input_cat, last_hc):\n",
    "        return self.encoder_block(input, input_pos, input_cat, last_hc, self.token_embedding, self.encoder_pos_embedding, self.cat_embedding)\n",
    "    def get_decoder_output(self, input, input_pos, input_cat, encoder_output, last_hc, last_hidden_state):\n",
    "        return self.decoder_block(input, input_pos, input_cat, encoder_output, last_hc, last_hidden_state, self.token_embedding, self.decoder_pos_embedding, self.cat_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamGPT_TextSummarizer():\n",
    "    def __init__(self, model, tokenizer, generating_params, max_len, token_length_limit=128):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.generating_params = generating_params\n",
    "        self.max_len = max_len\n",
    "        self.token_length_limit =token_length_limit\n",
    "        self.model.eval()\n",
    "    def preprocessing(self, text):\n",
    "        text = re.sub(r\"[^가-힣 ]\", \"\", text)\n",
    "        text = \" \".join([i for i in text.split() if len(i) > 1])\n",
    "        return text\n",
    "    def tokenizing(self, text, max_len):\n",
    "        token = torch.tensor([vocab[\"<s>\"]] + self.tokenizer.EncodeAsIds(text)[:(max_len-2)] + [vocab[\"</s>\"]], dtype=torch.int64)\n",
    "        if len(token) < max_len:\n",
    "            token = torch.cat([token, torch.zeros(max_len - len(token), dtype=torch.int64)])\n",
    "        assert len(token) == max_len\n",
    "        return token\n",
    "    def summarize(self, text, cat, device):\n",
    "        text = self.preprocessing(text)\n",
    "        text = self.tokenizing(text, self.max_len)\n",
    "        text = text.view(1, -1).to(device)\n",
    "        cat = torch.tensor([cat], dtype=torch.int64, device=device)\n",
    "        self.model.to(device)\n",
    "        output_cls = []\n",
    "        with torch.no_grad():\n",
    "            encoder_pos = torch.tile(torch.arange(text.shape[1], dtype=torch.int64).view(1, -1), (text.shape[0], 1)).to(device)\n",
    "            last_hc = torch.zeros(generating_params[\"num_layers\"], len(text), generating_params[\"embed_dim\"], device=device) + 1e-7, \\\n",
    "                    torch.zeros(generating_params[\"num_layers\"], len(text), generating_params[\"embed_dim\"], device=device) + 1e-7            \n",
    "            encoder_output, last_hc = model.get_encoder_output(\n",
    "                input=text, input_pos=encoder_pos, input_cat=torch.tile(cat.view(-1, 1), (1, text.shape[-1])), last_hc=last_hc,\n",
    "            )\n",
    "            decoder_output = torch.zeros(len(text), 1, generating_params[\"embed_dim\"], dtype=torch.int64, device=device) + 1e-7\n",
    "            decoder_input = torch.zeros(len(text), 1, dtype=torch.int64, device=device) + vocab[\"</s>\"]\n",
    "            for i in range(self.token_length_limit):\n",
    "                decoder_pos = (torch.zeros(len(text), dtype=torch.int64, device=device).view(-1, 1) + i)\n",
    "                decoder_output, decoder_output_prob, last_hc = self.model.get_decoder_output(\n",
    "                    input=decoder_input, input_pos=decoder_pos, input_cat=cat.view(-1, 1),\n",
    "                    encoder_output=encoder_output, last_hc=last_hc, last_hidden_state=decoder_output\n",
    "                )\n",
    "                decoder_output_prob = decoder_output_prob.squeeze(dim=1)\n",
    "                decoder_output_cls = F.softmax(decoder_output_prob, dim=-1).argmax(dim=-1)\n",
    "                pred_token = decoder_output_cls.squeeze().item()\n",
    "                if pred_token == vocab[\"</s>\"]:\n",
    "                    break\n",
    "                else:\n",
    "                    decoder_input = decoder_output_cls.view(-1, 1)\n",
    "                    output_cls.append(pred_token)\n",
    "        return sp.DecodeIds(output_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_max_len = 122\n",
    "label_max_len = 21\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('tokenizer.model')\n",
    "vocab = {sp.id_to_piece(i): i for i in range(sp.get_piece_size())}\n",
    "\n",
    "cat_lbe = pickleIO(None, \"./cat_lbe.pkl\", \"r\")\n",
    "generating_params = pickleIO(None, \"./model_params.pkl\", \"r\")\n",
    "\n",
    "encoder = EncoderRNN(\n",
    "    input_size=sp.get_piece_size(), embed_dim=generating_params[\"embed_dim\"], max_len=feature_max_len, num_layers=generating_params[\"num_layers\"],\n",
    ")\n",
    "decoder = DecoderRNN(\n",
    "    input_size=sp.get_piece_size(), output_size=sp.get_piece_size(), embed_dim=generating_params[\"embed_dim\"], max_len=label_max_len, num_layers=generating_params[\"num_layers\"],\n",
    ")\n",
    "model = Seq2SeqModel(encoder, decoder, input_size=sp.get_piece_size(), embed_dim=generating_params[\"embed_dim\"], feature_max_len=feature_max_len, label_max_len=label_max_len, cat_size=len(cat_lbe))\n",
    "model.load_state_dict(torch.load(f\"./model_fold{0}_best.pth\", map_location=\"cpu\")[\"model\"])\n",
    "model.to(device)\n",
    "\n",
    "# initialize summarizer\n",
    "teamGPT_summarizer = TeamGPT_TextSummarizer(model, sp, generating_params=generating_params, max_len=feature_max_len, token_length_limit=label_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamGPT_SentimentPredictor():\n",
    "    def __init__(self, model_sent, tokenizer_sent, max_len_sent, stopwords):\n",
    "        self.tokenizer_sent = tokenizer_sent\n",
    "        self.model_sent = model_sent\n",
    "        self.max_len_sent = max_len_sent\n",
    "        self.stopwords = stopwords\n",
    "    def predict_proba(self, new_sentence):\n",
    "        new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "        new_sentence = mecab.morphs(new_sentence)\n",
    "        new_sentence = [word for word in new_sentence if not word in self.stopwords]\n",
    "        encoded = self.tokenizer_sent.texts_to_sequences([new_sentence])\n",
    "        pad_new = tf_pad_sequences(encoded, maxlen=self.max_len_sent)\n",
    "        score = float(self.model_sent.predict(pad_new, verbose=0))\n",
    "        if(score > 0.5):\n",
    "            print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
    "        else:\n",
    "            print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stopwords-ko.txt', 'r', encoding=\"utf8\") as s:\n",
    "    stopwords = [words.strip() for words in s.readlines()]\n",
    "max_len_sent = 80\n",
    "\n",
    "# initializer sentiment predictor\n",
    "teamGPT_sentimentPredictor = TeamGPT_SentimentPredictor(\n",
    "    model_sent=load_model(\"02-0.87113.hdf5\"),\n",
    "    tokenizer_sent=pickleIO(None, \"./tokenizer_sent.pkl\", \"r\"),\n",
    "    max_len_sent=max_len_sent,\n",
    "    stopwords=stopwords,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading crawling data & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pickleIO(None, \"./news_삼성전자.pkl\", \"r\")\n",
    "df_review_shop = pickleIO(None, \"./review_lg그램.pkl\", \"r\")\n",
    "df_review_netflix = pickleIO(None, \"./review_netflix.pkl\", \"r\")\n",
    "df_review_netflix = df_review_netflix[df_review_netflix[\"review\"].apply(len) > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news[\"summarization\"] = df_news[\"sector\"].apply(lambda x: teamGPT_summarizer.summarize(x, 0, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 본문 ===\n",
      "오후 8~11시, 28일까지 표출 [서울경제] 삼성전자(005930)가 국내에서 열릴 갤럭시 Z5 시리즈 신제품 공개 행사 ‘갤럭시 언팩’을 눈앞에 두고 서울 용산구 N서울타워에서 야간 디지털 옥외 광고를 시작했다고 24일 밝혔다.광고는 새로운 갤럭시 폴더블 제품이 최상의 일상을 위해 무한한 가능성을 열어준다는 내용을 담고 있으며, 캠페인 메시지 'Join the flip side'는 기존과 다른 세상(flip side)으로 소비자들을 초대한다는 의미를 가지고 있다고 삼성전자는 설명했다. 남산 야간 디지털 광고는 매일 오후 8~11시까지 진행되며 이달 28일까지 운영된다. 한편 삼성전자는 전통과 미래가 공존하고 글로벌 트렌드와 혁신을 이끄는 대한민국 서울에서 새로운 갤럭시 Z 제품을 선보일 예정이다. 갤럭시 언팩 행사는 오는 26일 서울 코엑스(COEX)에서 진행된다.\n",
      "\n",
      "=== 요약문 ===\n",
      "오후 일까지 표출서울경제 삼성전자가 국내에서 열릴 갤럭시 시리즈 신제품 공개 행사 갤럭시 언팩\n",
      "\n",
      "\n",
      "=== 본문 ===\n",
      "[서울=뉴시스]삼성전자는 게이밍 모니터 '오디세이 OLED G9'이 최근 미국과 영국의 주요 글로벌 IT 매체들로부터 연이은 호평을 받고 있다고 25일 밝혔다. 사진은 프로게이머 '페이커(Faker)'가 서울 강남구에 위치한 T1 사옥에서 세계 최초 듀얼 QHD 해상도를 지원하는 OLED 게이밍 모니터 '오디세이 OLED G9'을 소개하고 있는 모습. (사진=삼성전자 제공) photo@newsis.com *재판매 및 DB 금지[서울=뉴시스]이인준 기자 = 삼성전자는 게이밍 모니터 '오디세이 OLED G9'이 최근 미국과 영국의 주요 글로벌 IT 매체들로부터 연이은 호평을 받고 있다고 25일 밝혔다.오디세이 OLED G9은 미국 일간지 'USA투데이'에서 운영하는 제품 평가 전문 매체 '리뷰드닷컴'이 실시한 게이밍 모니터 평가에서 \"지금까지 테스트한 모니터 중 최고의 성능을 갖췄다\"는 평가와 함께 '에디터스 초이스(Editors` Choice)'에 선정됐다. 이 매체는 또 오디세이 OLED G9이 색 정확도와 명암비가 뛰어날 뿐 아니라 환상적인 응답속도와 고주사율을 제공한다고 설명했다. 또 스트리밍 서비스인 스마트 TV 기능과 게이밍 허브 등의 기능까지 다양한 게이밍 관련 기능을 갖췄다며 극찬했다.글로벌 IT 전문 매체 트러스티드 리뷰(Trusted Reviews)는 오디세이 OLED G9이 뛰어난 몰입감을 제공하는 울트라 와이드 게이밍 모니터라며 '추천(Recommended Award)' 제품으로 선정했다. 그러면서 ▲뛰어난 블랙 화면과 명암비 ▲선명한 색상 ▲0.03ms 응답속도 ▲240Hz 고주사율 등을 호평했다. 영국 IT 전문 매체인 T3는 오디세이 OLED G9에 5점 만점과 함께 플래티넘 어워드(Platinum Award)를 수여했다. 이 매체는 오디세이 OLED G9이 게임과 영화를 위한 환상적인 화질을 만들어내는 훌륭한 게이밍 모니터라고 극찬했다.영국 IT 매체 포켓린트(Pocket-Lint)와 스터프(Stuff)도 오디세이 OLED G9에 5점 만점을 부여했다. 포켓린트는 \"다른 어떤 제품과도 비교할 수 없는 PC 게이밍 경험을 제공하는 제품\"이라 극찬했다. 스터프도 \"현존하는 최고의 게이밍 모니터\"라 평가했다.정훈 삼성전자 영상디스플레이사업부 부사장은 \"더 많은 게이머들이 압도적인 몰입감을 제공하는 뛰어난 화질과 게이밍 성능을 통해 최고의 게임 환경을 제공할 수 있도록 노력할 것\"이라고 말했다.\n",
      "\n",
      "=== 요약문 ===\n",
      "서울뉴시스삼성전자는 게이밍 모니터 오디세이 최근 미국과 영국의 주요\n",
      "\n",
      "\n",
      "=== 본문 ===\n",
      "[스타뉴스 | 김혜림 기자] /사진제공=삼성전자'삼성스토어'가 갤럭시 최초의 '한국 언팩'을 알린다.삼성전자는 서울 서초구 강남대로에 위치한 '삼성 강남'과 '삼성스토어 청담', '삼성스토어 대치' 등 서울 주요 삼성스토어에서 갤럭시 최초의 '한국 언팩'을 알리고 있다고 25일 밝혔다. 삼성전자는 오는 26일, 27회차를 맞이하는 갤럭시 언팩을 사상 최초로 대한민국 서울에서 진행한다. '갤럭시 언팩'은 삼성전자 스마트폰 '갤럭시'의 신제품 공개 행사로, 지난 2010년 미국 라스베이거스에서 최초의 갤럭시 S 공개로 처음 시작됐다.이후, 스페인 바르셀로나, 독일 베를린, 영국 런던, 미국 뉴욕, 샌프란시스코 등 전세계 주요 도시에서 글로벌 미디어, 파트너 등을 대상으로 갤럭시 언팩을 진행해 왔다.\n",
      "\n",
      "=== 요약문 ===\n",
      "스타뉴스 김혜림 기자 사진제공삼성전자삼성스토어가 갤럭시 최초의 한국 언\n",
      "\n",
      "\n",
      "=== 본문 ===\n",
      "삼성전자가 '갤럭시 언팩'을 눈앞에 두고, 서울 용산구 남산 'N서울타워'에서 야간 디지털 옥외 광고를 시작했다. 사진=삼성전자 제공삼성전자가 '갤럭시 언팩'을 눈앞에 두고, 서울 용산구 남산 'N서울타워'에서 야간 디지털 옥외 광고를 시작했다고 24일 밝혔다.광고는 새로운 갤럭시 폴더블 제품이 최상의 일상을 위해 무한한 가능성을 열어준다는 내용을 담고 있다. 캠페인 메시지 'Join the flip side'는 기존과 다른 세상(flip side)으로 소비자들을 초대한다는 의미를 뜻한다.남산 'N서울타워'에서 진행되는 '갤럭시 언팩' 야간 디지털 광고는 매일 밤 8시부터 11시까지 진행되며, 오는 28일까지 운영된다. 삼성전자는 오는 26일 서울 강남구 코엑스(COEX)에서 신제품 공개 행사 '삼성 갤럭시 언팩 2023'을 개최하고 갤럭시Z플립·폴드5를 비롯한 새로운 갤럭시 제품을 선보일 계획이다. 삼성전자가 '갤럭시 언팩'을 눈앞에 두고, 서울 용산구 남산 'N서울타워'에서 야간 디지털 옥외 광고를 시작했다. 사진=삼성전자 제공\n",
      "\n",
      "=== 요약문 ===\n",
      "삼성전자가 갤럭시 언팩을 눈앞에 두고 서울 용산구 남산 서울타워에서 야간 디지털 옥\n",
      "\n",
      "\n",
      "=== 본문 ===\n",
      "89형 마이크로 LED 통해 초프리미엄 시장 리더십 강화 삼성전자 모델이 서울 소공동 삼성스토어 롯데 본점에서 89형 마이크로 LED 신제품을 소개하고 있다. /삼성전자삼성전자가 89형 마이크로 LED(MNA89MS1BACXKR) 모델을 출시하며 초프리미엄 TV 시장에서 리더십을 강화한다.삼성전자는 89형 마이크로 LED 모델을 국내 시장에 출시한다고 23일 밝혔다. 출고가는 1억3000만 원이다.지난 4월 중국에 처음 출시한 89형 마이크로 LED는 압도적인 화질로 궁극의 스크린 경험을 제공하는 초프리미엄 제품이다.마이크로 LED는 마이크로미터(㎛) 단위의 LED가 백라이트나 컬러필터 없이 스스로 빛과 색을 내 최상의 화질을 구현하며, 베젤 없는 디자인으로 어떠한 환경에서도 몰입감 있는 시청 경험을 선사한다.삼성전자는 89형 마이크로 LED 출시를 기념해 이달 말까지 제품을 구매하면 500만 삼성전자 멤버십 포인트에 더해 85형 더 프레임과 HW-Q990C 사운드바 패키지, 더 프리스타일 풀 패키지를 증정한다.황태환 삼성전자 한국 총괄 부사장은 \"89형 모델을 시작으로 76·101·114형까지 마이크로 LED 라인업을 확대해 소비자의 초프리미엄 TV 선택지를 넓힐 것\"이라며 \"차세대 디스플레이 기술 초격차를 유지해 시장을 선도해 나가겠다\"고 말했다.발로 뛰는 더팩트는 24시간 여러분의 제보를 기다립니다.▶카카오톡: '더팩트제보' 검색▶이메일: jebo@tf.co.kr▶뉴스 홈페이지: http://talk.tf.co.kr/bbs/report/write\n",
      "\n",
      "=== 요약문 ===\n",
      "마이크로 통해 초프리미엄 시장 리더십 강화삼성전자 모델이 서울 소공동 삼성스토\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df_news.sample(n=5, random_state=GLOBAL_SEED)\n",
    "for i, j in zip(df_tmp[\"sector\"], df_tmp[\"summarization\"]):\n",
    "    print(\"=== 본문 ===\")\n",
    "    print(\" \".join(i.replace(\"\\n\", \" \").replace(\"\\t\", \" \").split()))\n",
    "    print()\n",
    "    print(\"=== 요약문 ===\")\n",
    "    print(j)\n",
    "    print(\"\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.65% 확률로 긍정 리뷰입니다.\n",
      "89.79% 확률로 긍정 리뷰입니다.\n",
      "85.08% 확률로 긍정 리뷰입니다.\n",
      "99.22% 확률로 긍정 리뷰입니다.\n",
      "99.46% 확률로 긍정 리뷰입니다.\n",
      "92.39% 확률로 긍정 리뷰입니다.\n",
      "99.17% 확률로 긍정 리뷰입니다.\n",
      "99.17% 확률로 긍정 리뷰입니다.\n",
      "96.61% 확률로 긍정 리뷰입니다.\n",
      "99.23% 확률로 긍정 리뷰입니다.\n",
      "98.28% 확률로 긍정 리뷰입니다.\n",
      "96.72% 확률로 긍정 리뷰입니다.\n",
      "86.32% 확률로 긍정 리뷰입니다.\n",
      "97.04% 확률로 긍정 리뷰입니다.\n",
      "87.81% 확률로 긍정 리뷰입니다.\n",
      "98.66% 확률로 긍정 리뷰입니다.\n",
      "99.36% 확률로 긍정 리뷰입니다.\n",
      "98.38% 확률로 긍정 리뷰입니다.\n",
      "92.59% 확률로 긍정 리뷰입니다.\n",
      "99.06% 확률로 긍정 리뷰입니다.\n",
      "96.92% 확률로 긍정 리뷰입니다.\n",
      "99.46% 확률로 긍정 리뷰입니다.\n",
      "99.25% 확률로 긍정 리뷰입니다.\n",
      "96.04% 확률로 긍정 리뷰입니다.\n",
      "98.83% 확률로 긍정 리뷰입니다.\n",
      "99.72% 확률로 긍정 리뷰입니다.\n",
      "92.23% 확률로 긍정 리뷰입니다.\n",
      "99.25% 확률로 긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "df_review_shop[\"sent\"] = df_review_shop[\"review\"].apply(lambda x: teamGPT_sentimentPredictor.predict_proba(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 리뷰 ===\n",
      "기대이상으로 좋아요 색상도 깔끔하고 편리해요\n",
      "\n",
      "=== 감성분석 결과 (긍정) ===\n",
      "0.9922633171081543\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "그램치고 싸게 잘 산 것 같아서 대만족입니다! 진짜 가벼워요ㅋㅋ 디자인도 너무 예쁘고 성능도 좋아요! 부팅 진짜 빨라요 ㅎㅎ 14인치 고민했는데 딱 좋습니당!\n",
      "\n",
      "=== 감성분석 결과 (긍정) ===\n",
      "0.9971944093704224\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "배송 엄청 빨라서 좋네요 삼성기사가 직접 와서 이것저것 확인도 해주셨어요\n",
      "\n",
      "=== 감성분석 결과 (긍정) ===\n",
      "0.9660723209381104\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "쿠폰 설명도 잘 되어 있어서 할인 받아서 저렴하게 잘 구매했습니다. 배송도 금요일에 주문해서 월요일에 받아 빠르게 받을 수 있어서 좋았습니다. 사은품도 많이 받을 수 있게 되어 있어서 편합니다. 포장도 깔끔하게 왔고, 받자마자 켜보고 테스트 하고 있습니다. 다음에 또 노트북 구매할 일 있으면 여기서 구매할 의사 있습니다. 감사합니다 ^^\n",
      "\n",
      "=== 감성분석 결과 (긍정) ===\n",
      "0.9946125745773315\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "노트북이 필요해서 고민하다가 lg그램으로 선택했습니다. 15.6인치를 쓰고있어서 작은건 아닐까걱정했는데 괜찮네요 속도도 빠르고 디자인도 훌륭합니다 특히 여성분들 쓰기에 좋겠네요 사장님도 많이 친절하시답니다.\n",
      "\n",
      "=== 감성분석 결과 (긍정) ===\n",
      "0.9965307116508484\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df_review_shop.sample(n=5, random_state=GLOBAL_SEED)\n",
    "for i, j in zip(df_tmp[\"review\"], df_tmp[\"sent\"]):\n",
    "    print(\"=== 리뷰 ===\")\n",
    "    print(\" \".join(i.replace(\"\\n\", \" \").replace(\"\\t\", \" \").split()))\n",
    "    print()\n",
    "    print(\"=== 감성분석 결과 (긍정) ===\")\n",
    "    print(j)\n",
    "    print(\"\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.73% 확률로 긍정 리뷰입니다.\n",
      "98.83% 확률로 긍정 리뷰입니다.\n",
      "96.18% 확률로 긍정 리뷰입니다.\n",
      "97.65% 확률로 부정 리뷰입니다.\n",
      "99.09% 확률로 긍정 리뷰입니다.\n",
      "97.46% 확률로 부정 리뷰입니다.\n",
      "95.54% 확률로 부정 리뷰입니다.\n",
      "99.73% 확률로 부정 리뷰입니다.\n",
      "85.64% 확률로 부정 리뷰입니다.\n",
      "99.70% 확률로 부정 리뷰입니다.\n",
      "60.02% 확률로 긍정 리뷰입니다.\n",
      "95.59% 확률로 부정 리뷰입니다.\n",
      "96.87% 확률로 부정 리뷰입니다.\n",
      "68.39% 확률로 부정 리뷰입니다.\n",
      "98.31% 확률로 부정 리뷰입니다.\n",
      "60.02% 확률로 긍정 리뷰입니다.\n",
      "98.10% 확률로 긍정 리뷰입니다.\n",
      "98.67% 확률로 부정 리뷰입니다.\n",
      "89.50% 확률로 긍정 리뷰입니다.\n",
      "97.22% 확률로 긍정 리뷰입니다.\n"
     ]
    }
   ],
   "source": [
    "df_review_netflix[\"sent\"] = df_review_netflix[\"review\"].apply(lambda x: teamGPT_sentimentPredictor.predict_proba(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 리뷰 ===\n",
      "솔직히 보고나서 시즌2 나올까봐 두려웠다\n",
      "\n",
      "=== 감성분석 결과 ===\n",
      "긍정적 의견입니다 (긍정일 확률 : 64.73%)\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "지루한바다,발암의바다. 승리호를 타고 7광구로 가서 오합지졸 발암쑈를 벌임. 공유,김선영 머리에 뭘처바른건지 무적헤어. 팀장이무생 무슨컨셉인지 웅얼웅얼(모레시계최민수?), 김썬이성욱 초반에 죽었어도 무방. 애초에 그인원이 필요가 있었나?초반,극중간중간 cg는 잘만든 게임수준. 감독이 극을 끌어가기에 역부족. 90분 정도로 편집하면 그나마 좀 나을듯.\n",
      "\n",
      "=== 감성분석 결과 ===\n",
      "부정적 의견입니다 (긍정일 확률 : 1.33%)\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "클린봇이 부적절한 표현을 감지한 댓글입니다.\n",
      "\n",
      "=== 감성분석 결과 ===\n",
      "긍정적 의견입니다 (긍정일 확률 : 60.02%)\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "전형적인 sf판타지물 내가 진짜 좋아하는장르 시즌2도 나왔으면 좋겠다 이런시국에 차분하고 자극적이지않아 생각을 조용히 할수있어서 너무 좋맣음 인물들의 오버성도 없고\n",
      "\n",
      "=== 감성분석 결과 ===\n",
      "긍정적 의견입니다 (긍정일 확률 : 98.83%)\n",
      "\n",
      "\n",
      "=== 리뷰 ===\n",
      "고요하게 내가 잠이 들어버림\n",
      "\n",
      "=== 감성분석 결과 ===\n",
      "부정적 의견입니다 (긍정일 확률 : 14.36%)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df_review_netflix.sample(n=5, random_state=GLOBAL_SEED)\n",
    "for i, j in zip(df_tmp[\"review\"], df_tmp[\"sent\"]):\n",
    "    print(\"=== 리뷰 ===\")\n",
    "    print(\" \".join(i.replace(\"\\n\", \" \").replace(\"\\t\", \" \").split()))\n",
    "    print()\n",
    "    print(\"=== 감성분석 결과 ===\")\n",
    "    print(f\"{'부정적 의견입니다' if j < 0.5 else '긍정적 의견입니다'} (긍정일 확률 : {round(j * 100, 2)}%)\")\n",
    "    print(\"\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
