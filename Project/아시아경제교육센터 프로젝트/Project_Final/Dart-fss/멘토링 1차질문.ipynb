{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"멘토링 1차질문.ipynb","provenance":[],"collapsed_sections":["nzCUyWQsOoDr"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nzCUyWQsOoDr"},"source":["# 모듈 import"]},{"cell_type":"code","metadata":{"id":"nRwPg_myOahe"},"source":["import os\n","import IPython\n","import multiprocessing\n","import copy\n","import pickle\n","import warnings\n","from datetime import datetime\n","from time import time\n","from matplotlib import font_manager as fm, rc, rcParams\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","\n","import numpy as np\n","from numpy import array, nan, random as rnd, where as which\n","import pandas as pd\n","from pandas import DataFrame as dataframe, Series as series, isna, read_csv\n","from pandas.tseries.offsets import DateOffset\n","from scipy.special import boxcox1p\n","from scipy.stats import skew\n","from scipy import stats\n","\n","from sklearn import preprocessing as prep\n","from sklearn.impute import KNNImputer\n","from sklearn.model_selection import train_test_split as tts, GridSearchCV as GridTuner, StratifiedKFold, KFold\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n","from sklearn import metrics\n","from sklearn.pipeline import make_pipeline\n","\n","from sklearn import linear_model as lm\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as qda\n","from sklearn import svm\n","import lightgbm as lgb\n","import xgboost as xgb\n","import catboost as cat\n","from sklearn import neighbors as knn\n","from sklearn import ensemble\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import layers\n","from tensorflow.keras import activations\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import metrics as tf_metrics\n","from tensorflow.keras import callbacks as tf_callbacks\n","from tqdm.keras import TqdmCallback\n","from scikeras.wrappers import KerasClassifier, KerasRegressor\n","import tensorflow_addons as tfa\n","import keras_tuner as kt\n","from keras_tuner import HyperModel\n","\n","# display setting\n","warnings.filterwarnings(action='ignore')\n","rcParams['axes.unicode_minus'] = False\n","pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 100)\n","pd.set_option('display.width', 1000)\n","\n","# font setting\n","font_path = 'myfonts/NanumSquareB.ttf'\n","font_obj = fm.FontProperties(fname=font_path, size=12).get_name()\n","rc('font', family=font_obj)\n","\n","# %reset -f\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hpxo8i-3OurM"},"source":["# 기본 사용함수"]},{"cell_type":"code","metadata":{"id":"wfaDS7H7O3aE"},"source":["# ===== utility functions =====\n","\n","# label encoding for categorical column with excepting na value\n","class MyLabelEncoder:\n","    def __init__(self, preset={}):\n","        # dic_cat format -> {\"col_name\": {\"value\": replace}}\n","        self.dic_cat = preset\n","    def fit_transform(self, data_x, col_names):\n","        tmp_x = copy.deepcopy(data_x)\n","        for i in col_names:\n","            # type check\n","            if not ((tmp_x[i].dtype.name == \"object\") or (tmp_x[i].dtype.name == \"category\")):\n","                print(F\"WARNING : {i} is not object or category\")\n","            # if key is not in dic, update dic\n","            if i not in self.dic_cat.keys():\n","                tmp_dic = dict.fromkeys(sorted(set(tmp_x[i]).difference([nan])))\n","                label_cnt = 0\n","                for j in tmp_dic.keys():\n","                    tmp_dic[j] = label_cnt\n","                    label_cnt += 1\n","                self.dic_cat[i] = tmp_dic\n","            # transform value which is not in dic to nan\n","            tmp_x[i] = tmp_x[i].astype(\"object\")\n","            conv = tmp_x[i].replace(self.dic_cat[i])\n","            for conv_idx, j in enumerate(conv):\n","                if j not in self.dic_cat[i].values():\n","                    conv[conv_idx] = nan\n","            # final return\n","            tmp_x[i] = conv.astype(\"float\")\n","        return tmp_x\n","    def transform(self, data_x, col_names):\n","        tmp_x = copy.deepcopy(data_x)\n","        for i in col_names:\n","            if not ((tmp_x[i].dtype.name == \"object\") or (tmp_x[i].dtype.name == \"category\")):\n","                print(F\"WARNING : {i} is not object or category\")\n","            # transform value which is not in dic to nan\n","            tmp_x[i] = tmp_x[i].astype(\"object\")\n","            conv = tmp_x[i].replace(self.dic_cat[i])\n","            for conv_idx, j in enumerate(conv):\n","                if j not in self.dic_cat[i].values():\n","                    conv[conv_idx] = nan\n","            # final return\n","            tmp_x[i] = conv.astype(\"float\")\n","        return tmp_x\n","    def clear(self, dic_cat={}):\n","        self.dic_cat = dic_cat\n","\n","class MyOneHotEncoder:\n","    def __init__(self, label_preset={}):\n","        self.dic_cat = {}\n","        self.label_preset = label_preset\n","    def fit_transform(self, data_x, col_names):\n","        tmp_x = dataframe()\n","        for i in data_x:\n","            if i not in col_names:\n","                tmp_x = pd.concat([tmp_x, dataframe(data_x[i])], axis=1)\n","            else:\n","                if not ((data_x[i].dtype.name == \"object\") or (data_x[i].dtype.name == \"category\")):\n","                    print(F\"WARNING : {i} is not object or category\")\n","                self.dic_cat[i] = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n","                conv = self.dic_cat[i].fit_transform(dataframe(data_x[i])).astype(\"int\")\n","                col_list = []\n","                for j in self.dic_cat[i].categories_[0]:\n","                    if i in self.label_preset.keys():\n","                        for k, v in self.label_preset[i].items():\n","                            if v == j:\n","                                col_list.append(str(i) + \"_\" + str(k))\n","                    else:\n","                        col_list.append(str(i) + \"_\" + str(j))\n","                conv = dataframe(conv, columns=col_list)\n","                tmp_x = pd.concat([tmp_x, conv], axis=1)\n","        return tmp_x\n","    def transform(self, data_x, col_names):\n","        tmp_x = dataframe()\n","        for i in data_x:\n","            if not i in col_names:\n","                tmp_x = pd.concat([tmp_x, dataframe(data_x[i])], axis=1)\n","            else:\n","                if not ((data_x[i].dtype.name == \"object\") or (data_x[i].dtype.name == \"category\")):\n","                    print(F\"WARNING : {i} is not object or category\")\n","                conv = self.dic_cat[i].transform(dataframe(data_x[i])).astype(\"int\")\n","                col_list = []\n","                for j in self.dic_cat[i].categories_[0]:\n","                    if i in self.label_preset.keys():\n","                        for k, v in self.label_preset[i].items():\n","                            if v == j: col_list.append(str(i) + \"_\" + str(k))\n","                    else:\n","                        col_list.append(str(i) + \"_\" + str(j))\n","                conv = dataframe(conv, columns=col_list)\n","                tmp_x = pd.concat([tmp_x, conv], axis=1)\n","        return tmp_x\n","    def clear(self, dic_cat={}, label_preset={}):\n","        self.dic_cat = dic_cat\n","        self.label_preset = label_preset\n","\n","class MyKNNImputer:\n","    def __init__(self, k=5):\n","        self.imputer = KNNImputer(n_neighbors=k)\n","        self.cat_dic = {}\n","        self.naidx_dix = {}\n","    def fit_transform(self, x, y, cat_vars=None):\n","        for i in cat_vars:\n","            self.cat_dic[i] = diff(list(sorted(set(x[i]))), [nan])\n","            self.naidx_dix[i] = list(which(array(x[i].isna()))[0])\n","        x_imp = dataframe(self.imputer.fit_transform(x, y), columns=x.columns)\n","\n","        # if imputed categorical value are not in the range, adjust the value\n","        for i in cat_vars:\n","            x_imp[i] = x_imp[i].apply(lambda x: int(round(x, 0)))\n","            for j in self.naidx_dix[i]:\n","                if x_imp[i][j] not in self.cat_dic[i]:\n","                    if x_imp[i][j] < self.cat_dic[i][0]:\n","                        x_imp[i][self.naidx_dix[i]] = self.cat_dic[i][0]\n","                    elif x_imp[i][j] > self.cat_dic[i][0]:\n","                        x_imp[i][self.naidx_dix[i]] = self.cat_dic[i][len(self.cat_dic[i]) - 1]\n","        return x_imp\n","    def transform(self, x):\n","        for i in self.cat_dic.keys():\n","            self.naidx_dix[i] = list(which(array(x[i].isna()))[0])\n","        x_imp = dataframe(self.imputer.transform(x), columns=x.columns)\n","\n","        # if imputed categorical value are not in the range, adjust the value\n","        for i in self.cat_dic.keys():\n","            x_imp[i] = x_imp[i].apply(lambda x: int(round(x, 0)))\n","            for j in self.naidx_dix[i]:\n","                if x_imp[i][j] not in self.cat_dic[i]:\n","                    if x_imp[i][j] < self.cat_dic[i][0]:\n","                        x_imp[i][self.naidx_dix[i]] = self.cat_dic[i][0]\n","                    elif x_imp[i][j] > self.cat_dic[i][0]:\n","                        x_imp[i][self.naidx_dix[i]] = self.cat_dic[i][len(self.cat_dic[i]) - 1]\n","        return x_imp\n","    def clear(self, cat_dic={}, naidx_dix={}):\n","        self.cat_dic = cat_dic\n","        self.naidx_dix = naidx_dix\n","\n","def easyIO(x=None, path=None, op=\"r\"):\n","    tmp = None\n","    if op == \"r\":\n","        with open(path, \"rb\") as f:\n","            tmp = pickle.load(f)\n","        return tmp\n","    elif op == \"w\":\n","        tmp = {}\n","        print(x)\n","        if type(x) is dict:\n","            for k in x.keys():\n","                if \"MLP\" in k:\n","                    tmp[k] = {}\n","                    for model_comps in x[k].keys():\n","                        if model_comps != \"model\":\n","                            tmp[k][model_comps] = copy.deepcopy(x[k][model_comps])\n","                    print(F\"INFO : {k} model is removed (keras)\")\n","                else:\n","                    tmp[k] = x[k]\n","        if input(\"Write [y / n]: \") == \"y\":\n","            with open(path, \"wb\") as f:\n","                pickle.dump(tmp, f)\n","            print(\"operation success\")\n","        else:\n","            print(\"operation fail\")\n","    else:\n","        print(\"Unknown operation type\")\n","\n","def diff(first, second):\n","    second = set(second)\n","    return [item for item in first if item not in second]\n","\n","def findIdx(data_x, col_names):\n","    return [int(i) for i, j in enumerate(data_x) if j in col_names]\n","\n","def orderElems(for_order, using_ref):\n","    return [i for i in using_ref if i in for_order]\n","# concatenate by row\n","\n","def ccb(df1, df2):\n","    if type(df1) == series:\n","        tmp_concat = series(pd.concat([dataframe(df1), dataframe(df2)], axis=0, ignore_index=True).iloc[:,0])\n","        tmp_concat.reset_index(drop=True, inplace=True)\n","    elif type(df1) == dataframe:\n","        tmp_concat = pd.concat([df1, df2], axis=0, ignore_index=True)\n","        tmp_concat.reset_index(drop=True, inplace=True)\n","    elif type(df1) == np.ndarray:\n","        tmp_concat = np.concatenate([df1, df2], axis=0)\n","    else:\n","        print(\"Unknown Type: return 1st argument\")\n","        tmp_concat = df1\n","    return tmp_concat\n","\n","def change_width(ax, new_value):\n","    for patch in ax.patches :\n","        current_width = patch.get_width()\n","        adj_value = current_width - new_value\n","        # we change the bar width\n","        patch.set_width(new_value)\n","        # we recenter the bar\n","        patch.set_x(patch.get_x() + adj_value * .5)\n","        \n","def dispPerformance(result_dic, result_metrics):\n","    perf_table = dataframe(columns=result_metrics)\n","    for k, v in result_dic.items():\n","        perf_table = pd.concat([perf_table, v[\"performance\"]], ignore_index=True, axis=0)\n","    print(perf_table)\n","    return perf_table\n","\n","\n","# from sklearn import datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f4oJz96DPuZT"},"source":["# 1. dart_fss api로 rawdata 불러오기"]},{"cell_type":"code","metadata":{"id":"yzzxFI-3PZqk"},"source":["import dart_fss as dart\n","from pykrx import stock\n","# # dart_fss_classifier Plugin 불러오기 (IFRS 도입(2011년) 전의 재무제표와의 호환성)\n","# import dart_fss_classifier\n","# # Attach plugin\n","# assert dart_fss_classifier.attached_plugin() == True\n","api_key = '730e8899e231f24386cdbff47d900047cf016caf'\n","dart.set_api_key(api_key)\n","\n","#전체 기업재무정보 리스트\n","corp_list = dart.corp.CorpList()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Njs6sx0bSwEZ"},"source":["# 2. 데이터셋 기본설정 함수\n","\n","*   원본 재무제표 로드 함수\n","*   재무제표 columns 정리(수, 일자 매칭) 함수\n","*   stock code 로드 함수\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"5PDUmZl6QKO5"},"source":["#1-- raw data 로드 함수\n","def getFinancialStatement(tickers, from_date=\"20140101\", end_date=\"20210930\", report_type=[\"annual\"]):\n","    # create dictionary for dataset\n","    # 기업들을 저장할 딕셔너리 초기화\n","    fs_dic = dict.fromkeys(tickers, None)\n","\n","    # for loop on tickers\n","    for i in tickers:\n","        print(\"Financial Statement Loading --->\", i)\n","        try:\n","            # 각 기업의 재무데이터를 저장할 딕셔너리 초기화\n","            fs_dic[i] = {}\n","            # 재무제표 로딩\n","            corp_obj = corp_list.find_by_corp_name(i, exactly=True)[0]. \\\n","                extract_fs(bgn_de=from_date, end_de=end_date, report_tp=report_type, separator=False)\n","            fs_dic[i][\"bs\"] = corp_obj[\"bs\"]\n","            fs_dic[i][\"is\"] = corp_obj[\"is\"]\n","            fs_dic[i][\"cis\"] = corp_obj[\"cis\"]\n","            fs_dic[i][\"cf\"] = corp_obj[\"cf\"]\n","            fs_dic[i][\"metrics\"] = {}\n","            fs_dic[i][\"stock_code\"] = {}\n","        except:\n","            # 만약 로딩 시 에러가 발생하면 해당 키 (해당 기업)을 딕셔너리에서 삭제\n","            print('EXCEPTION : Error occurs, delete the key')\n","            del fs_dic[i]\n","    return fs_dic\n","\n","#2-- 재무제표 데이터의 적절한 컬럼을 추출하는 함수 (2차원 컬럼 -> 1차원 컬럼)\n","def clearFinancialStatement(fs):\n","    fs_copy = copy.deepcopy(fs)\n","    try:\n","        for i in list(fs.keys()):\n","            print(\"===== Columns clearing\", i, \"=====\")\n","            # label_ko 열에서 한글만 추출하기 위한 re 조건식 지정\n","            expression_hangul = re.compile('[^가-힣+]')\n","\n","            # Balance Sheet\n","            # 2차원 컬럼에서 필요한 열을 추출해 저장할 리스트 생성\n","            selected_idx = []\n","            selected_column = []\n","            # 2중 컬럼에 대한 for loop 수행\n","            for idx, name in enumerate(fs_copy[i][\"bs\"]):\n","                # 튜플 형식으로 넘어오는 name 에 대해 검사 수행\n","                # 만약 label_ko (매출액, 당기순이익 등의 계정과목이 저장된 열) 이면 저장\n","                if name[1] == \"label_ko\":\n","                    selected_idx.append(idx)\n","                    selected_column.append(name[1])\n","                # 일자의 경우 튜플 형식으로 넘어오므로, 튜플 확인 조건문 수행\n","                # 만약 튜플이고, 해당 튜플의 첫번쨰 튜플 원소가 '연결재무제표' 인 경우 저장 (오타단어 포함)\n","                if type(name[1]) == tuple and (name[1][0] == \"연결재무제표\" or name[1][0] == \"연결재무재표\"):\n","                    selected_idx.append(idx)\n","                    selected_column.append(name[0])\n","            # 반복문의 통해 선택된 열 인덱스 및 열 이름으로 새로운 데이터프레임 생성\n","            tmp_df = fs_copy[i][\"bs\"].iloc[:, selected_idx]\n","            tmp_df.columns = selected_column\n","            # label_ko 의 문자열에 대해 한글만 추출한 뒤 공백을 모두 제거\n","            tmp_df[\"label_ko\"] = tmp_df[\"label_ko\"].apply(lambda x: expression_hangul.sub(\"\", x).replace(\" \", \"\"))\n","            # na 및 공백을 모두 0으로 대치\n","            fs_copy[i][\"bs\"] = tmp_df.fillna(0.0)\n","            fs_copy[i][\"bs\"].replace([\"\", \" \"], 0.0, inplace=True)\n","            # 각 컬럼의 일자를 YYYYMMDD 형식으로 통일 (fiscal year 의 마지막 일자)\n","            tmp_cols = [\"label_ko\"]\n","            for j in fs_copy[i][\"bs\"].columns[1:]:\n","                tmp_cols.append(j.split(\"-\")[-1])\n","            fs_copy[i][\"bs\"].columns = tmp_cols\n","            # 중복 컬럼이 있는 데이터에 대해서는 0이 제일 적은 열만 선택\n","            dup_cols = fs_copy[i][\"bs\"].columns.value_counts().index[fs_copy[i][\"bs\"].columns.value_counts() > 1]\n","            if len(dup_cols) != 0:\n","                print(\"WARNING : duplicated date columns exist (column which has the least zero values is selected)\")\n","                min_zero_col = np.inf\n","                drop_cols = []\n","                for j in dup_cols:\n","                    dup_col_idx = which(fs_copy[i][\"bs\"].columns == j)[0]\n","                    for z in dup_col_idx:\n","                        if (fs_copy[i][\"bs\"].iloc[:, z] == 0).sum() <= min_zero_col:\n","                            min_zero_col = z\n","                    drop_cols = drop_cols + diff(dup_col_idx, [z])\n","                fs_copy[i][\"bs\"] = fs_copy[i][\"bs\"].iloc[:, diff(list(range(len(fs_copy[i][\"bs\"].columns))), drop_cols)]\n","\n","\n","            # 손익계산서가 None 이면 포괄손익계산서를 사용\n","            # 손익계산서가 None 이 아니면 포괄손익계산서(cis) 키값에 대입 후 손익계산서(is) 키는 사용 하지 않음\n","            if fs_copy[i][\"is\"] is None:\n","                # Consolidated Income Statement\n","                selected_idx_cis = []\n","                selected_column_cis = []\n","                for idx, name in enumerate(fs_copy[i][\"cis\"]):\n","                    if name[1] == \"label_ko\":\n","                        selected_idx_cis.append(idx)\n","                        selected_column_cis.append(name[1])\n","                    if type(name[1]) == tuple and (name[1][0] == \"연결재무제표\" or name[1][0] == \"연결재무재표\"):\n","                        selected_idx_cis.append(idx)\n","                        selected_column_cis.append(name[0])\n","                tmp_df = fs_copy[i][\"cis\"].iloc[:, selected_idx_cis]\n","                tmp_df.columns = selected_column_cis\n","                tmp_df[\"label_ko\"] = tmp_df[\"label_ko\"].apply(lambda x: expression_hangul.sub(\"\", x).replace(\" \", \"\"))\n","                fs_copy[i][\"cis\"] = tmp_df.fillna(0.0)\n","                fs_copy[i][\"cis\"].replace([\"\", \" \"], 0.0, inplace=True)\n","            else:\n","                # Income Statement\n","                selected_idx_cis = []\n","                selected_column_cis = []\n","                for idx, name in enumerate(fs_copy[i][\"is\"]):\n","                    if name[1] == \"label_ko\":\n","                        selected_idx_cis.append(idx)\n","                        selected_column_cis.append(name[1])\n","                    if type(name[1]) == tuple and (name[1][0] == \"연결재무제표\" or name[1][0] == \"연결재무재표\"):\n","                        selected_idx_cis.append(idx)\n","                        selected_column_cis.append(name[0])\n","                tmp_df = fs_copy[i][\"is\"].iloc[:, selected_idx_cis]\n","                tmp_df.columns = selected_column_cis\n","                tmp_df[\"label_ko\"] = tmp_df[\"label_ko\"].apply(lambda x: expression_hangul.sub(\"\", x).replace(\" \", \"\"))\n","                fs_copy[i][\"cis\"] = tmp_df.fillna(0.0)\n","                fs_copy[i][\"cis\"].replace([\"\", \" \"], 0.0, inplace=True)\n","            del fs_copy[i][\"is\"]\n","\n","            tmp_cols = [\"label_ko\"]\n","            for j in fs_copy[i][\"cis\"].columns[1:]:\n","                tmp_cols.append(j.split(\"-\")[-1])\n","            fs_copy[i][\"cis\"].columns = tmp_cols\n","\n","            dup_cols = fs_copy[i][\"cis\"].columns.value_counts().index[fs_copy[i][\"cis\"].columns.value_counts() > 1]\n","            if len(dup_cols) != 0:\n","                print(\"WARNING : duplicated date columns exist (column which has the least zero values is selected)\")\n","                min_zero_col = np.inf\n","                drop_cols = []\n","                for j in dup_cols:\n","                    dup_col_idx = which(fs_copy[i][\"cis\"].columns == j)[0]\n","                    for z in dup_col_idx:\n","                        if (fs_copy[i][\"cis\"].iloc[:, z] == 0).sum() <= min_zero_col:\n","                            min_zero_col = z\n","                    drop_cols = drop_cols + diff(dup_col_idx, [z])\n","                fs_copy[i][\"cis\"] = fs_copy[i][\"cis\"].iloc[:, diff(list(range(len(fs_copy[i][\"cis\"].columns))), drop_cols)]\n","\n","            # Cash Flow Chart\n","            selected_idx_cf = []\n","            selected_column_cf = []\n","            for idx, name in enumerate(fs_copy[i][\"cf\"]):\n","                if name[1] == \"label_ko\":\n","                    selected_idx_cf.append(idx)\n","                    selected_column_cf.append(name[1])\n","                if type(name[1]) == tuple and (name[1][0] == \"연결재무제표\" or name[1][0] == \"연결재무재표\"):\n","                    selected_idx_cf.append(idx)\n","                    selected_column_cf.append(name[0])\n","            tmp_df = fs_copy[i][\"cf\"].iloc[:, selected_idx_cf]\n","            tmp_df.columns = selected_column_cf\n","            tmp_df[\"label_ko\"] = tmp_df[\"label_ko\"].apply(lambda x: expression_hangul.sub(\"\", x).replace(\" \", \"\"))\n","            fs_copy[i][\"cf\"] = tmp_df.fillna(0.0)\n","            fs_copy[i][\"cf\"].replace([\"\", \" \"], 0.0, inplace=True)\n","\n","            tmp_cols = [\"label_ko\"]\n","            for j in fs_copy[i][\"cf\"].columns[1:]:\n","                tmp_cols.append(j.split(\"-\")[-1])\n","            fs_copy[i][\"cf\"].columns = tmp_cols\n","\n","            dup_cols = fs_copy[i][\"cf\"].columns.value_counts().index[fs_copy[i][\"cf\"].columns.value_counts() > 1]\n","            if len(dup_cols) != 0:\n","                print(\"WARNING : duplicated date columns exist (column which has the least zero values is selected)\")\n","                min_zero_col = np.inf\n","                drop_cols = []\n","                for j in dup_cols:\n","                    dup_col_idx = which(fs_copy[i][\"cf\"].columns == j)[0]\n","                    for z in dup_col_idx:\n","                        if (fs_copy[i][\"cf\"].iloc[:, z] == 0).sum() <= min_zero_col:\n","                            min_zero_col = z\n","                    drop_cols = drop_cols + diff(dup_col_idx, [z])\n","                fs_copy[i][\"cf\"] = fs_copy[i][\"cf\"].iloc[:, diff(list(range(len(fs_copy[i][\"cf\"].columns))), drop_cols)]\n","\n","        return fs_copy\n","    except:\n","        print(\"ERROR : return original\")\n","        return fs\n","\n","\n","#3-- 각 기업 재무제표의 컬럼수 조정 및 일자 매칭 여부 점검 함수\n","def alignFinancialStatement(fs, cut_off_year=2019, min_recent_year=3, column_unmatched_exception=\"remove\"):\n","    '''\n","    :param fs: 특정 기업의 재무데이터가 있는 딕셔너리\n","    :param cut_off_year: 재무제표에서 제외시킬 최소년도 (ex. 2019 으로 설정된 경우 2019년 이상인 년도는 모두 drop)\n","    :param min_recent_year: 최소로 존재해야 할 재무제표 (ex. 2019, 2018 년만 존재할 경우 해당 기업 drop)\n","    :param column_unmatched_exception: bs, cis, cf 의 컬럼 일자가 맞지 않을 경우 처리 방법을 지정 (default : \"remove\")\n","    :return: 정상수행 시 전처리된 컬럼을 가진 fs를 리턴, 오류발생 시 원본 fs 를 리턴\n","    '''\n","    fs_copy = copy.deepcopy(fs)\n","    try:\n","        for k in list(fs.keys()):\n","            print(\"===== Columns preprocessing\", k, \"=====\")\n","            # balance sheet, income statement, cash flow chart 의 컬럼 수를 비교\n","            col_length_check = array([fs_copy[k][\"bs\"].shape[1], fs_copy[k][\"cis\"].shape[1], fs_copy[k][\"cf\"].shape[1]])\n","            column_cutoff = col_length_check.min()\n","            # 만약 컬럼 수가 다르면 수행\n","            if col_length_check.var() != 0.0:\n","                print(\"WARNING : Column's lengths are not same\", col_length_check)\n","                # 각 재무제표의 첫 열 중 가장 작은 값 및 마지막 열 중 가장 큰 값을 계산 (min_col_first ~ max_col_last 범위의 열 선택이 목적)\n","                min_col_first = str(min(array([fs_copy[k][\"bs\"].columns[1], fs_copy[k][\"cis\"].columns[1], fs_copy[k][\"cf\"].columns[1]], dtype=\"int\")))\n","                max_col_last = str(max(array([fs_copy[k][\"bs\"].columns[-1], fs_copy[k][\"cis\"].columns[-1], fs_copy[k][\"cf\"].columns[-1]], dtype=\"int\")))\n","                # 강제로 가장 적은 열을 가진 재무데이터에 다른 데이터들을 맞추도록 하는 flag 설정\n","                min_cutoff_flag = False\n","                # slicing 할 열의 인덱스 위치를 저장할 딕셔너리 생성\n","                cutoff_index = {\"bs\": None, \"cis\": None, \"cf\": None}\n","                for i in [\"bs\", \"cis\", \"cf\"]:\n","                    # 위에서 선정한 min_col_first 및 max_col_last 가 각각의 재무제표 열 안에 존재하는지 확인\n","                    # 만약 존재 하지 않으면 강제로 가장 작은 열을 가진 재무데이터에 다른 재무데이터들을 마지막 열부터 드랍하여 맞춤\n","                    if (min_col_first not in fs_copy[k][i].columns) or (max_col_last not in fs_copy[k][i].columns):\n","                        print(\"WARNING : an interval date doesn't exist in column sequence\")\n","                        # 강제 설정되었으므로 flag를 True로 변경\n","                        min_cutoff_flag = True\n","                        # 모든 재무데이터에 일자가 존재해야하므로 한 경우라도 발생하면 break\n","                        break\n","                    else:\n","                        # 일자가 열에 존재하면 min_col_first 와 max_col_first 의 인덱스 위치를 찾아 cut_off_index 딕셔너리에 저장\n","                        cutoff_index[i] = (which(fs_copy[k][i].columns == min_col_first)[0][0], which(fs_copy[k][i].columns == max_col_last)[0][0])\n","\n","                # min_cutoff_flag 가 False 이면\n","                if min_cutoff_flag:\n","                    fs_copy[k][\"bs\"] = fs_copy[k][\"bs\"].iloc[:, 0:column_cutoff]\n","                    fs_copy[k][\"cis\"] = fs_copy[k][\"cis\"].iloc[:, 0:column_cutoff]\n","                    fs_copy[k][\"cf\"] = fs_copy[k][\"cf\"].iloc[:, 0:column_cutoff]\n","                else:\n","                    # 각 재무데이터를 min_col_first ~ max_col_last 일자로 맞춤\n","                    for i in [\"bs\", \"cis\", \"cf\"]:\n","                        fs_copy[k][i] = fs_copy[k][i].iloc[:, [0] + list(range(cutoff_index[i][0], cutoff_index[i][1]+1))]\n","                    length_check_after_cutting = array([fs_copy[k][\"bs\"].shape[1], fs_copy[k][\"cis\"].shape[1], fs_copy[k][\"cf\"].shape[1]])\n","                    # 만약 중간에 비어있는 일자 떄문에 재무데이터 간 컬럼 갯수가 맞지 않으면 해당 기업 drop (ex. 2019 2018 2016 과 같은 열)\n","                    if length_check_after_cutting.var() != 0:\n","                        print(\"WARNING : lengths are not same after cutting\")\n","                        del fs_copy[k]\n","                        continue\n","                    else:\n","                        column_cutoff = length_check_after_cutting.min()\n","                # 최종 슬라이싱 된 각 재무데이터의 열을 출력\n","                print(\"After cutting :\", array([fs_copy[k][\"bs\"].shape[1], fs_copy[k][\"cis\"].shape[1], fs_copy[k][\"cf\"].shape[1]]))\n","\n","            # bs, cis, cf 의 컬럼의 날짜를 align 하는 부분\n","            # 열 일자 매칭 검사에 대한 해당 기업 drop 여부 flag\n","            col_notmatch_flag = False\n","            # label_ko을 제외한 (계정과목 관련) 데이터에 대해 for loop 수행\n","            for i in range(1, column_cutoff):\n","                cols_date = array([fs_copy[k][\"bs\"].columns[i], fs_copy[k][\"cis\"].columns[i], fs_copy[k][\"cf\"].columns[i]]).astype(\"int32\")\n","                # 만약 각 재무제표들의 컬럼 일자가 맞지 않으면 경고 메시지 출력\n","                if cols_date.var() != 0:\n","                    print(\"WARNING : Cross check error on each columns' date\")\n","                    print(cols_date)\n","                    # column_unmatched_exception 파라미터가 \"remove\" 이면 해당 기업 drop\n","                    if column_unmatched_exception == \"remove\":\n","                        print(\"DELETE : column_unmatched_exception == 'remove'\")\n","                        del fs_copy[k]\n","                        col_notmatch_flag = True\n","                    # 한 열이라도 맞지 않으면 작업을 수행할 수 없으므로 한 번 조건 통과 시 break\n","                    break\n","\n","            # col_notmath_flag 가 False 이면 수행 (각 재무데이터의 컬럼이 align 되어있으면)\n","            if not col_notmatch_flag:\n","                # cut_off_year 미만인 컬럼의 인덱스를 구함 (label_ko 는 강제 포함)\n","                seleted_cols = list(which(pd.to_datetime(series(fs_copy[k][\"bs\"].drop(\"label_ko\", axis=1).columns)).dt.year < cut_off_year)[0] + 1)\n","                # 각 재무제표들을 선택된 인덱스를 슬라이싱 하여 재저장 후 이름을 bs의 열 이름으로 통합\n","                fs_copy[k][\"bs\"] = fs_copy[k][\"bs\"].iloc[:, ([0] + seleted_cols)]\n","                fs_copy[k][\"cis\"] = fs_copy[k][\"cis\"].iloc[:, ([0] + seleted_cols)]\n","                fs_copy[k][\"cf\"] = fs_copy[k][\"cf\"].iloc[:, ([0] + seleted_cols)]\n","                # 최소 요구년도보다 적은 열만 있는 기업 드랍\n","                if (fs_copy[k][\"bs\"].shape[1] < min_recent_year + 1):\n","                    print(\"DELETE : financial data is less than\", min_recent_year)\n","                    del fs_copy[k]\n","                    continue\n","                # 최소 요구년도 이상의 열 중 첫 열의 년도가 cut_off_year - 1 이 아니면 해당 기업 드랍\n","                if (pd.to_datetime(fs_copy[k][\"bs\"].columns[1]).year != cut_off_year-1):\n","                    print(\"DELETE : first column is not\", cut_off_year-1)\n","                    del fs_copy[k]\n","                    continue\n","                # 계정과목에 해당 하는 값이 모두 0인 경우 (label_ko 열을 제외한 모든 열의 값이 0인 경우) 해당 계정과목을 drop 합니다\n","                fs_copy[k][\"bs\"] = fs_copy[k][\"bs\"][(fs_copy[k][\"bs\"].iloc[:, 1:] != 0).any(True)]\n","                fs_copy[k][\"bs\"].reset_index(drop=True, inplace=True)\n","                fs_copy[k][\"cis\"] = fs_copy[k][\"cis\"][(fs_copy[k][\"cis\"].iloc[:, 1:] != 0).any(True)]\n","                fs_copy[k][\"cis\"].reset_index(drop=True, inplace=True)\n","                fs_copy[k][\"cf\"] = fs_copy[k][\"cf\"][(fs_copy[k][\"cf\"].iloc[:, 1:] != 0).any(True)]\n","                fs_copy[k][\"cf\"].reset_index(drop=True, inplace=True)\n","        return fs_copy\n","    except:\n","        print(\"ERROR : return original\")\n","        return fs\n","\n","\n","#4-- 해당 기업의 종목코드를 불러오는 함수\n","def getStockcode(fs):\n","    fs_copy = copy.deepcopy(fs)\n","    for i in list(fs.keys()):\n","        fs_copy[i][\"stock_code\"] = corp_list.find_by_corp_name(i, exactly=True)[0].info[\"stock_code\"]\n","    return fs_copy\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAqRTaVETYxH"},"source":["# 3. stock sector 별 재무데이터 dictionary에 저장"]},{"cell_type":"code","metadata":{"id":"oLcFzemUQ7gP"},"source":["\n","sector_list = [\"comm_services\", \"discretionary\", \"energy\",\n","               \"health_care\", \"industrials\", \"it\", \"materials\", \"staples\"]\n","sector = {}\n","start_time = time()\n","\n","#상단의 함수를 이용하여 sector별 데이터 dictionary에 저장\n","for i in sector_list:\n","    sector[i] = easyIO(None, \"./kdigital_project3/fs_rawdata_\" + i + \".pickle\", op=\"r\")\n","    sector[i] = clearFinancialStatement(sector[i])\n","    sector[i] = alignFinancialStatement(sector[i], cut_off_year=2020, min_recent_year=3, column_unmatched_exception=\"remove\")\n","    sector[i] = getStockcode(sector[i])\n","\n","time() - start_time\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OnCH9XddTrcE"},"source":["# 4. 학습데이터에 필요한 features 생성"]},{"cell_type":"markdown","metadata":{"id":"emmJdcmXT4cI"},"source":["(1) feature 에 필요한 서브지표 계산 함수"]},{"cell_type":"code","metadata":{"id":"Zk5rQV7ORwkC"},"source":["# 연도별 매출액\n","def getRevenue(fs_meta, years=3, multidriverException=\"sum\"):\n","    # 서비스업은 주로 매출액이 아닌 영업수익 계정과목으로 매출실적을 나타냄\n","    condition_list = [\"영업수익\", \"영업수익매출액\"]\n","    primary_check_list = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: (x in condition_list) and (\"매출원가\" not in x))\n","\n","    # 영업수익 또는 영업수익매출액 키워드를 찾고, 없으면 제조업과 관련된 계정과목으로 매출실적을 찾음\n","    if primary_check_list.sum() == 0:\n","        condition_list = [\"매출\", \"매출액\", \"수익매출액\", '수익']\n","        primary_check_list = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: (x in condition_list or \"매출액\" in x or \"수익매출액\" in x) and (\"매출원가\" not in x))\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cis\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cis\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return nan\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 영업이익\n","def getOperatingIncome(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"영업이익\", \"영업이익손실\", \"영업손익\", \"영업손실\"]\n","    primary_check_list = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cis\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cis\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                          fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return nan\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                      fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        \n","# 연도별 당기순이익\n","def getEarnings(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"당기순이익\", \"당기순이익손실\", \"당기순손실\", \"당기순손익\", \"연결당기순손익\", \"연결당기순이익손실\"]\n","    primary_check_list = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","    if primary_check_list.sum() == 0:\n","        condition_list = [\"지배기업의소유주에게귀속되는당기순이익손실\", \"지배기업의소유주지분\"]\n","        primary_check_list = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cis\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cis\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                          fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return nan\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                      fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        \n","# 연도별 EPS\n","def getEPS(fs_meta, years=3, multidriverException=\"first\", epsType=\"either\", mixed_eps_fisrt=True):\n","    '''\n","    :param fs_meta:\n","    :param years:\n","    :param multidriverException:\n","    :param epsType:\n","    :param mixed_eps_fisrt:\n","    :return:\n","    additional : eps 벡터 중 0 값이 있을경우, 자동적으로 계속 및 중단 eps 의 합으로 대체하는 연산을 수행합니다\n","    '''\n","\n","    mixed_eps = [\"기본및희석주당보통주순이익손실\", \"기본및희석주당이익\", \"기본및희석주당순이익\",\n","                 \"기본및희석주당이익손실\", \"기본및희석주당순손실\", \"기본및희석주당순이익손실\"]\n","    mixed_continuing_eps = [\"계속영업기본및희석주당이익손실\", \"계속영업기본및희석주당순이익\"]\n","    mixed_discontinued_eps = [\"중단영업기본및희석주당이익손실\", \"중단영업기본및희석주당순이익\"]\n","\n","    basic_eps = [\"기본주당이익\", \"기본주당순이익\", \"기본주당이익손실\", \"기본주당순이익손실\", \"기본주당손익\",\n","                 \"기본보통주당순이익\", \"기본보통주당순이익\", \"보통주기본주당이익\", \"기본주당손실\", \"보통주기본주당순이익\"]\n","    basic_continuing_eps = [\"계속영업기본주당이익손실\", \"계속영업기본주당순손익\", \"계속영업기본주당손실\"]\n","    basic_discontinued_eps = [\"중단영업기본주당이익손실\", \"중단영업기본주당순손익\", \"중단영업기본주당손실\"]\n","\n","    diluted_eps = [\"희석주당이익\", \"희석주당순이익\", \"희석주당이익손실\", \"희석주당순이익손실\", \"희석주당손익\",\n","                   \"희석보통주당순이익\", \"희석보통주당순이익\", \"보통주희석주당이익\", \"희석주당손실\", \"보통주희석주당순이익\"]\n","    diluted_continuing_eps = [\"계속영업희석주당이익손실\", \"계속영업희석주당순손익\", \"계속영업희석주당이익\"]\n","    diluted_discontinued_eps = [\"중단영업희석주당이익손실\", \"중단영업희석주당순손익\", \"중단영업희석주당손실\"]\n","\n","    # mixed_eps_first == True 이면, 기본 및 희석 eps 를 탐색합니다\n","    if mixed_eps_fisrt:\n","        mixed_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in mixed_eps)\n","\n","        # 기본 및 희석 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","        if mixed_label.sum() > 0:\n","            # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","            if multidriverException == \"first\":\n","                mixed_eps_vector = fs_meta[\"cis\"][mixed_label].iloc[0, 1:(1 + years)]\n","            # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","            else:\n","                mixed_eps_vector = fs_meta[\"cis\"][mixed_label].iloc[:, 1:(1 + years)].sum(axis=0)\n","\n","        else:\n","            mixed_eps_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                      fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","        # 기본 eps vector 에 0인 값이 존재하면,\n","        # 계속영업 및 중단영업 합으로 대체하는 process를 수행합니다\n","        if (mixed_eps_vector == 0).sum() > 0:\n","            continuing_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in mixed_continuing_eps)\n","            discontinued_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in mixed_discontinued_eps)\n","\n","            # 계속영업 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if continuing_label.sum() > 0:\n","                continuing_vector = fs_meta[\"cis\"][continuing_label].iloc[0, 1:(1 + years)]\n","            else:\n","                continuing_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                           fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 중단영업 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if discontinued_label.sum() > 0:\n","                discontinued_vector = fs_meta[\"cis\"][discontinued_label].iloc[0, 1:(1 + years)]\n","            else:\n","                discontinued_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                             fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 기본 eps vector에 0인 값을 계속영업 eps + 중단영업 eps 값으로 대체합니다\n","            con_discon_sum = continuing_vector + discontinued_vector\n","            for idx, value in enumerate(mixed_eps_vector):\n","                if value == 0:\n","                    mixed_eps_vector[idx] = con_discon_sum[idx]\n","\n","        # eps vector 값이 모두 0이면 다음 process를 진행합니다\n","        if (mixed_eps_vector == 0).all():\n","            print(\"Mixed EPS values are all zeros ---> pass\")\n","            pass\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return mixed_eps_vector\n","    else:\n","        pass\n","\n","    # 기본 eps 탐색\n","    if epsType == \"basic\":\n","        basic_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in basic_eps)\n","\n","        # 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","        if basic_label.sum() > 0:\n","            # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","            if multidriverException == \"first\":\n","                basic_eps_vector = fs_meta[\"cis\"][basic_label].iloc[0, 1:(1 + years)]\n","            # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","            else:\n","                basic_eps_vector = fs_meta[\"cis\"][basic_label].iloc[:, 1:(1 + years)].sum(axis=0)\n","        else:\n","            basic_eps_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                      fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","        # 기본 eps vector 에 0인 값이 존재하면,\n","        # 계속영업 및 중단영업 합으로 대체하는 process를 수행합니다\n","        if (basic_eps_vector == 0).sum() > 0:\n","            continuing_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in basic_continuing_eps)\n","            discontinued_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in basic_discontinued_eps)\n","\n","            # 계속영업 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if continuing_label.sum() > 0:\n","                continuing_vector = fs_meta[\"cis\"][continuing_label].iloc[0, 1:(1 + years)]\n","            else:\n","                continuing_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                           fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 중단영업 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if discontinued_label.sum() > 0:\n","                discontinued_vector = fs_meta[\"cis\"][discontinued_label].iloc[0, 1:(1 + years)]\n","            else:\n","                discontinued_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                             fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 기본 eps vector에 0인 값을 계속영업 eps + 중단영업 eps 값으로 대체합니다\n","            con_discon_sum = continuing_vector + discontinued_vector\n","            for idx, value in enumerate(basic_eps_vector):\n","                if value == 0:\n","                    basic_eps_vector[idx] = con_discon_sum[idx]\n","\n","        # eps vector 값이 모두 0이면 다음 nan을 리턴합니다\n","        if (basic_eps_vector == 0).all():\n","            print(\"ERROR : EPS values are all zeros ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                          fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return basic_eps_vector\n","    # 희석 eps 탐색\n","    elif epsType == \"diluted\":\n","        diluted_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in diluted_eps)\n","\n","        # 희석 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","        if diluted_label.sum() > 0:\n","            # 계정과목이 하나 이상 탐지된 경우 제일 첫번째 열만 사용합니다\n","            if multidriverException == \"first\":\n","                diluted_eps_vector = fs_meta[\"cis\"][diluted_label].iloc[0, 1:(1 + years)]\n","            # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","            else:\n","                diluted_eps_vector = fs_meta[\"cis\"][diluted_label].iloc[:, 1:(1 + years)].sum(axis=0)\n","        else:\n","            diluted_eps_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                        fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","        # 희석 eps vector 에 0인 값이 존재하면,\n","        # 계속영업 및 중단영업 합으로 대체하는 process를 수행합니다\n","        if (diluted_eps_vector == 0).sum() > 0:\n","            continuing_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in diluted_continuing_eps)\n","            discontinued_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in diluted_discontinued_eps)\n","\n","            # 계속영업 희석 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if continuing_label.sum() > 0:\n","                continuing_vector = fs_meta[\"cis\"][continuing_label].iloc[0, 1:(1 + years)]\n","            else:\n","                continuing_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                           fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 중단영업 희석 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if discontinued_label.sum() > 0:\n","                discontinued_vector = fs_meta[\"cis\"][discontinued_label].iloc[0, 1:(1 + years)]\n","            else:\n","                discontinued_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                             fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 희석 eps vector에 0인 값을 계속영업 eps + 중단영업 eps 값으로 대체합니다\n","            con_discon_sum = continuing_vector + discontinued_vector\n","            for idx, value in enumerate(diluted_eps_vector):\n","                if value == 0:\n","                    diluted_eps_vector[idx] = con_discon_sum[idx]\n","\n","        # eps vector 값이 모두 0이면 다음 nan을 리턴합니다\n","        if (diluted_eps_vector == 0).all():\n","            print(\"ERROR : EPS values are all zeros ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                          fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return diluted_eps_vector\n","    # 기본 eps 및 희석 eps 를 둘 다 탐색하여, 기본 eps 가 0 이면 희석 eps 값으로 대체\n","    else:\n","        # ===== basic eps 계산 =====\n","        basic_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in basic_eps)\n","\n","        # 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","        if basic_label.sum() > 0:\n","            # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","            if multidriverException == \"first\":\n","                basic_eps_vector = fs_meta[\"cis\"][basic_label].iloc[0, 1:(1 + years)]\n","            # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","            else:\n","                basic_eps_vector = fs_meta[\"cis\"][basic_label].iloc[:, 1:(1 + years)].sum(axis=0)\n","        else:\n","            basic_eps_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                      fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","        # 기본 eps vector 에 0인 값이 존재하면,\n","        # 계속영업 및 중단영업 합으로 대체하는 process를 수행합니다\n","        if (basic_eps_vector == 0).sum() > 0:\n","            continuing_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in basic_continuing_eps)\n","            discontinued_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in basic_discontinued_eps)\n","\n","            # 계속영업 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if continuing_label.sum() > 0:\n","                continuing_vector = fs_meta[\"cis\"][continuing_label].iloc[0, 1:(1 + years)]\n","            else:\n","                continuing_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                           fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 중단영업 기본 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if discontinued_label.sum() > 0:\n","                discontinued_vector = fs_meta[\"cis\"][discontinued_label].iloc[0, 1:(1 + years)]\n","            else:\n","                discontinued_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                             fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 기본 eps vector에 0인 값을 계속영업 eps + 중단영업 eps 값으로 대체합니다\n","            con_discon_sum = continuing_vector + discontinued_vector\n","            for idx, value in enumerate(basic_eps_vector):\n","                if value == 0:\n","                    basic_eps_vector[idx] = con_discon_sum[idx]\n","\n","        # ===== diluted eps 대치 =====\n","        # eps vector 에 0인 값이 하나라도 있으면\n","        if (basic_eps_vector == 0).sum() > 0:\n","            print(\"diluted eps replacement process\")\n","            diluted_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in diluted_eps)\n","\n","            # 희석 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","            if diluted_label.sum() > 0:\n","                # 계정과목이 하나 이상 탐지된 경우 제일 첫번째 열만 사용합니다\n","                if multidriverException == \"first\":\n","                    diluted_eps_vector = fs_meta[\"cis\"][diluted_label].iloc[0, 1:(1 + years)]\n","                # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","                else:\n","                    diluted_eps_vector = fs_meta[\"cis\"][diluted_label].iloc[:, 1:(1 + years)].sum(axis=0)\n","            else:\n","                diluted_eps_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                            fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","            # 희석 eps vector 에 0인 값이 존재하면,\n","            # 계속영업 및 중단영업 합으로 대체하는 process를 수행합니다\n","            if (diluted_eps_vector == 0).sum() > 0:\n","                continuing_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in diluted_continuing_eps)\n","                discontinued_label = fs_meta[\"cis\"][\"label_ko\"].apply(lambda x: x in diluted_discontinued_eps)\n","\n","                # 계속영업 희석 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","                if continuing_label.sum() > 0:\n","                    continuing_vector = fs_meta[\"cis\"][continuing_label].iloc[0, 1:(1 + years)]\n","                else:\n","                    continuing_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                               fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","                # 중단영업 희석 eps 를 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","                if discontinued_label.sum() > 0:\n","                    discontinued_vector = fs_meta[\"cis\"][discontinued_label].iloc[0, 1:(1 + years)]\n","                else:\n","                    discontinued_vector = series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                                                 fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","\n","                # 희석 eps vector에 0인 값을 계속영업 eps + 중단영업 eps 값으로 대체합니다\n","                con_discon_sum = continuing_vector + discontinued_vector\n","                for idx, value in enumerate(diluted_eps_vector):\n","                    if value == 0:\n","                        diluted_eps_vector[idx] = con_discon_sum[idx]\n","\n","            # 기본 eps vector에 0인 값을 희석 eps vector의 값으로 대체합니다\n","            for idx, value in enumerate(basic_eps_vector):\n","                if value == 0:\n","                    basic_eps_vector[idx] = diluted_eps_vector[idx]\n","\n","        # eps vector 값이 모두 0이면 다음 nan을 리턴합니다\n","        if (basic_eps_vector == 0).all():\n","            print(\"ERROR : EPS values are all zeros ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index),\n","                          fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return basic_eps_vector\n","\n","# 연도별 법인세\n","def getTax(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"법인세의납부\", \"법인세비용수익\", \"법인세납부환급\", \"법인세납부\", \"법인세비용\", \"법인세납부액\", \"법인세의환급지급\", \"법인세환급\",\n","                      \"법인세환급납부\", \"법인세납부영업\", \"법인세비용\", \"법인세납부액환급액\"]\n","    primary_check_list = fs_meta[\"cf\"][\"label_ko\"].apply(lambda x: x in condition_list or \"법인세\" in x)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 이자비용\n","def getInterestExpense(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"이자비용\", \"이자의지급\", \"이자지급\", \"이자지급영업\"]\n","    primary_check_list = fs_meta[\"cf\"][\"label_ko\"].apply(lambda x: x in condition_list or \"이자비용\" in x or \"이자지급\" in x)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 감가상각비\n","def getDepreciationAndAmortization(fs_meta, years=3, multidriverException=\"sum\"):\n","    condition_list = [\"감가상각비\", \"자산상각비\", \"대손상각비\", \"당기순이익조정을위한가감\", \"조정\", \"수익비용의조정\", \"무형자산감가상각비\"]\n","    primary_check_list = fs_meta[\"cf\"][\"label_ko\"].apply(lambda x: x in condition_list or \"자산상각비\" in x or \"감가상각비\" in x)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 자기자본\n","def getEquity(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"자본총계\"]\n","    primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","    if primary_check_list.sum() == 0:\n","        condition_list = [\"자본\"]\n","        primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return nan\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 부채\n","def getDebt(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"부채총계\"]\n","    primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","    if primary_check_list.sum() == 0:\n","        condition_list = [\"부채\"]\n","        primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return nan\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 영업활동 현금흐름 (조정항목이 계산되지 않은 현금흐름)\n","def getCFO(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"영업활동현금흐름\", \"영업활동으로인한현금흐름\"]\n","    primary_check_list = fs_meta[\"cf\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return nan\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 영업에서 창출된 현금흐름 (조정항목이 미리 계산된 현금흐름)\n","def getAdjCFO(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"영업에서창출된현금흐름\", \"영업으로부터창출된현금흐름\", \"영업에서창출된현금\", \"계속영업에서창출된현금흐름\",\\\n","                      \"영업활동으로부터창출된현금흐름\",\"영업활동에서창출된현금흐름\",\"영업활동으로창출된현금\", \"영업으로부터창출된현금\" ]\n","\n","    primary_check_list = fs_meta[\"cf\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 재고자산\n","def getInventory(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = ['재고자산']\n","    primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 유동자산\n","def getCurrentAsset(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"유동자산\"]\n","    primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 유동부채\n","def getCurrentLiab(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"유동부채\"]\n","    primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return nan\")\n","            return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return nan\")\n","        return series([nan] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 배당금\n","def getDividend(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"배당금지급\", \"배당금의지급\", '배당금의지급등']\n","    primary_check_list = fs_meta[\"cf\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 자사주매입금\n","def getBuyback(fs_meta, years=3, multidriverException=\"first\"):\n","    condition_list = [\"자기주식의처분\", '자기주식의취득']\n","    primary_check_list = fs_meta[\"cf\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"cf\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"cf\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 매출채권 (not used)\n","def getBond(fs_meta, years=3, multidriverException=\"sum\"):\n","    condition_list = [\"매출채권및기타채권\", \"매출채권\", '매출채권및기타유동채권', '매출채권및기타채권', '매출채권및대출채권',\n","                      '매출채권및기타수취채권', '매출채권및수취채권', '매출채권및계약자산', '단기매출채권', '유동매출채권및기타채권']\n","\n","    primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","\n","# 연도별 현금성자산 (not used)\n","def getCash(fs_meta, years=3, multidriverException=\"sum\"):\n","    condition_list = ['현금및현금성자산', '현금']\n","    primary_check_list = fs_meta[\"bs\"][\"label_ko\"].apply(lambda x: x in condition_list)\n","\n","    # 계정과목을 탐색하여 vector를 생성하고, 존재하지 않을 경우 0인 벡터를 생성합니다\n","    if primary_check_list.sum() > 0:\n","        if primary_check_list.sum() > 1: print(\"WARNING : Multi drivers are detected\")\n","        # 계정과목이 하나 이상 탐지된 경우 제일 첫 번째 열을 사용합니다\n","        if multidriverException == \"first\":\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[0, 1:(1 + years)]\n","        # 계정과목이 여러 개 탐지된 경우 모두 합산한 값을 사용합니다\n","        else:\n","            output_vector = fs_meta[\"bs\"][primary_check_list].iloc[:, 1:(1 + years)].sum(axis=0)\n","        # eps vector 값이 모두 0일 경우 리턴값을 설정합니다\n","        if (output_vector == 0).all():\n","            print(\"INFO : All values are zero ---> return 0\")\n","            return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        # 아니면 eps vector 를 리턴합니다\n","        else:\n","            return output_vector\n","    # driver가 찾아지지 않은 경우, 리턴값을 설정합니다\n","    else:\n","        print(\"ERROR : Any driver is not found ---> return 0\")\n","        return series([0] * len(fs_meta[\"cis\"].iloc[0, 1:(1 + years)].index), fs_meta[\"bs\"].iloc[0, 1:(1 + years)].index)\n","        \n","# 연도별 일평균 주가 (종가기준)\n","def getStockPrice(fs_meta, stock_dates=(), item_name=\"종가\", op=\"mean\"):\n","    if type(stock_dates) in (tuple, list):\n","        from_date = stock_dates[0]\n","        to_date = stock_dates[1]\n","    else:\n","        from_date = (pd.to_datetime(datetime.now()) - DateOffset(days=stock_dates)).strftime('%Y%m%d')\n","        to_date = pd.to_datetime(datetime.now()).strftime('%Y%m%d')\n","    if op == \"mean\":\n","        ohlc = stock.get_market_ohlcv_by_date(fromdate=from_date, todate=to_date, ticker=fs_meta[\"stock_code\"]).resample(\"1Y\").mean().transpose()\n","        ohlc.columns = ohlc.columns.to_series().apply(lambda x: x.strftime(\"%Y%m%d\"))\n","        ohlc.reset_index(inplace=True)\n","        ohlc.columns = [\"label_ko\"] + list(ohlc.columns[1:])\n","        ohlc.columns.name = None\n","        ohlc = ohlc[ohlc[\"label_ko\"] == item_name].iloc[0, 1:]\n","        ohlc.sort_index(ascending=False, inplace=True)\n","    else:\n","        ohlc = stock.get_market_ohlcv_by_date(fromdate=from_date, todate=to_date, ticker=fs_meta[\"stock_code\"])\n","    return ohlc\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0S_r8uXTUYrh"},"source":["(2) feature 계산함수\n","\n","*   성장성 지표\n","*   안정성 지표\n","*   수익성 지표\n","*   가치평가 지표\n","*   주주환원 지표\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"1YshhU4xSA3v"},"source":["\n","# ===== financial statement =====\n","# 1. 성장성 지표 (전체기간 평균 증가율)\n","# 매출액 평균 성장률\n","# 영입이익 평균 성장률\n","# EBITDA 평균 성장률\n","# EPS 평균 성장률\n","def getRateOfChange(df):\n","    df = df.iloc[0]\n","    df.sort_index(inplace=True)\n","    df = df.replace(0, nan).interpolate()\n","    return df.pct_change()[1:].mean()\n","def getGrowthIndicator(fs, years=7):\n","    fs_copy = copy.deepcopy(fs)\n","    print(fs_copy.keys())\n","    for i in fs.keys():\n","        print(i)\n","        ##매출액 연평균 성장률\n","        a = getRevenue(fs_copy[i], years=years)\n","        a = a.to_frame().T\n","        # print(growth(a, years))\n","        try:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_revenue\"] = getRateOfChange(a, len(a.columns))\n","        except:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_revenue\"] = nan\n","\n","        ##영업이익 연평균 성장률\n","        b = getOperatingIncome(fs_copy[i], years=years)\n","        b = b.to_frame().T\n","        # print(growth(b, years))\n","        try:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_operating_income\"] = getRateOfChange(b, len(b.columns))\n","        except:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_operating_income\"] = nan\n","\n","        ##EBITDA 연평균 성장률\n","        if getAdjCFO(fs_copy[i], years).mean() == 0:\n","            c = getEarnings(fs_copy[i], years) + \\\n","                getDepreciationAndAmortization(fs_copy[i], years) - \\\n","                getInterestExpense(fs_copy[i], years) - \\\n","                getTax(fs_copy[i], years)\n","        else:\n","            c = getAdjCFO(fs_copy[i], years) - \\\n","                getInterestExpense(fs_copy[i], years) - \\\n","                getTax(fs_copy[i], years)\n","        c = c.to_frame().T\n","        # print(growth(b, years))\n","        try:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_ebitda\"] = getRateOfChange(c, len(c.columns))\n","        except:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_ebitda\"] = nan\n","\n","        ##eps 연평균 성장률\n","        d = getEPS(fs_copy[i], years)\n","        d = d.to_frame().T\n","        # print(growth(c, years))\n","        try:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_eps\"] = getRateOfChange(d, len(d.columns))\n","        except:\n","            fs_copy[i][\"metrics\"][\"yoy_avg_eps\"] = nan\n","\n","    return fs_copy\n","\n","# 2. 안정성 지표 (최근 3년 평균)\n","# Quick ratio = (유동자산 - 재고자산) / 유동부채\n","# 매출채권 회전율 = 매출액 / 매출채권\n","# 부채비율 = 부채 / 자기자본\n","# ICR(Interest Coverage Ratio) = EBITDA / 이자비용\n","def getStabilityIndicator(fs, years=3):\n","    fs_copy = copy.deepcopy(fs)\n","    for i in list(fs_copy.keys()):\n","        print(\"===== Getting metrics on\", i, \"=====\")\n","        try:\n","            fs_copy[i][\"metrics\"][\"quick_ratio\"] = ((getCurrentAsset(fs_copy[i], years) - getInventory(fs_copy[i], years)) / \\\n","                                                    getCurrentLiab(fs_copy[i], years)).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"quick_ratio\"] = nan\n","\n","        try:\n","            fs_copy[i][\"metrics\"][\"receivable_turnover_ratio\"] = (getRevenue(fs_copy[i], years) / getBond(fs_copy[i], years)).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"receivable_turnover_ratio\"] = nan\n","\n","        try:\n","            fs_copy[i][\"metrics\"][\"asset_turnover_ratio\"] = (getRevenue(fs_copy[i], years) / (getEquity(fs_copy[i], years) + getDebt(fs_copy[i], years))).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"asset_turnover_ratio\"] = nan\n","\n","        try:\n","            fs_copy[i][\"metrics\"][\"debt_to_equity_ratio\"] = (getDebt(fs_copy[i], years) / getEquity(fs_copy[i], years)).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"debt_to_equity_ratio\"] = nan\n","\n","        try:\n","            if getAdjCFO(fs_copy[i], years).mean() == 0:\n","                ebitda = getEarnings(fs_copy[i], years) + \\\n","                         getDepreciationAndAmortization(fs_copy[i], years) - \\\n","                         getInterestExpense(fs_copy[i], years) - \\\n","                         getTax(fs_copy[i], years)\n","            else:\n","                ebitda = getAdjCFO(fs_copy[i], years) - \\\n","                         getInterestExpense(fs_copy[i], years) - \\\n","                         getTax(fs_copy[i], years)\n","            interest_expense = getInterestExpense(fs_copy[i], years)\n","            ebitda = ebitda[interest_expense != 0]\n","            interest_expense = interest_expense[interest_expense != 0]\n","            fs_copy[i][\"metrics\"][\"icr\"] = (ebitda / interest_expense).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"icr\"] = nan\n","        print(\"===== Complete =====\")\n","    return fs_copy\n","\n","# 3. 수익성 지표 (최근 3년 평균)\n","# 매출액\n","# 영업이익\n","# 영업이익 마진\n","# EBITDA\n","# EBITDA 마진\n","# ROE = 당기순이익 / 자기자본\n","# CFO to Earnings = 영업현금흐름 / 당기순이익\n","def getProfitabilityIndicator(fs, years=3):\n","    fs_copy = copy.deepcopy(fs)\n","    for i in list(fs_copy.keys()):\n","        print(\"===== Getting metrics on\", i, \"=====\")\n","        fs_copy[i][\"metrics\"][\"revenue\"] = getRevenue(fs_copy[i], years).mean()\n","        fs_copy[i][\"metrics\"][\"operating_income\"] = getOperatingIncome(fs_copy[i], years).mean()\n","        fs_copy[i][\"metrics\"][\"operating_margin\"] = (getOperatingIncome(fs_copy[i], years) / getRevenue(fs_copy[i], years)).mean()\n","        if getAdjCFO(fs_copy[i], years).mean() == 0:\n","            fs_copy[i][\"metrics\"][\"ebitda\"] = (getEarnings(fs_copy[i], years) + \\\n","                                               getDepreciationAndAmortization(fs_copy[i], years) - \\\n","                                               getInterestExpense(fs_copy[i], years) - \\\n","                                               getTax(fs_copy[i], years)).mean()\n","            fs_copy[i][\"metrics\"][\"ebitda_margin\"] = ((getEarnings(fs_copy[i], years) + \\\n","                                                       getDepreciationAndAmortization(fs_copy[i], years) - \\\n","                                                       getInterestExpense(fs_copy[i], years) - \\\n","                                                       getTax(fs_copy[i], years)) / getRevenue(fs_copy[i], years)).mean()\n","        else:\n","            fs_copy[i][\"metrics\"][\"ebitda\"] = (getAdjCFO(fs_copy[i], years) - \\\n","                                               getInterestExpense(fs_copy[i], years) - \\\n","                                               getTax(fs_copy[i], years)).mean()\n","            fs_copy[i][\"metrics\"][\"ebitda_margin\"] = ((getAdjCFO(fs_copy[i], years) - \\\n","                                                       getInterestExpense(fs_copy[i], years) - \\\n","                                                       getTax(fs_copy[i], years)) / getRevenue(fs_copy[i], years)).mean()\n","        try:\n","            fs_copy[i][\"metrics\"][\"roe\"] = (getEarnings(fs_copy[i], years) / getEquity(fs_copy[i], years)).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"roe\"] = nan\n","\n","        try:\n","            fs_copy[i][\"metrics\"][\"cfo_to_earnings\"] = (getCFO(fs_copy[i], years) / getEarnings(fs_copy[i], years)).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"cfo_to_earnings\"] = nan\n","        print(\"===== Complete =====\")\n","    return fs_copy\n","    \n","# 4. 가치평가 지표 (최근 1년)\n","# PSR = 1주당 주가 / 주당 매출액\n","# PER = 1주당 주가 / 주당 순이익\n","def getValuationIndicator(fs, years=1, stock_dates=()):\n","    fs_copy = copy.deepcopy(fs)\n","    for i in list(fs_copy.keys()):\n","        print(\"===== Getting metrics on\", i, \"=====\")\n","        try:\n","            fs_copy[i][\"metrics\"][\"per\"] = (getStockPrice(fs_copy[i], stock_dates).values / getEPS(fs_copy[i], years).values).mean()\n","        except:\n","            fs_copy[i][\"metrics\"][\"per\"] = nan\n","        print(\"===== Complete =====\")\n","    return fs_copy\n","# 5. 주주환원 지표 (최근 3년 평균)\n","# 주주환원율 = (배당금 + 자사주매입금) / 당기순이익\n","def getShareholderReturnIndicator(fs, years=3):\n","    fs_copy = copy.deepcopy(fs)\n","    for i in list(fs_copy.keys()):\n","        print(\"===== Getting metrics on\", i, \"=====\")\n","        fs_copy[i][\"metrics\"][\"shareholder_return\"] = ((getDividend(fs_copy[i], years) + getBuyback(fs_copy[i], years)) / \\\n","                                                       getEarnings(fs_copy[i], years)).mean()\n","        print(\"===== Complete =====\")\n","    return fs_copy\n","\n","def getBeta(portfolio, benchmark):\n","    return stats.linregress(portfolio.pct_change()[1:].values, benchmark.pct_change()[1:].values)[0]\n","def getJensenAlpah(fs, benchmark=\"KOSPI\", riskfree_rate=0.02, stock_dates=(), period=\"q\"):\n","    fs_copy = copy.deepcopy(fs)\n","    if benchmark == \"KOSPI\":\n","        benchmark_df = stock.get_index_ohlcv_by_date(stock_dates[0], stock_dates[1], \"1001\")[\"종가\"]\n","        benchmark_df.name = \"benchmark\"\n","    else:\n","        print(\"Unknown benchmark : return original\")\n","        return fs\n","    for i in list(fs.keys()):\n","        try:\n","            print(\"===== Get jensen alpha on\", i, \"=====\")\n","            portfolio_df = getStockPrice(fs_copy[i], stock_dates=(stock_dates[0], stock_dates[1]), op=\"raw\")[\"종가\"]\n","            portfolio_df.name = \"portfolio\"\n","\n","            # 해당 기간의 수익률을 구합니다 (기간 첫 value 와 기간 마지막 value 의 변화율)\n","            comp_df = pd.concat([benchmark_df, portfolio_df], axis=1, join=\"inner\")\n","            if period == \"m\":\n","                comp_df_resample = comp_df.resample(\"1M\").agg(lambda x: (x[-1] - x[0]) / x[0])\n","                comp_df_resample[\"beta\"] = comp_df.resample(\"1M\").agg(lambda x: getBeta(x[\"portfolio\"], x[\"benchmark\"]))\n","            elif period == \"q\":\n","                comp_df_resample = comp_df.resample(\"1Q\").agg(lambda x: (x[-1] - x[0]) / x[0])\n","                comp_df_resample[\"beta\"] = comp_df.resample(\"1Q\").agg(lambda x: getBeta(x[\"portfolio\"], x[\"benchmark\"]))\n","            elif period == \"y\":\n","                comp_df_resample = comp_df.resample(\"1Y\").agg(lambda x: (x[-1] - x[0]) / x[0])\n","                comp_df_resample[\"beta\"] = comp_df.resample(\"1Y\").agg(lambda x: getBeta(x[\"portfolio\"], x[\"benchmark\"]))\n","            else:\n","                comp_df_resample = dataframe([comp_df.agg(lambda x: (x[-1] - x[0]) / x[0])])\n","                comp_df_resample[\"beta\"] = getBeta(comp_df[\"portfolio\"], comp_df[\"benchmark\"])\n","                print(\"Unknown period : 'daily' is set\")\n","\n","            # 기간 평균 젠센알파를 구합니다\n","            fs_copy[i][\"metrics\"][\"jensen_alpha\"] = (comp_df_resample[\"portfolio\"] - (riskfree_rate + comp_df_resample[\"beta\"] * (comp_df_resample[\"benchmark\"] - riskfree_rate))).mean()\n","            fs_copy[i][\"metrics\"][\"jensen_alpha_class\"] = 1 if fs_copy[i][\"metrics\"][\"jensen_alpha\"] >= 0 else 0\n","        except:\n","            print(\"ERROR : delete key\", i)\n","            del fs_copy[i]\n","    return fs_copy\n","def getSortinoRatio(fs, benchmark=\"KOSPI\", riskfree_rate=0.02, stock_dates=(), period=\"q\"):\n","    fs_copy = copy.deepcopy(fs)\n","    if benchmark == \"KOSPI\":\n","        benchmark_df = stock.get_index_ohlcv_by_date(stock_dates[0], stock_dates[1], \"1001\")[\"종가\"]\n","        benchmark_df.name = \"benchmark\"\n","    else:\n","        print(\"Unknown benchmark : return original\")\n","        return fs\n","    for i in list(fs.keys()):\n","        try:\n","            print(\"===== Get sortino ratio on\", i, \"=====\")\n","            portfolio_df = getStockPrice(fs_copy[i], stock_dates=(stock_dates[0], stock_dates[1]), op=\"raw\")[\"종가\"]\n","            portfolio_df.name = \"portfolio\"\n","\n","            # 해당 기간의 수익률을 구합니다 (기간 첫 value 와 기간 마지막 value 의 변화율)\n","            comp_df = pd.concat([benchmark_df, portfolio_df], axis=1, join=\"inner\")\n","            if period == \"m\":\n","                comp_df_resample = comp_df.resample(\"1M\").agg(lambda x: (x[-1] - x[0]) / x[0])\n","                comp_df_resample[\"downside_std\"] = comp_df.pct_change()[1:][\"portfolio\"].resample(\"1M\").agg(lambda x: x[x < 0].std())\n","            elif period == \"q\":\n","                comp_df_resample = comp_df.resample(\"1Q\").agg(lambda x: (x[-1] - x[0]) / x[0])\n","                comp_df_resample[\"downside_std\"] = comp_df.pct_change()[1:][\"portfolio\"].resample(\"1Q\").agg(lambda x: x[x < 0].std())\n","            elif period == \"y\":\n","                comp_df_resample = comp_df.resample(\"1Y\").agg(lambda x: (x[-1] - x[0]) / x[0])\n","                comp_df_resample[\"downside_std\"] = comp_df.pct_change()[1:][\"portfolio\"].resample(\"1Y\").agg(lambda x: x[x < 0].std())\n","            else:\n","                comp_df_resample = dataframe([comp_df.agg(lambda x: (x[-1] - x[0]) / x[0])])\n","                comp_df_resample[\"downside_std\"] = comp_df.pct_change()[1:][\"portfolio\"][comp_df.pct_change()[1:][\"portfolio\"]<0].std()\n","                print(\"Unknown period : 'day' is set\")\n","\n","            # 기간 평균 소티노비율를 구합니다\n","            fs_copy[i][\"metrics\"][\"sortino_ratio\"] = ((comp_df_resample[\"portfolio\"] - riskfree_rate) / comp_df_resample[\"downside_std\"]).mean()\n","            fs_copy[i][\"metrics\"][\"sortino_ratio_class\"] = 1 if fs_copy[i][\"metrics\"][\"sortino_ratio\"] >= 0 else 0\n","        except:\n","            print(\"ERROR : delete key\", i)\n","            del fs_copy[i]\n","    return fs_copy\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9HXGhm6XU1cj"},"source":["(3) sector dictionary에 기업별 재무 feature 저장"]},{"cell_type":"code","metadata":{"id":"8W37Pg4tSKDS"},"source":["\n","for i in sector.keys():\n","    sector[i] = getGrowthIndicator(sector[i], 7)\n","    sector[i] = getStabilityIndicator(sector[i])\n","    sector[i] = getProfitabilityIndicator(sector[i])\n","    sector[i] = getValuationIndicator(sector[i], 1, (\"20190101\", \"20191231\"))\n","    sector[i] = getShareholderReturnIndicator(sector[i])\n","    sector[i] = getJensenAlpah(sector[i], riskfree_rate=0.0169, stock_dates=(\"20200101\", \"20201231\"))\n","    # sector[i] = getSortinoRatio(sector[i], riskfree_rate=0.0189, stock_dates=(\"20190101\", \"20191231\"))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FnDfhvEiVCVx"},"source":["(4) sector dict 내의 데이터를 dataframe으로 변환"]},{"cell_type":"code","metadata":{"id":"hTdHaDIlSQT4"},"source":["\n","def transform_frame(sector_dict, sector_key, col_name):\n","    df = dataframe(columns=col_name)\n","    for k, v in sector_dict.items():\n","        df = pd.concat([df, dataframe([v[\"metrics\"].values()], columns=v[\"metrics\"].keys())], axis=0)\n","    df[\"sector\"] = sector_key\n","    df.index = sector_dict.keys()\n","    df.index.name = \"기업명\"\n","    return df\n","    \n","# metric 키값 구하기 및 sector 컬럼 결합\n","# sector iteration\n","for i in sector.keys():\n","    # corporate iteration\n","    for j in sector[i].keys():\n","        col_name = list(sector[i][j][\"metrics\"].keys()) + [\"sector\"]\n","        break\n","\n","# 빈데이터 프레임 생성\n","full_x = dataframe(columns=col_name)\n","# sector에 있는 데이터 모두 데이터프레임화\n","for key, item in sector.items():\n","    a = transform_frame(item, key, col_name)\n","    full_x = pd.concat([full_x, a], axis=0)\n","del sector\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SCNaJ_mXVS90"},"source":["(5) 생성한 학습데이터셋에 대한 중복 확인 및 NA값 대치"]},{"cell_type":"code","metadata":{"id":"OKoPjr-ySVc3"},"source":["\n","# 무한대값은 0으로 나누는 연산이 있는 series 에서 발생한 것이므로 na 처리\n","full_x.replace([np.inf, -np.inf], nan, inplace=True)\n","\n","dup_table = pd.read_excel(\"kdigital_project3/중복기업리스트_섹터할당.xlsx\")\n","dup_table.columns = [\"name\", \"sector\", \"사업부문\", \"추천섹터\"]\n","dup_table = dup_table.drop(which(dup_table[\"추천섹터\"].isna())[0], axis=0)\n","\n","# 산업군에 중복으로 들어간 기업들에 대해 drop 수행\n","drop_list = []\n","for i in range(full_x.shape[0]):\n","    if full_x.index[i] in dup_table[\"name\"].values:\n","        if full_x[\"sector\"][i] != dup_table[full_x.index[i] == dup_table[\"name\"].values][\"sector\"].values[0]:\n","            drop_list.append(i)\n","\n","retain_list = diff(list(range(full_x.shape[0])), drop_list)\n","full_x = full_x.iloc[retain_list]\n","corp_index = full_x.index\n","full_x.reset_index(drop=True, inplace=True)\n","\n","full_y = full_x[\"jensen_alpha_class\"]\n","jensen_alpha = full_x[\"jensen_alpha\"]\n","full_x.drop([\"jensen_alpha\", \"jensen_alpha_class\"], axis=1, inplace=True)\n","\n","full_y.isna().sum()\n","full_x.isna().sum()\n","cat_vars = [\"sector\"]\n","\n","# sector 컬럼에 대해 label encoding\n","label_encoder = MyLabelEncoder()\n","full_x = label_encoder.fit_transform(full_x, cat_vars)\n","\n","# knn imputer 를 활용한 na값 imputing \n","knn_imputer = MyKNNImputer()\n","full_x = knn_imputer.fit_transform(full_x, full_y, cat_vars)\n","\n","print(full_x.isna().sum())\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1RcTphevvC_2"},"source":["# 질문 목록"]},{"cell_type":"markdown","metadata":{"id":"ULt1ZhPHvEBJ"},"source":["\n","\n","\n","1. 저희 팀은 특정 시점의 재무데이터를 가지고 미래의 분기평균 젠센알파를 이진분류하려고 합니다. (target은 젠센알파가 0 보다 크거나 같으면 1 아니면 0 변환) 다음과 같은 train 및 test 기간이 적절한지요?\n","\n","\n","*   train feature 기간 : 2012 ~ 2018 (최근 7년에 대한 투자지표)\n","*   train target 기간 : 2019년\n","*   test feature 기간 : 2013 ~ 2019 (최근 7년에 대한 투자지표)\n","*   test target 기간 : 2020년\n","\n","\n","2. 20 개의 feature 대부분 target 간의 상관관계가 매우 떨어지는 것을 확인하였습니다. (statsmodel 회귀 결과 '자산회전율' 1개의 feature 제외) 그리고 이에 따라 정확성 또한 조금 떨어지는 것도 확인하였습니다. 이러한 상황에서 분석의 의의를 찾기위해 어느 방향성으로 분석을 진행해야 하는지요?\n"]}]}