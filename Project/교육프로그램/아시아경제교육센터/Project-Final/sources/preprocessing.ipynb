{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBreakthroughPoint(df, col1, col2, patient_days, fill_method=\"fb\"):\n",
    "    '''\n",
    "    :param df: dataframe (including col1, col2)\n",
    "    :param col1: obj\n",
    "    :param col2: obj moving average\n",
    "    :param patient_days: patient days detected as breakthrough point\n",
    "    :return: signal series\n",
    "    '''\n",
    "    sigPrice = []\n",
    "    flag = -1  # A flag for the trend upward/downward\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        if df[col1][i] > df[col2][i] and flag != 1:\n",
    "            tmp = df['Close'][i:(i + patient_days + 1)]\n",
    "            if len(tmp) == 1:\n",
    "                sigPrice.append(\"buy\")\n",
    "                flag = 1\n",
    "            else:\n",
    "                if (tmp.iloc[1:] > tmp.iloc[0]).all():\n",
    "                    sigPrice.append(\"buy\")\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    sigPrice.append(nan)\n",
    "        elif df[col1][i] < df[col2][i] and flag != 0:\n",
    "            tmp = df['Close'][i:(i + patient_days + 1)]\n",
    "            if len(tmp) == 1:\n",
    "                sigPrice.append(\"sell\")\n",
    "                flag = 0\n",
    "            else:\n",
    "                if (tmp.iloc[1:] < tmp.iloc[0]).all():\n",
    "                    sigPrice.append(\"sell\")\n",
    "                    flag = 0\n",
    "                else:\n",
    "                    sigPrice.append(nan)\n",
    "        else:\n",
    "            sigPrice.append(nan)\n",
    "\n",
    "    sigPrice = series(sigPrice)\n",
    "    for idx, value in enumerate(sigPrice):\n",
    "        if not isna(value):\n",
    "            if value == \"buy\":\n",
    "                sigPrice.iloc[1:idx] = \"sell\"\n",
    "            else:\n",
    "                sigPrice.iloc[1:idx] = \"buy\"\n",
    "            break\n",
    "    # if fill_method == \"bf\":\n",
    "    #\n",
    "    # elif fill_method == \"\"\n",
    "    sigPrice.ffill(inplace=True)\n",
    "    return sigPrice\n",
    "def stochastic(df, n=14, m=5, t=5):\n",
    "    #데이터 프레임으로 받아오기 때문에 불필요\n",
    "\n",
    "    #n 일중 최저가\n",
    "    ndays_high = df['High'].rolling(window=n, min_periods=n).max()\n",
    "    ndays_low = df['Low'].rolling(window=n, min_periods=n).min()\n",
    "    fast_k = ((df['Close'] - ndays_low) / (ndays_high - ndays_low) * 100)\n",
    "    slow_k = fast_k.ewm(span=m, min_periods=m).mean()\n",
    "    slow_d = slow_k.ewm(span=t, min_periods=t).mean()\n",
    "    df = df.assign(fast_k=fast_k, fast_d=slow_k, slow_k=slow_k, slow_d=slow_d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== raw data loading =====\n",
    "# 한 종목코드에 대한 주가 정보를 로드\n",
    "\n",
    "# 임의 선별\n",
    "# 삼성전자\n",
    "# NAVER\n",
    "# 카카오\n",
    "\n",
    "# 랜덤 선별\n",
    "# rnd.seed(48)\n",
    "# stock_list.iloc[rnd.randint(len(stock_list))]\n",
    "# 금호석유\n",
    "# 티움바이오\n",
    "# 테크윙\n",
    "# 제테마\n",
    "# 주성엔지니어링\n",
    "# 고바이오랩\n",
    "# 고영\n",
    "\n",
    "# Get Stock List\n",
    "path = 'projects/dacon_stockprediction/open_week4/'\n",
    "list_name = 'Stock_List.csv'\n",
    "sample_name = 'sample_submission_week4.csv'\n",
    "\n",
    "# raw features (5개)\n",
    "# 주가, 거래량, 기관순매수, 외인순매수, 뉴스 기사(embedding)\n",
    "\n",
    "# derived features (14개)\n",
    "# 주가이평, 거래량이평, 기관순매수이평, 외인순매수이평, 뉴스 기사에 대한 긍부정점수, 요일, sin변환(5일), cos변환(5일)\n",
    "# 산식 보조 지표\n",
    "# 1. 주가 관련 지표 : Stochastic(20), RSI(20), 볼린저밴드(20)\n",
    "# 2. 거래량 관련 지표 : OBV, VR(20)\n",
    "# 3. 혼합지표 : MFI(주가 + 거래량)\n",
    "\n",
    "# 종목 코드 로드\n",
    "stock_list = read_csv(os.path.join(path, list_name))\n",
    "stock_list['종목코드'] = stock_list['종목코드'].apply(lambda x: str(x).zfill(6))\n",
    "\n",
    "# Get Data & Modeling\n",
    "# 분석할 date 변수 지정\n",
    "start_date = '20201201'\n",
    "end_date = '20211001'\n",
    "\n",
    "start_weekday = pd.to_datetime(start_date).weekday()\n",
    "max_weeknum = pd.to_datetime(end_date).strftime('%V')\n",
    "business_days = pd.DataFrame(pd.date_range(start_date, end_date, freq='B'), columns=['Date'])\n",
    "\n",
    "# 선택 종목\n",
    "stock_list.set_index(\"종목명\", inplace=True)\n",
    "selected_codes = [\"삼성전자\", \"NAVER\", \"카카오\", \"금호석유\", \"티움바이오\", \"테크윙\", \"제테마\", \"주성엔지니어링\", \"고바이오랩\", \"고영\"]\n",
    "stock_list = stock_list.loc[selected_codes][\"종목코드\"]\n",
    "\n",
    "# # 모든 종목\n",
    "# stock_list.set_index(\"종목명\", inplace=True)\n",
    "# selected_codes = stock_list.index.tolist()\n",
    "# stock_list = stock_list.loc[selected_codes][\"종목코드\"]\n",
    "\n",
    "stock_dic = dict.fromkeys(selected_codes)\n",
    "error_list = []\n",
    "corr_list = []\n",
    "anova_weekday = 0\n",
    "anova_weeknum = 0\n",
    "timeunit_gap = 1\n",
    "metric_days = 14\n",
    "\n",
    "# ==== selected feature =====\n",
    "selected_features = [\"date\", \"close\", \"fast_d\", \"obv\", \"fore_mv20\", \"inst_mv20\", \"kospi\", \"trading_amount_mv20\"]\n",
    "# selected_features = []\n",
    "\n",
    "for stock_name, stock_code in stock_list.items():\n",
    "    try:\n",
    "        print(\"=====\", stock_name, \"=====\")\n",
    "        # 종목 주가 데이터 로드\n",
    "        stock_dic[stock_name] = dict.fromkeys([\"df\", \"target_list\"])\n",
    "        stock_df = stock.get_market_ohlcv_by_date(start_date, end_date, stock_code).reset_index()\n",
    "        sleep(1)\n",
    "        investor_df = stock.get_market_trading_volume_by_date(start_date, end_date, stock_code)[[\"기관합계\", \"외국인합계\"]].reset_index()\n",
    "        sleep(1)\n",
    "        kospi_df = stock.get_index_ohlcv_by_date(start_date, end_date, \"1001\")[[\"종가\"]].reset_index()\n",
    "        sleep(1)\n",
    "\n",
    "        stock_df.columns = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "        investor_df.columns = [\"Date\", \"inst\", \"fore\"]\n",
    "        kospi_df.columns = [\"Date\", \"kospi\"]\n",
    "        # 영업일과 주가 정보를 outer 조인\n",
    "        train_x = pd.merge(business_days, stock_df, how='left', on=\"Date\")\n",
    "        train_x = pd.merge(train_x, investor_df, how='left', on=\"Date\")\n",
    "        train_x = pd.merge(train_x, kospi_df, how='left', on=\"Date\")\n",
    "        # 종가데이터에 생긴 na 값을 선형보간 및 정수로 반올림\n",
    "        train_x.iloc[:,1:] = train_x.iloc[:,1:].ffill(axis=0).round(0)\n",
    "\n",
    "        # ===== feature engineering =====\n",
    "        # 요일 및 주차 파생변수 추가\n",
    "        train_x['weekday'] = train_x[\"Date\"].apply(lambda x: x.weekday())\n",
    "        train_x['weeknum'] = train_x[\"Date\"].apply(lambda x: week_of_month(x))\n",
    "        cat_vars = [\"weekday\", \"weeknum\"]\n",
    "\n",
    "        # 거래대금 파생변수 추가\n",
    "        train_x['trading_amount'] = train_x[\"Close\"] * train_x[\"Volume\"]\n",
    "\n",
    "        # 월별 주기성 특징을 잡기 위한 sin 및 cos 변환 파생변수 추가\n",
    "        day_to_sec = 24 * 60 * 60\n",
    "        month_to_sec = 20 * day_to_sec\n",
    "        timestamp_s = train_x[\"Date\"].apply(datetime.timestamp)\n",
    "        timestamp_freq = round((timestamp_s / month_to_sec).diff(20)[20], 1)\n",
    "\n",
    "        train_x['dayofmonth_freq_sin'] = np.sin((timestamp_s / month_to_sec) * ((2 * np.pi) / timestamp_freq))\n",
    "        train_x['dayofmonth_freq_cos'] = np.cos((timestamp_s / month_to_sec) * ((2 * np.pi) / timestamp_freq))\n",
    "\n",
    "        # OBV 파생변수 추가\n",
    "        # 매수 신호: obv > obv_ema\n",
    "        # 매도 신호: obv < obv_ema\n",
    "        obv = [0]\n",
    "        for i in range(1, len(train_x.Close)):\n",
    "            if train_x.Close[i] > train_x.Close[i - 1]:\n",
    "                obv.append(obv[-1] + train_x.Volume[i])\n",
    "            elif train_x.Close[i] < train_x.Close[i - 1]:\n",
    "                obv.append(obv[-1] - train_x.Volume[i])\n",
    "            else:\n",
    "                obv.append(obv[-1])\n",
    "        train_x['obv'] = obv\n",
    "        train_x['obv'][0] = nan\n",
    "        train_x['obv_ema'] = train_x['obv'].ewm(com=metric_days, min_periods=metric_days).mean()\n",
    "\n",
    "\n",
    "        # Stochastic 파생변수 추가\n",
    "        # fast_d = moving average on fast_k\n",
    "        train_x[[\"fast_k\", \"fast_d\"]] = stochastic(train_x, n=metric_days)[[\"fast_k\", \"fast_d\"]]\n",
    "\n",
    "\n",
    "        # MFI 파생변수 추가\n",
    "        # MFI = 100 - (100 / 1 + MFR)\n",
    "        # MFR = 14일간의 양의 MF / 14일간의 음의 MF\n",
    "        # MF = 거래량 * (당일고가 + 당일저가 + 당일종가) / 3\n",
    "        # MF 컬럼 만들기\n",
    "        train_x[\"mf\"] = train_x[\"Volume\"] * ((train_x[\"High\"]+train_x[\"Low\"]+train_x[\"Close\"]) / 3)\n",
    "        # 양의 MF와 음의 MF 표기 컬럼 만들기\n",
    "        p_n = []\n",
    "        for i in range(len(train_x['mf'])):\n",
    "            if i == 0 :\n",
    "                p_n.append(nan)\n",
    "            else:\n",
    "                if train_x['mf'][i] >= train_x['mf'][i-1]:\n",
    "                    p_n.append('p')\n",
    "                else:\n",
    "                    p_n.append('n')\n",
    "        train_x['p_n'] = p_n\n",
    "        # 14일간 양의 MF/ 14일간 음의 MF 계산하여 컬럼 만들기\n",
    "        mfr = []\n",
    "        for i in range(len(train_x['mf'])):\n",
    "            if i < metric_days-1:\n",
    "                mfr.append(nan)\n",
    "            else:\n",
    "                train_x_=train_x.iloc[(i-metric_days+1):i]\n",
    "                a = sum(train_x_['mf'][train_x['p_n']=='p']) / sum(train_x_['mf'][train_x['p_n'] == 'n'])\n",
    "                mfr.append(a)\n",
    "        train_x['mfr'] = mfr\n",
    "        # 최종 MFI 컬럼 만들기\n",
    "        train_x['mfi'] = 100 - (100/(1+train_x['mfr']))\n",
    "        train_x[\"mfi_signal\"] = train_x['mfi'].apply(lambda x: \"buy\" if x > 50 else \"sell\")\n",
    "\n",
    "        # 이동평균 추가\n",
    "        train_x[\"close_mv5\"] = train_x[\"Close\"].rolling(5, min_periods=5).mean()\n",
    "        train_x[\"close_mv10\"] = train_x[\"Close\"].rolling(10, min_periods=10).mean()\n",
    "        train_x[\"close_mv20\"] = train_x[\"Close\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "        train_x[\"volume_mv5\"] = train_x[\"Volume\"].rolling(5, min_periods=5).mean()\n",
    "        train_x[\"volume_mv10\"] = train_x[\"Volume\"].rolling(10, min_periods=10).mean()\n",
    "        train_x[\"volume_mv20\"] = train_x[\"Volume\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "        train_x[\"trading_amount_mv5\"] = train_x[\"trading_amount\"].rolling(5, min_periods=5).mean()\n",
    "        train_x[\"trading_amount_mv10\"] = train_x[\"trading_amount\"].rolling(10, min_periods=10).mean()\n",
    "        train_x[\"trading_amount_mv20\"] = train_x[\"trading_amount\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "        train_x[\"inst_mv5\"] = train_x[\"inst\"].rolling(5, min_periods=5).mean()\n",
    "        train_x[\"inst_mv10\"] = train_x[\"inst\"].rolling(10, min_periods=10).mean()\n",
    "        train_x[\"inst_mv20\"] = train_x[\"inst\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "        train_x[\"fore_mv5\"] = train_x[\"fore\"].rolling(5, min_periods=5).mean()\n",
    "        train_x[\"fore_mv10\"] = train_x[\"fore\"].rolling(10, min_periods=10).mean()\n",
    "        train_x[\"fore_mv20\"] = train_x[\"fore\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "        train_x[\"kospi_mv5\"] = train_x[\"kospi\"].rolling(5, min_periods=5).mean()\n",
    "        train_x[\"kospi_mv10\"] = train_x[\"kospi\"].rolling(10, min_periods=10).mean()\n",
    "        train_x[\"kospi_mv20\"] = train_x[\"kospi\"].rolling(20, min_periods=20).mean()\n",
    "\n",
    "        # 지표계산을 위해 쓰인 컬럼 drop\n",
    "        train_x.drop([\"mf\", \"p_n\", \"mfr\", \"Open\", \"High\", \"Low\"], inplace=True, axis=1)\n",
    "\n",
    "        # 2021/1/4 이후 일자만 선택\n",
    "        train_x = train_x[train_x[\"Date\"] >= datetime(2021, 1, 4)]\n",
    "        train_x = train_x.dropna()\n",
    "        train_x.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # create target list\n",
    "        target_list = []\n",
    "        target_list.append(train_x[\"Close\"])\n",
    "        target_list.append(train_x[\"Close\"].shift(-1))\n",
    "        target_list.append(train_x[\"Close\"].shift(-2))\n",
    "        target_list.append(train_x[\"Close\"].shift(-3))\n",
    "        target_list.append(train_x[\"Close\"].shift(-4))\n",
    "        target_list.append(train_x[\"Close\"].shift(-5))\n",
    "        for idx, value in enumerate(target_list):\n",
    "            value.name = \"target_shift\" + str(idx)\n",
    "\n",
    "        # 컬럼이름 소문자 변환 및 정렬\n",
    "        train_x.columns = train_x.columns.str.lower()\n",
    "        train_x = pd.concat([train_x[[\"date\"]], train_x.iloc[:,1:].sort_index(axis=1)], axis=1)\n",
    "\n",
    "        # <visualization>\n",
    "        # 시각화용 데이터프레임 생성\n",
    "        train_bi = pd.concat([target_list[timeunit_gap], train_x], axis=1)[:-timeunit_gap]\n",
    "\n",
    "        # 평균 상관관계를 측정하기 위해 연산\n",
    "        corr_obj = train_bi.corr().round(3)\n",
    "        corr_rows = corr_obj.index.tolist()\n",
    "        corr_cols = corr_obj.columns.tolist()\n",
    "        corr_list.append(corr_obj.to_numpy().round(3)[...,np.newaxis])\n",
    "\n",
    "        # 상관관계 시각화\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        sns.heatmap(corr_obj, cmap=\"YlGnBu\", linewidths=0.2, annot=True)\n",
    "        plt.xticks(rotation=45)\n",
    "        fig.subplots_adjust(left=0.15, bottom=0.2)\n",
    "        plt.title('Correlation Visualization on ' + stock_name, fontsize=15, fontweight=\"bold\", pad=15)\n",
    "        plt.savefig(\"projects/dacon_stockprediction/graphs/\" + stock_name + \".png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "        # feature 와 target 간 시각화\n",
    "        # ===== scatter plot on numerical feature =====\n",
    "        for i in train_x.columns:\n",
    "            if i == \"date\" or i in cat_vars:\n",
    "                pass\n",
    "            else:\n",
    "                fig, ax = plt.subplots(figsize=(12, 6))\n",
    "                graph = sns.regplot(x=train_bi[i], y=train_bi[\"target_shift\" + str(timeunit_gap)], color=\"green\",\n",
    "                                    scatter_kws={'s': 15}, line_kws={\"color\": \"orange\"})\n",
    "                graph.set_title(i + \" on \" + stock_name, fontsize=15, fontweight=\"bold\", pad=15)\n",
    "                plt.show()\n",
    "                createFolder('projects/dacon_stockprediction/graphs/' + stock_name)\n",
    "                plt.savefig('projects/dacon_stockprediction/graphs/' + stock_name + \"/\" + i +\".png\", dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "        # feature 분포 시각화\n",
    "        # ===== hist plot on numerical feature =====\n",
    "        for i in train_x.columns:\n",
    "            if i == \"date\" or i in cat_vars:\n",
    "                pass\n",
    "            else:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                graph = sns.histplot(x=train_bi[i], bins=50, color=\"orange\")\n",
    "                graph.set_title(\"Distribution on \" + stock_name + \" (skewness : \" + str(train_bi[i].skew().round(3)) + \")\", fontsize=15, fontweight=\"bold\", pad=15)\n",
    "                graph.set_xlabel(graph.get_xlabel(), fontsize=12, fontweight=\"bold\", labelpad=15)\n",
    "                graph.set_ylabel(graph.get_ylabel(), fontsize=12, fontweight=\"bold\", labelpad=15)\n",
    "                plt.show()\n",
    "                createFolder('projects/dacon_stockprediction/graphs/' + stock_name)\n",
    "                plt.savefig('projects/dacon_stockprediction/graphs/' + stock_name + \"/dist_\" + i +\".png\", dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "        # <feature scaling>\n",
    "        # close, fast_d, kospi, trading_amount_mv20 -> 로그 변환\n",
    "        train_x[[\"close\", \"fast_d\", \"kospi\", \"trading_amount_mv20\"]] = train_x[[\"close\", \"fast_d\", \"kospi\", \"trading_amount_mv20\"]].apply(np.log1p)\n",
    "\n",
    "        # scaling 후 재 시각화\n",
    "        # ===== hist plot on numerical feature =====\n",
    "        for i in [\"close\", \"fast_d\", \"kospi\", \"trading_amount_mv20\"]:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            graph = sns.histplot(x=train_x[i], bins=50, color=\"orange\")\n",
    "            graph.set_title(\"After log scaling distribution on \" + stock_name + \" (skewness : \" + str(train_x[i].skew().round(3)) + \")\", fontsize=15,\n",
    "                            fontweight=\"bold\", pad=15)\n",
    "            graph.set_xlabel(graph.get_xlabel(), fontsize=12, fontweight=\"bold\", labelpad=15)\n",
    "            graph.set_ylabel(graph.get_ylabel(), fontsize=12, fontweight=\"bold\", labelpad=15)\n",
    "            plt.show()\n",
    "            createFolder('projects/dacon_stockprediction/graphs/' + stock_name)\n",
    "            plt.savefig('projects/dacon_stockprediction/graphs/' + stock_name + \"/dist_logTrans_\" + i + \".png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "        # categorical 변수에 대한 분산분석 (target 과의 상관관계 파악)\n",
    "        # 귀무가설(H0) : 두 변수는 상관관계가 없다\n",
    "        # 대립가설(H1) : 두 변수는 상관관계가 있다\n",
    "        cat_list = train_bi.groupby(\"weekday\")[\"target_shift\" + str(timeunit_gap)].apply(list)\n",
    "        anova_weekday += 1 / len(stock_list) if f_oneway(*cat_list)[1] <= 0.05 else 0\n",
    "\n",
    "        cat_list = train_bi.groupby(\"weeknum\")[\"target_shift\" + str(timeunit_gap)].apply(list)\n",
    "        anova_weeknum += 1 / len(stock_list) if f_oneway(*cat_list)[1] <= 0.05 else 0\n",
    "\n",
    "        # export csv for BI tool\n",
    "        corr_obj.to_csv(\"projects/dacon_stockprediction/bi_dataset/bi_corr_\" + stock_name + \".csv\", encoding=\"euc-kr\", index_label=True, header=False)\n",
    "        train_bi.to_csv(\"projects/dacon_stockprediction/bi_dataset/bi_data_\" + stock_name + \".csv\", encoding=\"euc-kr\", index=False)\n",
    "\n",
    "        # <feature selection>\n",
    "        if len(selected_features) != 0:\n",
    "            train_x = train_x[selected_features]\n",
    "b \n",
    "        stock_dic[stock_name][\"df\"] = train_x.copy()\n",
    "        stock_dic[stock_name][\"target_list\"] = target_list.copy()\n",
    "    except:\n",
    "        print(\"ERROR :\", stock_name)\n",
    "        error_list.append((stock_name, stock_code))\n",
    "del train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
